{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YinYangFit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYbJKgmyCulyi8+5z4F+1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skosch/YinYangFit/blob/master/YinYangFit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnMfGpUTnOrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n",
        "\n",
        "if tf.test.is_gpu_available():\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "      raise SystemError('GPU device not found')\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "elif False:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    \n",
        "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "    tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA7klPDBnZ-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "pi = np.pi\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.cm as cm\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import random; random.seed()\n",
        "import math\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm as tqdm\n",
        "import sys\n",
        "from functools import reduce\n",
        "import random\n",
        "from itertools import cycle, islice, product\n",
        "import operator\n",
        "from scipy.linalg import toeplitz\n",
        "\n",
        "!pip install --quiet tensorfont\n",
        "!pip install --quiet fonttools\n",
        "!pip install --quiet --upgrade fontParts\n",
        "!pip install booleanOperations\n",
        "!pip install --quiet --upgrade ufo-extractor\n",
        "!pip install --quiet --upgrade defcon\n",
        "!pip install --quiet --upgrade ufo2ft\n",
        "import fontParts\n",
        "import extractor\n",
        "import defcon\n",
        "from ufo2ft import compileOTF\n",
        "\n",
        "from tensorfont import Font\n",
        "\n",
        "print(\"✓ Dependencies imported.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrGlCMQnnfcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget -q -O OpenSans-Regular.ttf https://github.com/googlefonts/opensans/blob/master/ttfs/OpenSans-Regular.ttf?raw=true\n",
        "#!wget -q -O Roboto.ttf https://github.com/google/fonts/blob/master/apache/roboto/Roboto-Regular.ttf?raw=true\n",
        "#!wget -q -O Roboto.otf https://github.com/AllThingsSmitty/fonts/blob/master/Roboto/Roboto-Regular/Roboto-Regular.otf?raw=true\n",
        "#!wget -q -O DroidSerif.ttf https://github.com/datactivist/sudweb/blob/master/fonts/droid-serif-v6-latin-regular.ttf?raw=true\n",
        "!wget -q -O CrimsonItalic.otf https://github.com/skosch/Crimson/blob/master/Desktop%20Fonts/OTF/Crimson-Italic.otf?raw=true\n",
        "#!wget -q -O CrimsonBold.otf https://github.com/skosch/Crimson/blob/master/Desktop%20Fonts/OTF/Crimson-Bold.otf?raw=true \n",
        "#!wget -q -O CrimsonRoman.otf https://github.com/alif-type/amiri/blob/master/Amiri-Regular.ttf?raw=true\n",
        "\n",
        "!wget -q -O CrimsonRoman.otf https://github.com/skosch/Crimson/blob/master/Desktop%20Fonts/OTF/Crimson-Roman.otf?raw=true\n",
        "print(\"✓ Font file(s) downloaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxGlXUzWngSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glyph_char_list = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "#glyph_char_list = \"bdghijlmnopqu\" # straight letters only\n",
        "#glyph_char_list = \"abgjqrst\"\n",
        "#glyph_char_list = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "#glyph_char_list = \"OO\"\n",
        "#glyph_char_list = \"abc\"\n",
        "\n",
        "# ==== Create Font ====\n",
        "factor = 1.0 #1.539  # This scales the size of everything\n",
        "filename = \"CrimsonRoman.otf\"\n",
        "f = Font(filename, 34 * factor) # Roboto.ttf CrimsonRoman.otf # 34 for lowercase\n",
        "box_height = int(f.full_height_px)\n",
        "box_width = int(161 * factor) # 121\n",
        "box_width += (box_width + 1) % 2\n",
        "print(\"Box size:\", box_height, \"×\", box_width)\n",
        "\n",
        "batch_size = 2\n",
        "sample_distance_deltas = [-2, 0, 2]\n",
        "sample_distance_factors = [.3, 1., 4.4]\n",
        "n_sample_distances = len(sample_distance_deltas)\n",
        "\n",
        "n_v1_scales = 5\n",
        "n_b_scales = 1\n",
        "n_v1_orientations = 4\n",
        "n_v4_scales = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROjMw0u2nk7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sigmas(skip_scales=0):\n",
        "    sigmas = []\n",
        "    for s in range(n_v1_scales):\n",
        "        min_sigma = 0.7\n",
        "        max_sigma = box_width / 15\n",
        "        sigmas.append((max_sigma - min_sigma) * (s + skip_scales)**2 / (n_v1_scales - 1)**2 + min_sigma)\n",
        "        #sigmas.append((max_sigma - min_sigma) * s / n_v1_scales + min_sigma)\n",
        "    return np.array(sigmas)\n",
        "\n",
        "print(\"Spatial frequency scales:\", get_sigmas())\n",
        "\n",
        "def get_v1_filter_bank(skip_scales, display_filters=False):\n",
        "    def rotated_mgrid(oi):\n",
        "        \"\"\"Generate a meshgrid and rotate it by RotRad radians.\"\"\"\n",
        "        rotation = np.array([[ np.cos(pi*oi/n_v1_orientations), np.sin(pi*oi/n_v1_orientations)],\n",
        "                             [-np.sin(pi*oi/n_v1_orientations), np.cos(pi*oi/n_v1_orientations)]])\n",
        "        hh = box_height # / 2\n",
        "        bw = box_width # / 2\n",
        "        y, x = np.mgrid[-hh:hh, -bw:bw].astype(np.float32)\n",
        "        y += 0.5 # 0 if box_height % 2 == 0 else 0.5\n",
        "        x += 0.5 # 0 if box_width % 2 == 0 else 0.5\n",
        "        return np.einsum('ji, mni -> jmn', rotation, np.dstack([x, y]))\n",
        "\n",
        "    def get_filter(s, theta):\n",
        "        x, y = rotated_mgrid(theta)\n",
        "\n",
        "        # To minimize ringing etc., we create the filter as is, then run it through the DFT.\n",
        "\n",
        "        # First derivative (odd filter/up-down)\n",
        "        d1_space = np.exp(-(x**2+y**2)/(2*s**2))*x/(2*pi*s**4)\n",
        "        d1_relu_sum = np.sum(d1_space * (d1_space > 0))\n",
        "        d1 = np.fft.fft2(np.fft.ifftshift(d1_space + 1j * np.zeros_like(d1_space)))\n",
        "\n",
        "        # Second derivative (even filter/mexican hat):\n",
        "        s2 = s * .85 # To make them about the same width\n",
        "        d2_space = np.exp(-(x**2+y**2)/(2*s2**2))/(2*pi*s2**4) - np.exp(-(x**2+y**2)/(2*s2**2))*x**2/(2*pi*s2**6)\n",
        "        d2_relu_sum = np.sum(d2_space * (d2_space > 0))\n",
        "        d2 = (d1_relu_sum / d2_relu_sum) * np.fft.fft2(np.fft.ifftshift(d2_space + 1j * np.zeros_like(d2_space)))\n",
        "\n",
        "        return (d1 + 1j*d2) / (np.max(tf.abs(d1+1j*d2))) # Max output should be about 0.2, which leaves lots of flexibility for the HRA later\n",
        "\n",
        "    filter_bank = np.zeros((n_v1_scales, n_v1_orientations, 2*box_height, 2*box_width)).astype(np.complex64)\n",
        "\n",
        "    if display_filters:\n",
        "        sizediv = 20\n",
        "        fig, ax = plt.subplots(nrows=n_v1_scales*2, ncols=n_v1_orientations, gridspec_kw = {'wspace':0, 'hspace':0}, figsize=(box_width * n_v1_orientations / sizediv, box_height * n_v1_scales * 2 / sizediv))\n",
        "\n",
        "    sigmas = get_sigmas()\n",
        "    for s in range(n_v1_scales):\n",
        "        sigma = sigmas[s]\n",
        "        for o in range(n_v1_orientations):\n",
        "            f = get_filter(sigma, o)\n",
        "            if display_filters:\n",
        "                mx = np.max(np.abs(np.imag(np.fft.ifft2(f))))\n",
        "                ax[s*2, o].imshow(np.real(np.fft.fftshift(np.fft.ifft2(f))), cmap=\"RdBu\", vmin=-mx, vmax=mx)\n",
        "                ax[s*2, o].set_aspect(\"auto\")\n",
        "                ax[s*2, o].set_yticklabels([])\n",
        "                ax[s*2+1, o].imshow(np.imag(np.fft.fftshift(np.fft.ifft2(f))), cmap=\"RdBu\", vmin=-mx, vmax=mx)\n",
        "                ax[s*2+1, o].set_aspect(\"auto\")\n",
        "                ax[s*2+1, o].set_yticklabels([])\n",
        "            filter_bank[s, o, :, :] = f\n",
        "\n",
        "    if display_filters:\n",
        "        plt.show()\n",
        "\n",
        "    return filter_bank.astype(np.complex64)\n",
        "\n",
        "filter_bank = get_v1_filter_bank(0, display_filters=True)\n",
        "\n",
        "\n",
        "def apply_filter_bank(input_image, filter_bank):\n",
        "    \"\"\"\n",
        "    Input image should have dimensions <h, w> or <s, o, h, w> or <b, s, o, h, w, d>.\n",
        "    Filter bank should have dimensions <s, o, h, w>\n",
        "    \"\"\"\n",
        "    bdsohw_input_image = input_image[None, None, None, None, :, :]\n",
        "\n",
        "    # pad image to filter size, which is 2*box_height, 2*box_width (to prevent too much wrapping)\n",
        "    padded_input = tf.pad(bdsohw_input_image, [[0, 0], [0, 0], [0, 0], [0, 0],\n",
        "                            [int(np.ceil(box_height / 2)), int(box_height / 2)],\n",
        "                            [int(np.ceil(box_width / 2)), int(box_width / 2)]], mode='CONSTANT')\n",
        "\n",
        "    input_in_freqdomain = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(padded_input, tf.zeros_like(padded_input))))\n",
        "\n",
        "    padded_result = tf.signal.ifft2d(input_in_freqdomain * filter_bank[None, None, :, :, :, :])\n",
        "\n",
        "    presult = tf.signal.fftshift(padded_result[0, 0, :, :, :, :], [2, 3])\n",
        "\n",
        "    return presult[:, :, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                        int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hbbp_6ap8LP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Render glyphs\n",
        "\n",
        "def get_glyph_image(glyph_char):\n",
        "    \"\"\"Returns a np.array of shape [box_height, box_width] containing the glyph at the center.\"\"\"\n",
        "    return f.glyph(glyph_char).as_matrix(normalize=True).with_padding_to_constant_box_width(box_width).astype(np.float32)\n",
        "\n",
        "def get_glyph_ink_width(glyph_char):\n",
        "    \"\"\"Returns the width of the rendered glyph in pixels.\"\"\"\n",
        "    return f.glyph(glyph_char).ink_width\n",
        "\n",
        "def get_v1_response(glyph_image):\n",
        "    \"\"\"Returns a np.array of shape [n_v1_scales, n_v1_orientations, box_height, box_width] and type complex64,\n",
        "    containing the local responses to the V1 filter bank (after inverse Fourier transform, i.e. in the spatial domain).\"\"\"\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "        filtered = apply_filter_bank(glyph_image, filter_bank)\n",
        "    return filtered\n",
        "\n",
        "glyph_images = {c: get_glyph_image(c) for c in tqdm(glyph_char_list)}\n",
        "print(\"  ✓\", len(glyph_char_list), \"glyphs rendered.\", flush=True)\n",
        "glyph_ink_widths = {c: get_glyph_ink_width(c) for c in tqdm(glyph_char_list)}\n",
        "print(\"  ✓\", len(glyph_char_list), \"glyphs measured.\", flush=True)\n",
        "glyph_v1_responses = {c: get_v1_response(glyph_images[c]) for c in tqdm(glyph_char_list)}\n",
        "print(\"  ✓\", len(glyph_char_list), \"glyphs filtered.\", flush=True)\n",
        "\n",
        "# 1a. Show an example of filtered glyphs\n",
        "for si in range(n_v1_scales):\n",
        "    print(\"Scale:\", si)\n",
        "    plt.imshow(glyph_images[\"b\"], cmap=\"gray\")\n",
        "    plt.imshow(np.sum(np.abs(glyph_v1_responses[\"b\"][si, :, :, :]), (0))**2, cmap=\"Reds\", alpha=0.7)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "# 2. Assemble pairs\n",
        "\n",
        "def get_pair_translations(char1, char2, distance_deltas, distance_factors=None):\n",
        "    \"\"\"Returns two 1D arrays of distances (in pixels) by which the left and right glyph need to be translated (i.e. shifted horizontally)\n",
        "    in order to place the two glyphs at the desired distances.\n",
        "    \n",
        "    Example: distance_deltas = [-2, 0, 2] or distance_factors=[0.7, 1.0, 1.5]\n",
        "    \"\"\"\n",
        "\n",
        "    optimal_distance = int(f.pair_distance(char1, char2) + f.minimum_ink_distance(char1, char2))\n",
        "\n",
        "    if distance_factors is None:\n",
        "        if distance_deltas is None:\n",
        "            raise ValueError(\"Must provide either distance_deltas or distance_factors\")\n",
        "        \n",
        "        sample_distances = optimal_distance + np.array(distance_deltas)\n",
        "    else:\n",
        "        if distance_deltas is not None:\n",
        "            raise ValueError(\"Must provide either distance_deltas or distance_factors, not both\")\n",
        "\n",
        "        sample_distances = optimal_distance * np.array(distance_factors)\n",
        "\n",
        "    total_width_at_minimum_ink_distance = glyph_ink_widths[char1] + glyph_ink_widths[char2] - f.minimum_ink_distance(char1, char2)\n",
        "    total_ink_width = glyph_ink_widths[char1] + glyph_ink_widths[char2]\n",
        "    ink_width_left = np.floor(total_ink_width / 4)\n",
        "    ink_width_right = np.ceil(total_ink_width / 4)\n",
        "    sample_distances_left = np.ceil(sample_distances / 2)\n",
        "    sample_distances_right = np.floor(sample_distances / 2)\n",
        "\n",
        "    left_translations = (-(np.ceil(total_width_at_minimum_ink_distance/2) + sample_distances_left) - (-ink_width_left)).astype(np.int32)\n",
        "    right_translations = ((np.floor(total_width_at_minimum_ink_distance/2) + sample_distances_right) - ink_width_right).astype(np.int32)\n",
        "    \n",
        "    return (left_translations, right_translations)\n",
        "    \n",
        "left_images = []\n",
        "right_images = []\n",
        "left_v1_responses = []\n",
        "right_v1_responses = []\n",
        "left_translations = []\n",
        "right_translations = []\n",
        "\n",
        "for c1 in tqdm(glyph_char_list):\n",
        "    for c2 in reversed(glyph_char_list):\n",
        "        left_images.append(glyph_images[c1])\n",
        "        right_images.append(glyph_images[c2])\n",
        "        left_v1_responses.append(glyph_v1_responses[c1])\n",
        "        right_v1_responses.append(glyph_v1_responses[c2])\n",
        "\n",
        "        lt, rt = get_pair_translations(c1, c2, sample_distance_deltas) #, sample_distance_factors)\n",
        "        left_translations.append(lt)\n",
        "        right_translations.append(rt)\n",
        "\n",
        "print(\"  ✓\", len(glyph_char_list)**2, \"pairs assembled.\")\n",
        "\n",
        "# 3. Set up generator to yield pairs, and wrap generator in a tf.Dataset\n",
        "\n",
        "def return_pair():\n",
        "    i = 0\n",
        "    while i < len(left_images):\n",
        "        yield {\n",
        "            \"left_image\": left_images[i],\n",
        "            \"right_image\": right_images[i],\n",
        "            \"left_v1_response\": left_v1_responses[i],\n",
        "            \"right_v1_response\": right_v1_responses[i],\n",
        "            \"left_translations\": left_translations[i],\n",
        "            \"right_translations\": right_translations[i],\n",
        "        }\n",
        "        i = (i + 1) % len(left_images)\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "     return_pair,\n",
        "     {\n",
        "      \"left_image\": tf.float32,\n",
        "      \"right_image\": tf.float32,\n",
        "      \"left_v1_response\": tf.complex64,\n",
        "      \"right_v1_response\": tf.complex64,#\n",
        "      \"left_translations\": tf.int32,\n",
        "      \"right_translations\": tf.int32,\n",
        "     },\n",
        "     {\n",
        "      \"left_image\": tf.TensorShape([box_height, box_width]),\n",
        "      \"right_image\": tf.TensorShape([box_height, box_width]),\n",
        "      \"left_v1_response\": tf.TensorShape([n_v1_scales, n_v1_orientations, box_height, box_width]),\n",
        "      \"right_v1_response\": tf.TensorShape([n_v1_scales, n_v1_orientations, box_height, box_width]),\n",
        "      \"left_translations\": tf.TensorShape([n_sample_distances,]),\n",
        "      \"right_translations\": tf.TensorShape([n_sample_distances,])\n",
        "     },\n",
        ")\n",
        "\n",
        "print(\"\\n  ✓ Dataset ready.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-LYhZo_riZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. Apply horizontal translations in the dataset\n",
        "\n",
        "def translate_4d_image(input_image, translations):\n",
        "    \"\"\"Shifts images to left/right and back-fills with zeros.\n",
        "    @param image: <sizes, orientations, height, width>\n",
        "    @param translations: <len(translations)>\n",
        "    @output        <len(translations), sizes, orientations, height, width>\n",
        "    \"\"\"\n",
        "\n",
        "    images = tf.tile(input_image[:, :, :, :, None], [1, 1, 1, 1, translations.shape[0]]) # create len(shifts) channel copies\n",
        "    fill_constant = 0\n",
        "    left = tf.maximum(0, tf.reduce_max(translations)) # positive numbers are shifts to the right, for which we need to add zeros on the left\n",
        "    right = -tf.minimum(0, tf.reduce_min(translations)) # negative numbers are shifts to the left, for which we need to add zeros on the right\n",
        "    left_mask = tf.ones(shape=(tf.shape(images)[0], tf.shape(images)[1], tf.shape(images)[2], left, tf.shape(images)[4]), dtype=images.dtype) * fill_constant\n",
        "    right_mask = tf.ones(shape=(tf.shape(images)[0], tf.shape(images)[1], tf.shape(images)[2], right, tf.shape(images)[4]), dtype=images.dtype) * fill_constant\n",
        "    padded_images = tf.concat([left_mask, images, right_mask], axis=3) # pad on axis 3 (i.e. width-wise)\n",
        "\n",
        "    # Now that the images are all padded, we need to crop them to implement the shifts.\n",
        "    def crop_image_widthwise(image_and_shift):\n",
        "        image = image_and_shift[0] # sohw\n",
        "        shift = image_and_shift[1] # \n",
        "        return image[:, :, :, left-shift:left-shift+input_image.shape[3]] # positive shift: left-shift\n",
        "\n",
        "    result = tf.map_fn(\n",
        "        crop_image_widthwise,\n",
        "        (tf.einsum(\"sohwd->dsohw\", padded_images), translations),\n",
        "        dtype=images.dtype)\n",
        "\n",
        "    # Manually ensure that the width-dimension hasn't changed\n",
        "    s = list(result.shape)\n",
        "    s[-1] = box_width\n",
        "    result.set_shape(s)\n",
        "\n",
        "    return result\n",
        "\n",
        "def apply_translations(d):\n",
        "    d[\"left_image\"] = translate_4d_image(d[\"left_image\"][None, None, :, :], d[\"left_translations\"])[:, 0, 0, :, :]\n",
        "    d[\"right_image\"] = translate_4d_image(d[\"right_image\"][None, None, :, :], d[\"right_translations\"])[:, 0, 0, :, :]\n",
        "    d[\"left_v1_response\"] = translate_4d_image(d[\"left_v1_response\"], d[\"left_translations\"])\n",
        "    d[\"right_v1_response\"] = translate_4d_image(d[\"right_v1_response\"], d[\"right_translations\"])\n",
        "    del d[\"left_translations\"]\n",
        "    del d[\"right_translations\"]\n",
        "    return (d, 0.)  # The zero here doesn't do anything and is just to make Keras happy, because model.fit expects a dataset of 2-tuples where the second entry is the target value.\n",
        "\n",
        "translated_dataset = dataset.map(apply_translations)\n",
        "\n",
        "print(\"dataset shapes:\", translated_dataset.element_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qo5aVMk3sRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5. Utility functions\n",
        "eps = np.finfo(np.float32).tiny\n",
        "\n",
        "def invspa(t):\n",
        "    return np.log(np.exp(t) - 1).astype(np.float32)\n",
        "\n",
        "def invsp(t):\n",
        "    if t == 0:\n",
        "        return -1e10\n",
        "    else:\n",
        "        return np.log(np.exp(t) - 1).astype(np.float32)\n",
        "\n",
        "def sp(t):\n",
        "    return tf.nn.softplus(t)\n",
        "\n",
        "# 6. Generating G-cell fragments\n",
        "\n",
        "u, v = np.mgrid[-box_height:box_height,-box_width:box_width].astype(np.float32)\n",
        "u = u / (box_width)\n",
        "v = v / (box_width)\n",
        "r = np.sqrt(u**2 + v**2)[None, None, :, :]\n",
        "angle = np.arctan2(u, v)[None, None, :, :] # <b, d, s, o, c, h, w>\n",
        "angles = np.arange(n_v1_orientations)[:, None, None, None].astype(np.float32)/n_v1_orientations\n",
        "angle_mask_widths = 4. * np.ones((n_v1_orientations, n_v4_scales)).astype(np.float32)\n",
        "\n",
        "def make_v4_filters(k, spa, sn, hp, hn, cp, cn): # Returns masks of shape <o, c, h, w>\n",
        "    #p_mask_1 = tf.exp(-(r-sp(cp[None,:,None, None]))**2 / sp(spa[None, :, None, None])) * sp(hp[None, :, None, None])\n",
        "    #p_mask_2 = tf.exp(-(-r-sp(cp[None, :, None, None]))**2 / sp(spa[None, :, None, None])) * sp(hp[None, :, None, None])\n",
        "    #p_logmask = tfp.distributions.LogNormal(cp[None, :, None, None], spa[None, :, None, None], validate_args=True, allow_nan_stats=False).prob(r+eps)\n",
        "    #n_mask_1 = tf.exp(-(r-sp(cn[None, :, None, None]))**2 / sp(sn[None, :, None, None])) * sp(hn[None, :, None, None])\n",
        "    #n_mask_2 = tf.exp(-(-r-sp(cn[None, :, None, None]))**2 / sp(sn[None, :, None, None])) * sp(hn[None, :, None, None])\n",
        "\n",
        "    x_n = n_v4_scales + 2\n",
        "    \n",
        "    xs = tf.linspace(cp, 1, x_n) ** k * cn # k can be one or above (or below)\n",
        "    \n",
        "    a = xs[:-2][None, :, None, None]\n",
        "    c = xs[1:-1][None, :, None, None]\n",
        "    b = xs[2:][None, :, None, None]\n",
        "    \n",
        "    triangles = tf.zeros((n_v1_orientations, n_v4_scales, box_height, box_height))\n",
        "    \n",
        "    triangles = tf.where(tf.reduce_all([r > a, r <= c], axis=0), 2*(r-a)/((b-a)*(c-a)),\n",
        "                        tf.where(tf.reduce_all([r > c, r < b], axis=0), 2*(b-r)/((b-a)*(b-c)), 0))\n",
        "\n",
        "    radial_mask = triangles\n",
        "\n",
        "    #flat_indices = tf.reshape((r * box_width).astype(np.int), [4 * box_height * box_width])\n",
        "    #radial_mask = tf.reshape(tf.gather(sp(k), flat_indices), [1, 1, 2 * box_height, 2*box_width])\n",
        "\n",
        "    # Uses von-Mises distribution (via Bessel function)\n",
        "    bp_angle_masks = tf.exp(-angle_mask_widths[:, :, None, None] * tf.cos(angle - pi - pi * angles)) / (2*pi*tf.math.bessel_i0(angle_mask_widths[:, :, None, None]))\n",
        "    bn_angle_masks = tf.exp(-angle_mask_widths[:, :, None, None] * tf.cos(angle - pi * angles)) / (2*pi*tf.math.bessel_i0(angle_mask_widths[:, :, None, None]))\n",
        "\n",
        "    bp_masks = radial_mask * bp_angle_masks\n",
        "    bn_masks = radial_mask * bn_angle_masks\n",
        "\n",
        "    # Each bp/bn_mask fragment (the positive part) should add up to exactly one.\n",
        "    bp_masks_normed = 4*bp_masks / (eps + tf.reduce_sum((bp_masks)**2, [0, 2, 3], keepdims=True))\n",
        "    bn_masks_normed = 4*bn_masks / (eps + tf.reduce_sum((bn_masks)**2, [0, 2, 3], keepdims=True))\n",
        "\n",
        "    return tf.concat([bp_masks_normed, bn_masks_normed], axis=0)\n",
        "\n",
        "\n",
        "# 7. V4 layer\n",
        "class V4Layer(tf.keras.layers.Layer):\n",
        "    def __init__(self, skip_v4_convolution=False, **kwargs):\n",
        "        super(V4Layer, self).__init__(**kwargs)\n",
        "\n",
        "        self.skip_v4_convolution = skip_v4_convolution\n",
        "\n",
        "        self.csf = self.add_weight(shape=((n_v1_scales, n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(np.array([3, 15, 25, 3, 1])[:, None], [1, n_v1_orientations]).astype(np.float32) / 200.),\n",
        "                                 name=\"csf\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.v1_hra_k = self.add_weight(shape=((n_v1_scales, n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([2.,2.,2.,2.,2.])[:, None], [1, n_v1_orientations])), # 1 to .02\n",
        "                                 name=\"v1_hra_k\",\n",
        "                                 trainable=True)\n",
        "        self.v1_hra_b = self.add_weight(shape=((n_v1_scales, n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([.5,.5,.5,.5,.5])[:, None], [1, n_v1_orientations])), # 1 to .02\n",
        "                                 name=\"v1_hra_b\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        #self.v4_scales_exponent = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(1.5), name=\"v4_scales_exponent\", trainable=False)\n",
        "        #self.v4_scales_min = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(.54), name=\"v4_scales_min\", trainable=False)\n",
        "        #self.v4_scales_factor = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(0.75), name=\"v4_scales_factor\", trainable=False)\n",
        "#\n",
        "        #self.v4_widths_exponent = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(1.5), name=\"v4_widths_exponent\", trainable=False)\n",
        "        #self.v4_widths_min = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(.6), name=\"v4_widths_min\", trainable=False)\n",
        "        #self.v4_widths_factor = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(0.2), name=\"v4_widths_factor\", trainable=False)\n",
        "#\n",
        "        #self.v4_depression_scale_fraction = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(np.array([0.3, .3, .3, .3, .3]).astype(np.float32)), name=\"v4_depression_scale_fraction\", trainable=True)\n",
        "        #self.v4_inner_negative_depth = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(np.array([1.,1.,1.,1.,1.]).astype(np.float32)), name=\"v4_inner_negative_depth\", trainable=True)\n",
        "\n",
        "        # How far away from the center we are\n",
        "        #self.v4_cp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.0125, 0.016, 0.021, 0.03, 0.056, 0.08, .12, .2]).astype(np.float32))), name=\"v4_cp\", trainable=True)\n",
        "        #self.v4_cn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.0125, 0.016, 0.021, 0.03, 0.056, 0.08, .12, .2]).astype(np.float32) * 0.16)), name=\"v4_cn\", trainable=True)\n",
        "        self.v4_cp = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(0.2), name=\"v4_cp\", trainable=False)\n",
        "        self.v4_cn = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(0.25), name=\"v4_cn\", trainable=False)\n",
        "        # How wide the rims are\n",
        "        self.v4_sp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.00015, 0.00026, 0.00057, 0.00109, .00216, .0036, .0060, .0097]).astype(np.float32))), name=\"v4_sp\", trainable=True)\n",
        "        self.v4_sn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.00015, 0.00026, 0.00057, 0.00109, .00216, .0036, .0060, .0097]).astype(np.float32) * .25)), name=\"v4_sn\", trainable=True)\n",
        "        # How deep the rims are\n",
        "        self.v4_hp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([.8, .8, .8, .8, .8, .8, .8, .8]).astype(np.float32))), name=\"v4_hp\", trainable=True)\n",
        "        self.v4_hn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([.4, .4, .4, .4, .4, .4, .4, .4]).astype(np.float32)*4.)), name=\"v4_hn\", trainable=True)\n",
        "\n",
        "        #self.v4_cp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.03]).astype(np.float32))), name=\"v4_cp\", trainable=True)\n",
        "        #self.v4_cp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(np.array([-3]).astype(np.float32)), name=\"v4_cp\", trainable=True)\n",
        "        #self.v4_cn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.03]).astype(np.float32))), name=\"v4_cn\", trainable=True)\n",
        "        ## How wide the rims are\n",
        "        ##self.v4_sp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.00109]).astype(np.float32))), name=\"v4_sp\", trainable=True)\n",
        "        #self.v4_sp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(np.array([.2]).astype(np.float32)), name=\"v4_sp\", trainable=True)\n",
        "        #self.v4_sn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.00109]).astype(np.float32))), name=\"v4_sn\", trainable=True)\n",
        "        ## How deep the rims are\n",
        "        #self.v4_hp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([.8]).astype(np.float32))), name=\"v4_hp\", trainable=True)\n",
        "        #self.v4_hn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([.4]).astype(np.float32)*4.)), name=\"v4_hn\", trainable=True)\n",
        "\n",
        "        self.kk = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(2.80), name=\"v4_kk\", trainable=True)\n",
        "\n",
        "        #self.v4_scales = self.add_weight(shape=(n_v4_scales),\n",
        "        #                              initializer=tf.keras.initializers.Constant(np.array([.4,1.1,2.1,4.0,7.5]).astype(np.float32)/box_width),\n",
        "        #                              #initializer=tf.keras.initializers.Constant(np.array([1.4,1.6,1.75,1.83,1.9]).astype(np.float32)),\n",
        "        #                              name=\"v4_scales\", trainable=False)\n",
        "        #self.v4_widths = self.add_weight(shape=(n_v4_scales),\n",
        "        #                                    initializer=tf.keras.initializers.Constant(np.array([.5,0.7,1.,1.7,3.8]).astype(np.float32)/box_width),\n",
        "        #                                    #initializer=tf.keras.initializers.Constant(np.array([1.4,1.25,1.15,1.03,.98]).astype(np.float32)),\n",
        "        #                                    name=\"v4_widths\", trainable=False)\n",
        "        self.v4_angle_mask_widths = self.add_weight(shape=(n_v1_orientations, n_v4_scales),\n",
        "                                                 initializer=tf.keras.initializers.Constant(4.),\n",
        "                                                 name=\"v4_angle_mask_widths\", trainable=False)\n",
        "        self.v4_filter_strengths = self.add_weight(shape=(n_v1_orientations, n_v4_scales),\n",
        "                                               initializer=tf.keras.initializers.Constant(1.),\n",
        "                                               name=\"v4_filter_strengths\", trainable=False)\n",
        "\n",
        "        self.v4_hra_k = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4])[None, :], [2*n_v1_orientations, 1])),\n",
        "                                 #initializer=tf.keras.initializers.Constant(np.tile(invsp([1.4])[None, :], [2*n_v1_orientations, 1])),\n",
        "                                 name=\"v4_hra_k\",\n",
        "                                 trainable=True)\n",
        "        self.v4_hra_b = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([1.5,3,2,1,1, 1,1,1])[None, :], [2*n_v1_orientations, 1])),\n",
        "                                 #initializer=tf.keras.initializers.Constant(np.tile(invsp([1])[None, :], [2*n_v1_orientations, 1])),\n",
        "                                 name=\"v4_hra_b\",\n",
        "                                 trainable=True)\n",
        "\n",
        "\n",
        "        # Each ring should only be able to draw from \n",
        "        self.v1_v4_scale_weights = self.add_weight(shape=(n_v1_scales, n_v4_scales),\n",
        "                                 #initializer=tf.keras.initializers.Constant((eps + np.triu(np.ones((n_v1_scales, n_v4_scales))).astype(np.float32) * .5**toeplitz(np.zeros(n_v1_scales), np.arange(n_v4_scales)))),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.ones((n_v1_scales, n_v4_scales)).astype(np.float32)),\n",
        "                                 #initializer=tf.keras.initializers.Constant(np.array([1])[None, :].astype(np.float32)),\n",
        "                                 name=\"v1_v4_scale_weights\",\n",
        "                                 trainable=True)\n",
        "        self.v1_v4_orientation_weights = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"v1_v4_orientation_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.v4_b_scale_weights = self.add_weight(shape=(1, n_v4_scales),\n",
        "                                 #initializer=tf.keras.initializers.Constant((eps + np.triu(np.ones((n_v1_scales, n_v4_scales))).astype(np.float32) * .5**toeplitz(np.zeros(n_v1_scales), np.arange(n_v4_scales)))),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"v4_b_scale_weights\",\n",
        "                                 trainable=True)\n",
        "        self.v4_b_orientation_weights = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"v4_b_orientation_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.g_hra_k = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.array([2.4, 2.4, 2.4, 2.4, 2.4, 2.4, 2.4, 2.4])),\n",
        "                                 name=\"g_hra_k\",\n",
        "                                 trainable=True)\n",
        "        self.g_hra_b = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(0.4 ** (2.4 * np.arange(n_v4_scales).astype(np.float32))),\n",
        "                                 #initializer=tf.keras.initializers.Constant(invsp([.4]).astype(np.float32)),\n",
        "                                 name=\"g_hra_b\",\n",
        "                                 trainable=True)\n",
        "\n",
        "\n",
        "        #g_scale_scores = self.g_scale_score_factor ** (sp(self.g_hra_k) * np.arange(n_v4_scales).astype(np.float32))\n",
        "\n",
        "        self.g_scale_score_factor = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(0.4),\n",
        "                                 name=\"g_scale_score_factor\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.feedback_modulation_strength = self.add_weight(shape=(1, 2*n_v1_orientations, 1, 1),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.)),\n",
        "                                 name=\"feedback_modulation_strength\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.b_dn_b = self.add_weight(shape=(1, 2*n_v1_orientations),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(0.25)),\n",
        "                                 name=\"b_dn_b\",\n",
        "                                 trainable=True)\n",
        "        self.b_dn_k = self.add_weight(shape=(1, 2*n_v1_orientations),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(2.2)),\n",
        "                                 name=\"b_dn_k\",\n",
        "                                 trainable=True)\n",
        "        self.b_dn_k_pool = self.add_weight(shape=(1, 2*n_v1_orientations),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(3.9)),\n",
        "                                 name=\"b_dn_k_pool\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        # We would want the normalization pool to mostly include, for each size/orientation, the opposite orientation.\n",
        "        # We would also want to include smaller sizes. But perhaps that's not so important?\n",
        "\n",
        "        basic_dn_matrix = np.zeros((1, 2*n_v1_orientations, 1, 2*n_v1_orientations)).astype(np.float32)\n",
        "\n",
        "        # The first ones are the ones that count towards the second\n",
        "        for s1 in range(1):\n",
        "            for o1 in range(2*n_v1_orientations):\n",
        "                for s2 in range(1):\n",
        "                    for o2 in range(2*n_v1_orientations):\n",
        "                        s_distance = np.exp(-(s1 - s2)**2)\n",
        "                        basic_dn_matrix[s1, o1, s2, o2] = s_distance\n",
        "\n",
        "        self.b_dn_weights = self.add_weight(shape=((1, 2*n_v1_orientations, 1, 2*n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(invspa(basic_dn_matrix.astype(np.float32))),\n",
        "                                 name=\"b_dn_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.g_dn_b = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.5)),\n",
        "                                 name=\"g_dn_b\",\n",
        "                                 trainable=True)\n",
        "        self.g_dn_k = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(2.2)),\n",
        "                                 name=\"g_dn_k\",\n",
        "                                 trainable=True)\n",
        "        self.g_dn_k_pool = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.5)),\n",
        "                                 name=\"g_dn_k_pool\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        # We would want the normalization pool to mostly include, for each size/orientation, the opposite orientation.\n",
        "        # We would also want to include smaller sizes. But perhaps that's not so important?\n",
        "\n",
        "        basic_g_dn_matrix = np.zeros((n_v4_scales, n_v4_scales)).astype(np.float32)\n",
        "\n",
        "        # The first ones are the ones that count towards the second\n",
        "        for s1 in range(n_v4_scales):\n",
        "            for s2 in range(n_v4_scales): # the smaller ones should always suppress the bigger ones\n",
        "                s_distance = 1. if s1 <= s2 else 0.0001\n",
        "                basic_g_dn_matrix[s1, s2] = s_distance\n",
        "\n",
        "        self.g_dn_weights = self.add_weight(shape=((n_v4_scales, n_v4_scales)),\n",
        "                                 initializer=tf.keras.initializers.Constant(invspa(basic_g_dn_matrix.astype(np.float32))),\n",
        "                                 name=\"g_dn_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "\n",
        "\n",
        "    def get_v4_scales(self):\n",
        "        return (tf.nn.relu(eps + tf.range(0, n_v4_scales * self.v4_scales_factor, self.v4_scales_factor) + self.v4_scales_min) ** tf.nn.relu(eps + self.v4_scales_exponent)) / box_width\n",
        "\n",
        "    def get_v4_widths(self):\n",
        "        return (tf.nn.relu(eps + tf.range(0, n_v4_scales * self.v4_widths_factor, self.v4_widths_factor) + self.v4_widths_min) ** tf.nn.relu(eps + self.v4_widths_exponent)) / box_width\n",
        "\n",
        "    def print_weights(self):\n",
        "        print(\"CSF\")\n",
        "        plt.imshow(self.csf.numpy())\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        print(\"HRA parameters:\")\n",
        "        print(\"---------\")\n",
        "        print(\"V1 (scales/orientations) exponents [k] and half-points [b]\")\n",
        "        plt.imshow(sp(self.v1_hra_k))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        plt.imshow(sp(self.v1_hra_b))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"G (scales/orientations) exponents [k] and half-points [b]\")\n",
        "        print(sp(self.g_hra_k))\n",
        "        print(sp(self.g_hra_b))\n",
        "        plt.plot(sp(self.g_hra_k))\n",
        "        plt.show()\n",
        "        plt.plot(sp(self.g_hra_b))\n",
        "        plt.show()\n",
        "\n",
        "        print(\"M\")\n",
        "        #v4_filters = (make_v4_filters(self.get_v4_scales(), self.get_v4_widths(), self.v4_angle_mask_widths, self.v4_depression_scale_fraction, self.v4_inner_negative_depth))[None, None, None, ...]\n",
        "        v4_filters = make_v4_filters(self.kk, self.v4_sp, self.v4_sn, self.v4_hp, self.v4_hn, self.v4_cp, self.v4_cn)[None, None, None, ...]\n",
        "        print(self.v4_sp.numpy(), self.v4_hp.numpy(), self.v4_cp.numpy())\n",
        "        for i in range(n_v4_scales):\n",
        "            plt.imshow(tf.reduce_sum(v4_filters[0, 0, 0, :, i, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                            int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))], [0]))\n",
        "            plt.colorbar()\n",
        "            plt.show()\n",
        "\n",
        "        #print(\"SCALES, WIDTHS, STRENGHTS\", self.get_v4_scales().numpy(), \"ORIGINALSTRENGHTS\", self.v4_scales.numpy(), \"\\n WIDTHS\", self.get_v4_widths().numpy(), \"ORIGINALWIDTHS\", self.v4_widths.numpy(), \"\\n\", self.v4_filter_strengths.numpy())\n",
        "\n",
        "        print(\"Forward linking matrix:\")\n",
        "        print(\"Scale weights:\")\n",
        "        plt.imshow(self.v1_v4_scale_weights[:, :])\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        print(\"Orientation weights:\")\n",
        "        plt.imshow(self.v1_v4_orientation_weights[: ,:])\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"BDN exponents: upper k:\", sp(self.b_dn_k).numpy(), \"pool k:\", sp(self.b_dn_k_pool).numpy())\n",
        "        print(\"BDN exponents, b:\", sp(self.b_dn_b).numpy())\n",
        "        print(\"BDN Weights (size 2):\")\n",
        "        plt.imshow(sp(self.b_dn_weights)[0, :, 0, :])\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"GDN exponents: upper k:\", sp(self.g_dn_k).numpy(), \"pool k:\", sp(self.g_dn_k_pool).numpy())\n",
        "        print(\"GDN exponents, b:\", sp(self.g_dn_b).numpy())\n",
        "        print(\"GDN Weights (size 2):\")\n",
        "        plt.imshow(sp(self.g_dn_weights)[:, :])\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "        g_scale_scores = self.g_scale_score_factor ** (sp(self.g_hra_k) * np.arange(n_v4_scales).astype(np.float32))\n",
        "        print(\"G scale scores\", g_scale_scores.numpy())\n",
        "\n",
        "\n",
        "    def hra_v1(self, i):\n",
        "        return i\n",
        "        k = sp(self.v1_hra_k[None, None, :, :, None, None])\n",
        "        b = sp(self.v1_hra_b[None, None, :, :, None, None])\n",
        "        return ((i + eps) ** k) / (eps + b**k + (i + eps) ** k)\n",
        "        # We need to ensure that whatever comes out of v1 is scaled.\n",
        "        # The point of V1 scaling is that complex cells respond nonlinearly in real life; such that\n",
        "        # e.g. stems are active in the center, and not as much on the outside.\n",
        "        # But we need to ensure that total energy is kept the same, and simply redistributed.\n",
        "        # Question is whether there is a way to normalize this.\n",
        "\n",
        "    def hra_v4(self, i):\n",
        "        return i\n",
        "        k = sp(self.v4_hra_k[None, None, :, :, None, None])\n",
        "        b = sp(self.v4_hra_b[None, None, :, :, None, None])\n",
        "        return ((i + eps) ** k) # / (eps + b**k + (i + eps) ** k)\n",
        "\n",
        "    def hra_g(self, i):\n",
        "        k = sp(self.g_hra_k) #sp(self.g_hra_k[None, None, :, None, None])\n",
        "        b = sp(self.g_hra_b[None, None, :, None, None])\n",
        "        return ((i + eps) ** k) #/ (eps + b**k + (i + eps) ** k)\n",
        "\n",
        "    def score_g(self, i):\n",
        "        # We get [b, d, c, h, w], and for each c we want to have a quadratic equation\n",
        "\n",
        "\n",
        "        return (self.g_hra_b[None, None, :, None, None] * i ** self.g_hra_k[None, None, :, None, None])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        v1c = self.hra_v1(tf.abs(inputs)) #* tf.nn.relu(self.csf[None, None, :, :, None, None]) / (eps + tf.reduce_sum(tf.nn.relu(self.csf))), [2], keepdims=True) # should end up with just a single scale.\n",
        "    \n",
        "        b_balanced = tf.pad(tf.concat([v1c]*2, axis=3), [[0, 0], [0, 0], [0, 0], [0, 0],\n",
        "                                [int(np.ceil(box_height / 2)), int(box_height / 2)],\n",
        "                                [int(np.ceil(box_width / 2)), int(box_width / 2)]], mode='CONSTANT')\n",
        "        \n",
        "        b_balanced_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(b_balanced, 0.), [4, 5]))\n",
        "\n",
        "        v4_filters = make_v4_filters(self.kk, self.v4_sp, self.v4_sn, self.v4_hp, self.v4_hn, self.v4_cp, self.v4_cn)[None, None, None, ...]\n",
        "        \n",
        "        v4_filters_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(v4_filters, 0.), [5, 6]))\n",
        "        \n",
        "        v4_activations_0_by_s_o = tf.nn.relu(tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(v4_filters_fft * b_balanced_fft[:, :, :, :, None, :, :]), [5, 6])))\n",
        "        \n",
        "        v4_activations_0 = self.hra_v4(tf.einsum(\"bdsochw,sc->bdochw\", v4_activations_0_by_s_o, eps + tf.nn.relu(self.v1_v4_scale_weights) / (eps + tf.reduce_sum(tf.nn.relu(self.v1_v4_scale_weights))) )) # hra_v4\n",
        "        \n",
        "        G_0 = tf.einsum(\"bdochw,oc->bdchw\", v4_activations_0, tf.nn.relu(self.v1_v4_orientation_weights) / (eps + tf.reduce_mean(tf.nn.relu(self.v1_v4_orientation_weights), axis=[0], keepdims=True) ))\n",
        "\n",
        "        return G_0[:, :, None, None, :, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                              int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))] #* g_scale_scores[None, None, None, None, :, None, None]\n",
        "\n",
        "\n",
        "# 8. Cost layer\n",
        "class TargetStrengthLayer(tf.keras.layers.Layer): # These are like the V1 complex edges\n",
        "    def __init__(self, **kwargs):\n",
        "        super(TargetStrengthLayer, self).__init__(**kwargs)\n",
        "        # <b, s, o, h, w, d>\n",
        "        self.target_strength = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(.005),\n",
        "                                 name=\"target_strength\",\n",
        "                                 trainable=True)  \n",
        "    def print_weights(self):\n",
        "        print(\"Target strength:\", self.target_strength.numpy())\n",
        "\n",
        "    def call(self, inputs):\n",
        "         return (inputs - self.target_strength) ** 2\n",
        "\n",
        "\n",
        "# 8. Cost layer\n",
        "class CostLayer(tf.keras.layers.Layer): # These are like the V1 complex edges\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CostLayer, self).__init__(**kwargs)\n",
        "        # <b, s, o, h, w, d>\n",
        "        self.wp = self.add_weight(shape=(n_v4_scales), # Penalties for Losses\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp([4.0, 3.1, 1.53, 0.1, 0.01, 0.01, 0.01, 0.01])),\n",
        "                                 #initializer=tf.keras.initializers.Constant(invsp([1.])),\n",
        "                                 name=\"wp\",\n",
        "                                 trainable=True)  \n",
        "        self.wn = self.add_weight(shape=(n_v4_scales), # Gains\n",
        "                                 initializer=tf.keras.initializers.Constant(np.array([0.03, 0.13, 0.3, 0.900, 0.800123, 0.1, 0.01, 0.001]).astype(np.float32)),\n",
        "                                 #initializer=tf.keras.initializers.Constant(np.array([.9]).astype(np.float32)),\n",
        "                                 name=\"wn\",\n",
        "                                 trainable=False)\n",
        "        self.penalty_exps = self.add_weight(shape=((1, 1, 1, 1, n_v4_scales, 1, 1)),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.0)),\n",
        "                                 name=\"penalty_exps\",\n",
        "                                 trainable=True)\n",
        "        self.reward_exps = self.add_weight(shape=((1, 1, 1, 1, n_v4_scales, 1, 1)),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.0)),\n",
        "                                 name=\"reward_exps\",\n",
        "                                 trainable=True)\n",
        "\n",
        "    def norm(self, i):\n",
        "        \"\"\"Normalize the weights.\n",
        "        This regularization is necessary to keep the optimizer from simply making the weights tiny.\"\"\"\n",
        "\n",
        "        v = tf.cumsum(sp(1e3*i)/1e3, axis=0, reverse=True)\n",
        "        #wpv = tf.reduce_sum(tf.cumsum(sp(1e3*self.wn)/1e3, axis=0, reverse=True) + tf.cumsum(sp(1e3*self.wp)/1e3, axis=0, reverse=True))\n",
        "        wpv = tf.reduce_sum(tf.abs(self.wn) + tf.abs(self.wp))\n",
        "        v = tf.nn.relu(i) + eps # sp(i)\n",
        "\n",
        "        return (tf.nn.relu(i)[None, None, None, None, :, None, None] / (eps + wpv))\n",
        "\n",
        "    def print_weights(self):\n",
        "        print(\"Rewards:\")\n",
        "        plt.plot(self.norm(self.wn)[0, 0, 0, 0, :, 0, 0])\n",
        "        plt.show()\n",
        "        print(\"Penalties:\")\n",
        "        plt.plot(self.norm(self.wp)[0, 0, 0, 0, :, 0, 0])\n",
        "        plt.show()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        penalties = tf.nn.relu(inputs) * self.norm(self.wp)  # Don't penalize for now\n",
        "\n",
        "        rewards = tf.nn.relu(-inputs) * self.norm(self.wn)  # Such that a very strong large grouping is equivalent to a medium-strong smaller grouping\n",
        "\n",
        "        #total_penalties = tf.reduce_sum((eps + tf.reduce_sum(penalties, [5, 6], keepdims=True)) ** sp(self.penalty_exps), [2, 3, 4, 5, 6])\n",
        "\n",
        "        #mean_rewards = (eps + tf.reduce_sum(rewards, [2,3,4,5,6])) / (eps + tf.reduce_sum(tf.nn.relu(-inputs), [2,3,4,5,6]))\n",
        "\n",
        "        #total_rewards_deviation = (eps + tf.abs(mean_rewards - self.desired_total_grouping))**sp(self.desired_total_grouping_deviation_exponent)\n",
        "\n",
        "        return (penalties, rewards) #, total_rewards_deviation, total_penalties, mean_rewards)\n",
        "\n",
        "# 9. Set up the actual math\n",
        "\n",
        "def get_pair_violation(left_v1_response, right_v1_response):\n",
        "    \"\"\"Runs the V1 responses through the V4 layer, weights the pair differences via the CostLayer,\n",
        "    and then returns the worst violation of the \"cost-must-be-lowest-for-optimal-distance\" principle\n",
        "    which is then passed to the optimizer.\"\"\"\n",
        "\n",
        "    # Feed V1 responses through the V4 layer\n",
        "    v4 = V4Layer(False)\n",
        "    left_v4_response = tf.identity(v4(tf.abs(left_v1_response)), \"left_v4_response\")\n",
        "    right_v4_response = tf.identity(v4(tf.abs(right_v1_response)), \"right_v4_response\")\n",
        "    pair_v4_response = tf.identity(v4(tf.abs(left_v1_response + right_v1_response)), \"pair_v4_response\")\n",
        "\n",
        "    # Compute gains and losses in V4 (of pair, relative to standalone letters).\n",
        "    #pair_diff = tf.identity(tf.math.log((left_v4_response + right_v4_response + eps) / (pair_v4_response + eps)), \"pair_diff\")\n",
        "    pair_diff = tf.identity(pair_v4_response - left_v4_response - right_v4_response , \"pair_diff\")\n",
        "\n",
        "    # When the pair response is stronger, (a gain), then the pair_diff is negative.\n",
        "\n",
        "    local_grouping_strength = tf.identity(tf.reduce_sum(tf.nn.relu(pair_diff) ** 2, axis=[2,3,4], keepdims=True) / tf.reduce_sum(tf.nn.relu(pair_diff), axis=[2,3,4,5,6], keepdims=True), \"grouping_local_strengths\")\n",
        "    # Now we take the active average of the scores\n",
        "    grouping_strength = tf.identity(tf.reduce_sum(local_grouping_strength, axis=[2,3,4,5,6]), \"grouping_strengths\")\n",
        "\n",
        "    # We now want to divide the pair_diff by the total amount of pair_diff.\n",
        "    # What's important to us in this particular expeirment is that we try to measure the average distance, not the overall distance.\n",
        "    # So we divide all responses by the overall responses. That way, the responses add up to one everywhere,\n",
        "    # and each response can contribute exactly its own scale.\n",
        "    #pair_diff_normalized = pair_diff / tf.reduce_sum(pair_diff, axis=[2,3,4,5,6], keepdims=True)\n",
        "\n",
        "    # When this is negative, the pair_v4_response was greater than before, so we gained something.\n",
        "\n",
        "    # We first want to find out the average scale of the gains. Then, based on the average scale minus the ideal scale, we want to minimize the difference. \n",
        "    # \n",
        "\n",
        "    # Compute penalty/reward values for each pair_diff\n",
        "    cost = CostLayer()\n",
        "    (pair_pixel_penalties, pair_pixel_rewards) = cost(pair_diff)\n",
        "    \n",
        "    pair_pixel_cost = tf.identity(pair_pixel_penalties - pair_pixel_rewards, \"pair_pixel_cost\")\n",
        "\n",
        "    # Sum over all channels and pixels to yield one total cost per <pair, sample_distance>\n",
        "    #total_pair_cost = tf.reduce_sum(pair_pixel_cost, [2,3,4,5,6], name=\"pair_total_cost\") \n",
        "\n",
        "    tsl = TargetStrengthLayer()\n",
        "\n",
        "    total_pair_cost = tf.identity(tsl(grouping_strength), \"pair_total_cost\")\n",
        "    #\n",
        "    # Find worst violation of the well\n",
        "    up_first_ness = (total_pair_cost[:, 1] - total_pair_cost[:, 0]) #[1,2,3,4,5,6]\n",
        "    down_second_ness = (total_pair_cost[:, 1] - total_pair_cost[:, 2]) # has shape <batch_size>, [2,3,4,5,6,7,]\n",
        "    worst_violation_sum = tf.reduce_mean(tf.nn.elu(tf.reduce_max(tf.stack([up_first_ness, down_second_ness], axis=0), axis=[0])), name=\"worst_violation\")\n",
        "\n",
        "    # What we are optimizing for, here, is that the medium point is lowest in its deviation from perfection.\n",
        "    # This probably makes sense.\n",
        "\n",
        "    # Both pair_pixel_penalties and pair_pixel_rewards should only get bigger with more proximity\n",
        "    #penalty_nonmonotonicity = tf.reduce_sum(tf.nn.relu(pair_total_penalties[:, 1:] - pair_total_penalties[:, 0:-1]))\n",
        "    #reward_nonmonotonicity = tf.reduce_sum(tf.nn.relu(pair_total_rewards[:, 1:] - pair_total_rewards[:, 0:-1]))\n",
        "\n",
        "    return worst_violation_sum \n",
        "\n",
        "# 10. Set up Keras model and run\n",
        "\n",
        "def get_keras_model():\n",
        "    # The translated raw images aren't used in the model, they're just for visualization purposes ...\n",
        "    left_image = tf.keras.Input(shape=(n_sample_distances, box_height, box_width), name='left_image')\n",
        "    right_image = tf.keras.Input(shape=(n_sample_distances, box_height, box_width), name='right_image')\n",
        "\n",
        "    # ... but the translated V1 responses are:\n",
        "    left_v1_response = tf.keras.Input(shape=(n_sample_distances, n_v1_scales, n_v1_orientations, box_height, box_width), name='left_v1_response', dtype=tf.complex64)\n",
        "    right_v1_response = tf.keras.Input(shape=(n_sample_distances, n_v1_scales, n_v1_orientations, box_height, box_width), name='right_v1_response', dtype=tf.complex64)\n",
        "\n",
        "    # This calls the V4 layer, the penalty/reward layer, and finds the max cost\n",
        "    total_violation = tf.identity(get_pair_violation(left_v1_response, right_v1_response), \"total_violation\")\n",
        "\n",
        "    return tf.keras.Model(inputs=[left_v1_response, right_v1_response, left_image, right_image], outputs=(total_violation))\n",
        "\n",
        "class MonitorProgressCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, dataset, interval):\n",
        "        self.dataset = dataset\n",
        "        self.interval = interval\n",
        "        self.current_data = None\n",
        "\n",
        "    def get_val(self, name):\n",
        "        l = [l for l in self.model.layers if l.name.find(name) >= 0][0]\n",
        "        output = tf.keras.backend.function(self.model.inputs, [l.output])([self.current_data[\"left_v1_response\"],\n",
        "                                                                           self.current_data[\"right_v1_response\"],\n",
        "                                                                           self.current_data[\"left_image\"],\n",
        "                                                                           self.current_data[\"right_image\"]])[0]\n",
        "        return output\n",
        "\n",
        "    def get_weights(self, name):\n",
        "        l = [l for l in self.model.layers if l.name.find(name) >= 0][0]\n",
        "        return l.get_weights()\n",
        "\n",
        "    def print_weights(self, name):\n",
        "        l = [l for l in self.model.layers if l.name.find(name) >= 0][0]\n",
        "        l.print_weights()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Only show this stuff every [interval] batches\n",
        "        if epoch % self.interval != 0:\n",
        "            return\n",
        "\n",
        "        print([l.name for l in self.model.layers])\n",
        "        print(self.model.inputs)\n",
        "        self.current_data, _ = next(self.dataset) #list(self.dataset.take(1).as_numpy_iterator())[0]\n",
        "        pair_images = self.current_data[\"right_image\"]\n",
        "\n",
        "        #print(\"\\nPair DIFFS:\")\n",
        "        #pair_cost = self.get_val(\"pair_pixel_cost\")\n",
        "        #print(\"Pair total cost\", self.get_val(\"pair_total_cost\")[0, 0])\n",
        "        #plt.imshow(pair_images[0, 0, :, :], alpha=1)\n",
        "        #plt.imshow(tf.reduce_sum(pair_cost, [2, 3, 4], keepdims=True)[0, 0, 0, 0, 0, :, :], alpha=0.7)\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "        #print(\"Pair total cost\", self.get_val(\"pair_total_cost\")[0, 1])\n",
        "        #pair_cost = self.get_val(\"pair_pixel_cost\")\n",
        "        #plt.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "        #plt.imshow(tf.reduce_sum(pair_cost, [2, 3, 4], keepdims=True)[0, 1, 0, 0, 0, :, :], alpha=0.7)\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "        #print(\"Pair total cost\", self.get_val(\"pair_total_cost\")[0, 2])\n",
        "        #pair_cost = self.get_val(\"pair_pixel_cost\")\n",
        "        #plt.imshow(pair_images[0, 2, :, :], alpha=1)\n",
        "        #plt.imshow(tf.reduce_sum(pair_cost, [2, 3, 4], keepdims=True)[0, 2, 0, 0, 0, :, :], alpha=0.7)\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "\n",
        "        local_grouping_strengths = self.get_val(\"grouping_local_strengths\")\n",
        "        for nb in range(n_sample_distances):\n",
        "            plt.imshow(local_grouping_strengths[0, nb, 0, 0, 0, :, :])\n",
        "            plt.colorbar()\n",
        "            plt.show()\n",
        "\n",
        "        pair_diff = self.get_val(\"pair_diff\")\n",
        "        maxv = tf.reduce_max(pair_diff)\n",
        "        minv = tf.reduce_min(pair_diff)\n",
        "        ex = max(abs(maxv), abs(minv))\n",
        "        fs = 16\n",
        "        if True: # False if displaying B cells\n",
        "            print(\"RAW LOSSES for size\")\n",
        "            figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            if n_v4_scales > 1:\n",
        "                for j in range(n_v4_scales):\n",
        "                    ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                    ax[j].imshow(pair_diff[0, 1, 0, 0, j, :, :], alpha=0.7, vmin=-ex, vmax=ex)\n",
        "            else:\n",
        "                ax.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax.imshow(pair_diff[0, 1, 0, 0, 0, :, :], alpha=0.7, vmin=-ex, vmax=ex)\n",
        "            plt.show()\n",
        "    \n",
        "            figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            print(\"RAW V4 GAINS for size, without min/max limit\")\n",
        "            if n_v4_scales > 1:\n",
        "                for j in range(n_v4_scales):\n",
        "                    print(\"Scale\", j, \"max loss:\", tf.reduce_max(tf.nn.relu(pair_diff[0, 1, 0, 0, j, :, :])), \"total losses:\", tf.reduce_sum(tf.nn.relu(pair_diff[0, 1, 0, 0, j, :, :])))\n",
        "                    ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                    ax[j].imshow(tf.nn.relu(pair_diff[0, 1, 0, 0, j, :, :]), alpha=0.7)\n",
        "            else:\n",
        "                ax.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax.imshow(tf.nn.relu(pair_diff[0, 1, 0, 0, 0, :, :]), alpha=0.7)\n",
        "\n",
        "            plt.show()\n",
        "    \n",
        "            figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            print(\"RAW V4 LOSSES for size, without min/max limit\")\n",
        "            if n_v4_scales > 1:\n",
        "                for j in range(n_v4_scales):\n",
        "                    print(\"Scale\", j, \"max gain:\", tf.reduce_max(tf.nn.relu(-pair_diff[0, 1, 0, 0, j, :, :])), \"total gain:\", tf.reduce_sum(tf.nn.relu(-pair_diff[0, 1, 0, 0, j, :, :])))\n",
        "                    ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                    ax[j].imshow(tf.nn.relu(-pair_diff[0, 1, 0, 0, j, :, :]), alpha=0.7)\n",
        "            else:\n",
        "                ax.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax.imshow(tf.nn.relu(-pair_diff[0, 1, 0, 0, 0, :, :]), alpha=0.7)\n",
        "            plt.show()\n",
        "\n",
        "        left_v4_response = self.get_val(\"left_v4_response\")\n",
        "        pair_v4_response = self.get_val(\"pair_v4_response\")\n",
        "\n",
        "        figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "        fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "        print(\"LEFT GLYPH v4 response for size, without min/max limit, 0-3\")\n",
        "        if n_v4_scales > 1:\n",
        "            for j in range(n_v4_scales):\n",
        "                print(\"Channel\", j, \"max\", tf.reduce_max(left_v4_response[0, 1, 0, 0, j, :, :]), \"sum\", tf.reduce_sum(left_v4_response[0, 1, 0, 0, j, :, :]))\n",
        "                #print(\"Channel\", j, \"max\", tf.reduce_max(self.get_val(\"left_v4_response\")[0, 1, 0, j, 0, :, :]), \"sum\", tf.reduce_sum(self.get_val(\"left_v4_response\")[0, 1, 0, j, 0, :, :]))\n",
        "                ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax[j].imshow(left_v4_response[0, 1, 0, 0, j, :, :], alpha=0.8)\n",
        "                #ax[j].imshow(self.get_val(\"left_v4_response\")[0, 1, 0, j, 0, :, :], alpha=0.7)\n",
        "        else:\n",
        "            ax.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "            ax.imshow(left_v4_response[0, 1, 0, 0, 0, :, :], alpha=0.8)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        if False:\n",
        "            figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            print(\"PAIR v4 response for size, without min/max limit, 0-3\")\n",
        "            for j in range(n_v4_scales):\n",
        "                print(\"Channel\", j, \"max\", tf.reduce_max(pair_v4_response[0, 1, 0, 0, j, :, :]), \"sum\", tf.reduce_sum(pair_v4_response[0, 1, 0, 0, j, :, :]))\n",
        "                #print(\"Channel\", j, \"max\", tf.reduce_max(self.get_val(\"pair_v4_response\")[0, 1, 0, j, 0, :, :]), \"sum\", tf.reduce_sum(self.get_val(\"pair_v4_response\")[0, 1, 0, j, 0, :, :]))\n",
        "                ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax[j].imshow(pair_v4_response[0, 1, 0, 0, j, :, :], alpha=0.8)\n",
        "                #ax[j].imshow(self.get_val(\"pair_v4_response\")[0, 1, 0, j, 0, :, :])\n",
        "            plt.show()\n",
        "    \n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            maxv = tf.reduce_max(pair_cost)\n",
        "            minv = tf.reduce_min(pair_cost)\n",
        "            ex = max(abs(maxv), abs(minv))\n",
        "            print(\"COST of DIFF for size\")\n",
        "            for j in range(n_v4_scales):\n",
        "                ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax[j].imshow(pair_cost[0, 1, 0, 0, j, :, :], alpha=0.7, vmin=-ex, vmax=ex)\n",
        "            plt.show()\n",
        "\n",
        "        self.print_weights(\"v4_layer\")\n",
        "\n",
        "        print(\"costs\")\n",
        "        print(\"worst violation\", self.get_val(\"worst_violation\"))\n",
        "        plt.plot(np.transpose(self.get_val(\"pair_total_cost\")))\n",
        "        plt.show()\n",
        "\n",
        "        print(\"raw_losses\")\n",
        "        plt.plot(tf.reshape(tf.einsum(\"bdsoc->dbsoc\", tf.reduce_sum(pair_diff, [5,6])), [n_sample_distances, batch_size*n_v4_scales]))\n",
        "        plt.show()\n",
        "\n",
        "        print(\"grouping strenghts\")\n",
        "        self.print_weights(\"target_strength_layer\")\n",
        "        plt.plot(np.transpose(self.get_val(\"grouping_strengths\")))\n",
        "        plt.show()\n",
        "\n",
        "        #self.print_weights(\"cost_layer\")\n",
        "\n",
        "model = get_keras_model()\n",
        "testing = 1\n",
        "model.compile(loss=(lambda _, c: c), optimizer=tf.keras.optimizers.Adam(0.0 if testing else .0001))\n",
        "\n",
        "\n",
        "prepared_dataset = translated_dataset.shuffle(50*batch_size).batch(batch_size).prefetch(batch_size)\n",
        "\n",
        "if True:\n",
        "    history = model.fit(prepared_dataset,\n",
        "                        callbacks=[MonitorProgressCallback(prepared_dataset.as_numpy_iterator(), 1 if testing else 25)],\n",
        "                        epochs=(1 if testing else 1000),\n",
        "                        steps_per_epoch=(1 if testing else 20), use_multiprocessing=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCzdTCu_yk_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARAMETERS\n",
        "\n",
        "kk = 2.8\n",
        "cp = 0.2\n",
        "cn = 0.25\n",
        "v1_v4_scale_weights = tf.tile(tf.constant([1., 15, 35, 200, 1])[:, None], [1, n_v4_scales]) # includes the CSF\n",
        "v1_v4_scale_weights = tf.ones((n_v1_scales, n_v4_scales)) # An alternative for the CSF.\n",
        "v1_v4_orientation_weights = tf.ones((2*n_v1_orientations, n_v4_scales))\n",
        "\n",
        "k = tf.constant([2.4] * n_v4_scales)\n",
        "b = (0.7 ** (2.4 * tf.range(n_v4_scales, dtype=tf.float32)))\n",
        "\n",
        "v4_filters = make_v4_filters(2.8, 0, 0, 0, 0, cp, cn)[None, ...]\n",
        "v4_filters_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(v4_filters, 0.), [3, 4])) \n",
        "\n",
        "def g_response(v1c):\n",
        "    # Multiply by CSF\n",
        "    v1b = tf.pad(tf.concat([v1c]*2, axis=1), [[0, 0], [0, 0],\n",
        "                                [int(np.ceil(box_height / 2)), int(box_height / 2)],\n",
        "                                [int(np.ceil(box_width / 2)), int(box_width / 2)]], mode='CONSTANT')\n",
        "\n",
        "    b_balanced_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(v1b, 0.), [2, 3]))\n",
        "    v4_activations_by_s_o = tf.nn.relu(tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(v4_filters_fft * b_balanced_fft[:, :, None, :, :]), [3, 4]))) \n",
        "    v4_activations = tf.einsum(\"sochw,sc->ochw\", v4_activations_by_s_o, v1_v4_scale_weights)\n",
        "    g_activations = tf.einsum(\"ochw,oc->chw\", v4_activations, v1_v4_orientation_weights)\n",
        "\n",
        "    return g_activations[:, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                              int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))] \n",
        "\n",
        "    # Now to score the g_activations\n",
        "    #g_scores = b[:, None, None] * g_activations ** k[:, None, None]\n",
        "\n",
        "def pair_at_distance(l, r, d):\n",
        "    (lt, rt) = get_pair_translations(l, r, d)\n",
        "    v1_l = translate_4d_image(glyph_v1_responses[l], np.array([lt]))[0, ...]\n",
        "    v1_r = translate_4d_image(glyph_v1_responses[r], np.array([rt]))[0, ...]\n",
        "    g_l = translate_4d_image(glyph_images[l][None, None, :, :], np.array([lt]))[0, 0, 0, :, :]\n",
        "    g_r = translate_4d_image(glyph_images[r][None, None, :, :], np.array([rt]))[0, 0, 0, :, :]\n",
        "    v1_p = v1_l + v1_r\n",
        "\n",
        "    v1c_l, v1c_r, v1c_p = tf.abs(v1_l), tf.abs(v1_r), tf.abs(v1_p)\n",
        "    v4g_l, v4g_r, v4g_p = g_response(v1c_l), g_response(v1c_r), g_response(v1c_p)\n",
        "\n",
        "    grouping_gains = tf.nn.relu(v4g_p - v4g_l - v4g_r)\n",
        "    mean_grouping_gains = tf.reduce_sum(grouping_gains ** 2) / tf.reduce_sum(grouping_gains)\n",
        "    print(\"mean grouping gains:\", mean_grouping_gains.numpy())    \n",
        "\n",
        "    relevance = 2 * v4g_l * v4g_r / (v4g_l + v4g_r)\n",
        "\n",
        "    for i in range(n_v4_scales):\n",
        "        print(\"Scale i:\", i)\n",
        "        plt.imshow(g_l + g_r, cmap=\"gray\")\n",
        "        #plt.imshow(tf.reduce_sum(grouping_gains ** 2, [0]) / tf.reduce_sum(grouping_gains), alpha=0.7)\n",
        "        #plt.imshow(v4g_p[i, :, :], alpha=0.7)\n",
        "        plt.imshow(relevance[i, :, :], alpha=0.7)\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "pair_at_distance(\"n\", \"n\", 0)\n",
        "#pair_at_distance(\"l\", \"l\", 0)\n",
        "pair_at_distance(\"o\", \"o\", 0)\n",
        "#pair_at_distance(\"c\", \"x\", 0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}