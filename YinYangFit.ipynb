{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YinYangFit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpnJ1DNeTsXuVZfMiKj2iQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skosch/YinYangFit/blob/master/YinYangFit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnMfGpUTnOrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n",
        "\n",
        "if tf.test.is_gpu_available():\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "      raise SystemError('GPU device not found')\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "elif False:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    \n",
        "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "    tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA7klPDBnZ-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "pi = np.pi\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.cm as cm\n",
        "import tensorflow as tf\n",
        "import random; random.seed()\n",
        "import math\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm as tqdm\n",
        "import sys\n",
        "from functools import reduce\n",
        "import random\n",
        "from itertools import cycle, islice, product\n",
        "import operator\n",
        "from scipy.linalg import toeplitz\n",
        "\n",
        "!pip install --quiet tensorfont\n",
        "!pip install --quiet fonttools\n",
        "!pip install --quiet --upgrade fontParts\n",
        "!pip install booleanOperations\n",
        "!pip install --quiet --upgrade ufo-extractor\n",
        "!pip install --quiet --upgrade defcon\n",
        "!pip install --quiet --upgrade ufo2ft\n",
        "import fontParts\n",
        "import extractor\n",
        "import defcon\n",
        "from ufo2ft import compileOTF\n",
        "\n",
        "from tensorfont import Font\n",
        "\n",
        "print(\"✓ Dependencies imported.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrGlCMQnnfcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget -q -O OpenSans-Regular.ttf https://github.com/googlefonts/opensans/blob/master/ttfs/OpenSans-Regular.ttf?raw=true\n",
        "#!wget -q -O Roboto.ttf https://github.com/google/fonts/blob/master/apache/roboto/Roboto-Regular.ttf?raw=true\n",
        "#!wget -q -O Roboto.otf https://github.com/AllThingsSmitty/fonts/blob/master/Roboto/Roboto-Regular/Roboto-Regular.otf?raw=true\n",
        "#!wget -q -O DroidSerif.ttf https://github.com/datactivist/sudweb/blob/master/fonts/droid-serif-v6-latin-regular.ttf?raw=true\n",
        "!wget -q -O CrimsonItalic.otf https://github.com/skosch/Crimson/blob/master/Desktop%20Fonts/OTF/Crimson-Italic.otf?raw=true\n",
        "#!wget -q -O CrimsonBold.otf https://github.com/skosch/Crimson/blob/master/Desktop%20Fonts/OTF/Crimson-Bold.otf?raw=true \n",
        "#!wget -q -O CrimsonRoman.otf https://github.com/alif-type/amiri/blob/master/Amiri-Regular.ttf?raw=true\n",
        "\n",
        "!wget -q -O CrimsonRoman.otf https://github.com/skosch/Crimson/blob/master/Desktop%20Fonts/OTF/Crimson-Roman.otf?raw=true\n",
        "print(\"✓ Font file(s) downloaded.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxGlXUzWngSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glyph_char_list = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "#glyph_char_list = \"abgjqrst\"\n",
        "#glyph_char_list = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "#glyph_char_list = \"OO\"\n",
        "#glyph_char_list = \"abc\"\n",
        "\n",
        "# ==== Create Font ====\n",
        "factor = 0.8 #1.539  # This scales the size of everything\n",
        "filename = \"CrimsonRoman.otf\"\n",
        "f = Font(filename, 34 * factor) # Roboto.ttf CrimsonRoman.otf # 34 for lowercase\n",
        "box_height = int(f.full_height_px)\n",
        "box_width = int(161 * factor) # 121\n",
        "box_width += (box_width + 1) % 2\n",
        "print(\"Box size:\", box_height, \"×\", box_width)\n",
        "\n",
        "batch_size = 1\n",
        "sample_distance_deltas = [-2, 0, 2]\n",
        "sample_distance_factors = [.3, 1., 4.4]\n",
        "n_sample_distances = len(sample_distance_deltas)\n",
        "\n",
        "n_v1_scales = 5\n",
        "n_b_scales = 1\n",
        "n_v1_orientations = 4\n",
        "n_v4_scales = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROjMw0u2nk7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sigmas(skip_scales=0):\n",
        "    sigmas = []\n",
        "    for s in range(n_v1_scales):\n",
        "        min_sigma = 0.7\n",
        "        max_sigma = box_width / 15\n",
        "        sigmas.append((max_sigma - min_sigma) * (s + skip_scales)**2 / (n_v1_scales - 1)**2 + min_sigma)\n",
        "        #sigmas.append((max_sigma - min_sigma) * s / n_v1_scales + min_sigma)\n",
        "    return np.array(sigmas)\n",
        "\n",
        "print(\"Spatial frequency scales:\", get_sigmas())\n",
        "\n",
        "def get_v1_filter_bank(skip_scales, display_filters=False):\n",
        "    def rotated_mgrid(oi):\n",
        "        \"\"\"Generate a meshgrid and rotate it by RotRad radians.\"\"\"\n",
        "        rotation = np.array([[ np.cos(pi*oi/n_v1_orientations), np.sin(pi*oi/n_v1_orientations)],\n",
        "                             [-np.sin(pi*oi/n_v1_orientations), np.cos(pi*oi/n_v1_orientations)]])\n",
        "        hh = box_height # / 2\n",
        "        bw = box_width # / 2\n",
        "        y, x = np.mgrid[-hh:hh, -bw:bw].astype(np.float32)\n",
        "        y += 0.5 # 0 if box_height % 2 == 0 else 0.5\n",
        "        x += 0.5 # 0 if box_width % 2 == 0 else 0.5\n",
        "        return np.einsum('ji, mni -> jmn', rotation, np.dstack([x, y]))\n",
        "\n",
        "    def get_filter(s, theta):\n",
        "        x, y = rotated_mgrid(theta)\n",
        "\n",
        "        # To minimize ringing etc., we create the filter as is, then run it through the DFT.\n",
        "\n",
        "        # First derivative (odd filter/up-down)\n",
        "        d1_space = np.exp(-(x**2+y**2)/(2*s**2))*x/(2*pi*s**4)\n",
        "        d1_relu_sum = np.sum(d1_space * (d1_space > 0))\n",
        "        d1 = np.fft.fft2(np.fft.ifftshift(d1_space + 1j * np.zeros_like(d1_space)))\n",
        "\n",
        "        # Second derivative (even filter/mexican hat):\n",
        "        s2 = s * .85 # To make them about the same width\n",
        "        d2_space = np.exp(-(x**2+y**2)/(2*s2**2))/(2*pi*s2**4) - np.exp(-(x**2+y**2)/(2*s2**2))*x**2/(2*pi*s2**6)\n",
        "        d2_relu_sum = np.sum(d2_space * (d2_space > 0))\n",
        "        d2 = (d1_relu_sum / d2_relu_sum) * np.fft.fft2(np.fft.ifftshift(d2_space + 1j * np.zeros_like(d2_space)))\n",
        "\n",
        "        return (d1 + 1j*d2) / (5 * np.max(tf.abs(d1+1j*d2))) # Max output should be about 0.2, which leaves lots of flexibility for the HRA later\n",
        "\n",
        "    filter_bank = np.zeros((n_v1_scales, n_v1_orientations, 2*box_height, 2*box_width)).astype(np.complex64)\n",
        "\n",
        "    if display_filters:\n",
        "        sizediv = 20\n",
        "        fig, ax = plt.subplots(nrows=n_v1_scales*2, ncols=n_v1_orientations, gridspec_kw = {'wspace':0, 'hspace':0}, figsize=(box_width * n_v1_orientations / sizediv, box_height * n_v1_scales * 2 / sizediv))\n",
        "\n",
        "    sigmas = get_sigmas()\n",
        "    for s in range(n_v1_scales):\n",
        "        sigma = sigmas[s]\n",
        "        for o in range(n_v1_orientations):\n",
        "            f = get_filter(sigma, o)\n",
        "            if display_filters:\n",
        "                mx = np.max(np.abs(np.imag(np.fft.ifft2(f))))\n",
        "                ax[s*2, o].imshow(np.real(np.fft.fftshift(np.fft.ifft2(f))), cmap=\"RdBu\", vmin=-mx, vmax=mx)\n",
        "                ax[s*2, o].set_aspect(\"auto\")\n",
        "                ax[s*2, o].set_yticklabels([])\n",
        "                ax[s*2+1, o].imshow(np.imag(np.fft.fftshift(np.fft.ifft2(f))), cmap=\"RdBu\", vmin=-mx, vmax=mx)\n",
        "                ax[s*2+1, o].set_aspect(\"auto\")\n",
        "                ax[s*2+1, o].set_yticklabels([])\n",
        "            filter_bank[s, o, :, :] = f\n",
        "\n",
        "    if display_filters:\n",
        "        plt.show()\n",
        "\n",
        "    return filter_bank.astype(np.complex64)\n",
        "\n",
        "filter_bank = get_v1_filter_bank(0, display_filters=True)\n",
        "\n",
        "\n",
        "def apply_filter_bank(input_image, filter_bank):\n",
        "    \"\"\"\n",
        "    Input image should have dimensions <h, w> or <s, o, h, w> or <b, s, o, h, w, d>.\n",
        "    Filter bank should have dimensions <s, o, h, w>\n",
        "    \"\"\"\n",
        "    bdsohw_input_image = input_image[None, None, None, None, :, :]\n",
        "\n",
        "    # pad image to filter size, which is 2*box_height, 2*box_width (to prevent too much wrapping)\n",
        "    padded_input = tf.pad(bdsohw_input_image, [[0, 0], [0, 0], [0, 0], [0, 0],\n",
        "                            [int(np.ceil(box_height / 2)), int(box_height / 2)],\n",
        "                            [int(np.ceil(box_width / 2)), int(box_width / 2)]], mode='CONSTANT')\n",
        "\n",
        "    input_in_freqdomain = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(padded_input, tf.zeros_like(padded_input))))\n",
        "\n",
        "    padded_result = tf.signal.ifft2d(input_in_freqdomain * filter_bank[None, None, :, :, :, :])\n",
        "\n",
        "    presult = tf.signal.fftshift(padded_result[0, 0, :, :, :, :], [2, 3])\n",
        "\n",
        "    return presult[:, :, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                        int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hbbp_6ap8LP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Render glyphs\n",
        "\n",
        "def get_glyph_image(glyph_char):\n",
        "    \"\"\"Returns a np.array of shape [box_height, box_width] containing the glyph at the center.\"\"\"\n",
        "    return f.glyph(glyph_char).as_matrix(normalize=True).with_padding_to_constant_box_width(box_width).astype(np.float32)\n",
        "\n",
        "def get_glyph_ink_width(glyph_char):\n",
        "    \"\"\"Returns the width of the rendered glyph in pixels.\"\"\"\n",
        "    return f.glyph(glyph_char).ink_width\n",
        "\n",
        "def get_v1_response(glyph_image):\n",
        "    \"\"\"Returns a np.array of shape [n_v1_scales, n_v1_orientations, box_height, box_width] and type complex64,\n",
        "    containing the local responses to the V1 filter bank (after inverse Fourier transform, i.e. in the spatial domain).\"\"\"\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "        filtered = apply_filter_bank(glyph_image, filter_bank)\n",
        "    return filtered\n",
        "\n",
        "glyph_images = {c: get_glyph_image(c) for c in tqdm(glyph_char_list)}\n",
        "print(\"  ✓\", len(glyph_char_list), \"glyphs rendered.\", flush=True)\n",
        "glyph_ink_widths = {c: get_glyph_ink_width(c) for c in tqdm(glyph_char_list)}\n",
        "print(\"  ✓\", len(glyph_char_list), \"glyphs measured.\", flush=True)\n",
        "glyph_v1_responses = {c: get_v1_response(glyph_images[c]) for c in tqdm(glyph_char_list)}\n",
        "print(\"  ✓\", len(glyph_char_list), \"glyphs filtered.\", flush=True)\n",
        "\n",
        "# 1a. Show an example of filtered glyphs\n",
        "for si in range(n_v1_scales):\n",
        "    print(\"Scale:\", si)\n",
        "    plt.imshow(np.sum(np.abs(glyph_v1_responses[\"a\"][si, :, :, :]), (0)))\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "# 2. Assemble pairs\n",
        "\n",
        "def get_pair_translations(char1, char2, distance_deltas, distance_factors=None):\n",
        "    \"\"\"Returns two 1D arrays of distances (in pixels) by which the left and right glyph need to be translated (i.e. shifted horizontally)\n",
        "    in order to place the two glyphs at the desired distances.\n",
        "    \n",
        "    Example: distance_deltas = [-2, 0, 2] or distance_factors=[0.7, 1.0, 1.5]\n",
        "    \"\"\"\n",
        "\n",
        "    optimal_distance = int(f.pair_distance(char1, char2) + f.minimum_ink_distance(char1, char2))\n",
        "\n",
        "    if distance_factors is None:\n",
        "        if distance_deltas is None:\n",
        "            raise ValueError(\"Must provide either distance_deltas or distance_factors\")\n",
        "        \n",
        "        sample_distances = optimal_distance + np.array(distance_deltas)\n",
        "    else:\n",
        "        if distance_deltas is not None:\n",
        "            raise ValueError(\"Must provide either distance_deltas or distance_factors, not both\")\n",
        "\n",
        "        sample_distances = optimal_distance * np.array(distance_factors)\n",
        "\n",
        "    total_width_at_minimum_ink_distance = glyph_ink_widths[char1] + glyph_ink_widths[char2] - f.minimum_ink_distance(char1, char2)\n",
        "    total_ink_width = glyph_ink_widths[char1] + glyph_ink_widths[char2]\n",
        "    ink_width_left = np.floor(total_ink_width / 4)\n",
        "    ink_width_right = np.ceil(total_ink_width / 4)\n",
        "    sample_distances_left = np.ceil(sample_distances / 2)\n",
        "    sample_distances_right = np.floor(sample_distances / 2)\n",
        "\n",
        "    left_translations = (-(np.ceil(total_width_at_minimum_ink_distance/2) + sample_distances_left) - (-ink_width_left)).astype(np.int32)\n",
        "    right_translations = ((np.floor(total_width_at_minimum_ink_distance/2) + sample_distances_right) - ink_width_right).astype(np.int32)\n",
        "    \n",
        "    return (left_translations, right_translations)\n",
        "    \n",
        "left_images = []\n",
        "right_images = []\n",
        "left_v1_responses = []\n",
        "right_v1_responses = []\n",
        "left_translations = []\n",
        "right_translations = []\n",
        "\n",
        "for c1 in tqdm(glyph_char_list):\n",
        "    for c2 in glyph_char_list:\n",
        "        left_images.append(glyph_images[c1])\n",
        "        right_images.append(glyph_images[c2])\n",
        "        left_v1_responses.append(glyph_v1_responses[c1])\n",
        "        right_v1_responses.append(glyph_v1_responses[c2])\n",
        "\n",
        "        lt, rt = get_pair_translations(c1, c2, sample_distance_deltas) #, sample_distance_factors)\n",
        "        left_translations.append(lt)\n",
        "        right_translations.append(rt)\n",
        "\n",
        "print(\"  ✓\", len(glyph_char_list)**2, \"pairs assembled.\")\n",
        "\n",
        "# 3. Set up generator to yield pairs, and wrap generator in a tf.Dataset\n",
        "\n",
        "def return_pair():\n",
        "    i = 0\n",
        "    while i < len(left_images):\n",
        "        yield {\n",
        "            \"left_image\": left_images[i],\n",
        "            \"right_image\": right_images[i],\n",
        "            \"left_v1_response\": left_v1_responses[i],\n",
        "            \"right_v1_response\": right_v1_responses[i],\n",
        "            \"left_translations\": left_translations[i],\n",
        "            \"right_translations\": right_translations[i],\n",
        "        }\n",
        "        i = (i + 1) % len(left_images)\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "     return_pair,\n",
        "     {\n",
        "      \"left_image\": tf.float32,\n",
        "      \"right_image\": tf.float32,\n",
        "      \"left_v1_response\": tf.complex64,\n",
        "      \"right_v1_response\": tf.complex64,#\n",
        "      \"left_translations\": tf.int32,\n",
        "      \"right_translations\": tf.int32,\n",
        "     },\n",
        "     {\n",
        "      \"left_image\": tf.TensorShape([box_height, box_width]),\n",
        "      \"right_image\": tf.TensorShape([box_height, box_width]),\n",
        "      \"left_v1_response\": tf.TensorShape([n_v1_scales, n_v1_orientations, box_height, box_width]),\n",
        "      \"right_v1_response\": tf.TensorShape([n_v1_scales, n_v1_orientations, box_height, box_width]),\n",
        "      \"left_translations\": tf.TensorShape([n_sample_distances,]),\n",
        "      \"right_translations\": tf.TensorShape([n_sample_distances,])\n",
        "     },\n",
        ")\n",
        "\n",
        "print(\"\\n  ✓ Dataset ready.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-LYhZo_riZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. Apply horizontal translations in the dataset\n",
        "\n",
        "def translate_4d_image(input_image, translations):\n",
        "    \"\"\"Shifts images to left/right and back-fills with zeros.\n",
        "    @param image: <sizes, orientations, height, width>\n",
        "    @param translations: <len(translations)>\n",
        "    @output        <len(translations), sizes, orientations, height, width>\n",
        "    \"\"\"\n",
        "\n",
        "    images = tf.tile(input_image[:, :, :, :, None], [1, 1, 1, 1, translations.shape[0]]) # create len(shifts) channel copies\n",
        "    fill_constant = 0\n",
        "    left = tf.maximum(0, tf.reduce_max(translations)) # positive numbers are shifts to the right, for which we need to add zeros on the left\n",
        "    right = -tf.minimum(0, tf.reduce_min(translations)) # negative numbers are shifts to the left, for which we need to add zeros on the right\n",
        "    left_mask = tf.ones(shape=(tf.shape(images)[0], tf.shape(images)[1], tf.shape(images)[2], left, tf.shape(images)[4]), dtype=images.dtype) * fill_constant\n",
        "    right_mask = tf.ones(shape=(tf.shape(images)[0], tf.shape(images)[1], tf.shape(images)[2], right, tf.shape(images)[4]), dtype=images.dtype) * fill_constant\n",
        "    padded_images = tf.concat([left_mask, images, right_mask], axis=3) # pad on axis 3 (i.e. width-wise)\n",
        "\n",
        "    # Now that the images are all padded, we need to crop them to implement the shifts.\n",
        "    def crop_image_widthwise(image_and_shift):\n",
        "        image = image_and_shift[0] # sohw\n",
        "        shift = image_and_shift[1] # \n",
        "        return image[:, :, :, left-shift:left-shift+input_image.shape[3]] # positive shift: left-shift\n",
        "\n",
        "    result = tf.map_fn(\n",
        "        crop_image_widthwise,\n",
        "        (tf.einsum(\"sohwd->dsohw\", padded_images), translations),\n",
        "        dtype=images.dtype)\n",
        "\n",
        "    # Manually ensure that the width-dimension hasn't changed\n",
        "    s = list(result.shape)\n",
        "    s[-1] = box_width\n",
        "    result.set_shape(s)\n",
        "\n",
        "    return result\n",
        "\n",
        "def apply_translations(d):\n",
        "    d[\"left_image\"] = translate_4d_image(d[\"left_image\"][None, None, :, :], d[\"left_translations\"])[:, 0, 0, :, :]\n",
        "    d[\"right_image\"] = translate_4d_image(d[\"right_image\"][None, None, :, :], d[\"right_translations\"])[:, 0, 0, :, :]\n",
        "    d[\"left_v1_response\"] = translate_4d_image(d[\"left_v1_response\"], d[\"left_translations\"])\n",
        "    d[\"right_v1_response\"] = translate_4d_image(d[\"right_v1_response\"], d[\"right_translations\"])\n",
        "    del d[\"left_translations\"]\n",
        "    del d[\"right_translations\"]\n",
        "    return (d, 0.)  # The zero here doesn't do anything and is just to make Keras happy, because model.fit expects a dataset of 2-tuples where the second entry is the target value.\n",
        "\n",
        "translated_dataset = dataset.map(apply_translations)\n",
        "\n",
        "print(\"dataset shapes:\", translated_dataset.element_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qo5aVMk3sRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5. Utility functions\n",
        "eps = np.finfo(np.float32).tiny\n",
        "\n",
        "def invspa(t):\n",
        "    return np.log(np.exp(t) - 1).astype(np.float32)\n",
        "\n",
        "def invsp(t):\n",
        "    if t == 0:\n",
        "        return -1e10\n",
        "    else:\n",
        "        return np.log(np.exp(t) - 1).astype(np.float32)\n",
        "\n",
        "def sp(t):\n",
        "    return tf.nn.softplus(t)\n",
        "\n",
        "# 6. Generating G-cell fragments\n",
        "\n",
        "u, v = np.mgrid[-box_height:box_height,-box_width:box_width].astype(np.float32)\n",
        "u = u / (2*box_width)\n",
        "v = v / (2*box_width)\n",
        "r = np.sqrt(u**2 + v**2)[None, None, :, :]\n",
        "angle = np.arctan2(u, v)[None, None, :, :] # <b, d, s, o, c, h, w>\n",
        "angles = np.arange(n_v1_orientations)[:, None, None, None].astype(np.float32)/n_v1_orientations\n",
        "\n",
        "def make_v4_filters(scales, inner_widths, angle_mask_widths): # Returns masks of shape <o, c, h, w>\n",
        "    freq_masks = tf.exp(-(r - scales[None, :, None, None])**2 / (2 * (inner_widths[None, :, None, None])**2)) #/ (r + eps)\n",
        "    #freq_masks = (1/(r**2 + eps)) * tf.exp(-(tf.math.log(r + eps) - scales[None, :, None, None])**2 / (2 * inner_widths[None, :, None, None])**2)\n",
        "\n",
        "    # Uses von-Mises distribution (via Bessel function)\n",
        "    bp_angle_masks = tf.exp(-angle_mask_widths[:, :, None, None] * tf.cos(angle - pi - pi * angles)) / (2*pi*tf.math.bessel_i0(angle_mask_widths[:, :, None, None]))\n",
        "    bn_angle_masks = tf.exp(-angle_mask_widths[:, :, None, None] * tf.cos(angle - pi * angles)) / (2*pi*tf.math.bessel_i0(angle_mask_widths[:, :, None, None]))\n",
        "\n",
        "    bp_masks = (freq_masks) * bp_angle_masks\n",
        "    bn_masks = (freq_masks) * bn_angle_masks\n",
        "\n",
        "    # Each bp/bn_mask fragment should add up to exactly one.\n",
        "    bp_masks_normed = 4*bp_masks / (eps + tf.reduce_sum(bp_masks, [0, 2, 3], keepdims=True))\n",
        "    bn_masks_normed = 4*bn_masks / (eps + tf.reduce_sum(bn_masks, [0, 2, 3], keepdims=True))\n",
        "\n",
        "    return tf.clip_by_value(tf.concat([bp_masks_normed, bn_masks_normed], axis=0), -1e12, 1e12)\n",
        "\n",
        "\n",
        "# 7. V4 layer\n",
        "class V4Layer(tf.keras.layers.Layer):\n",
        "    def __init__(self, skip_v4_convolution=False, **kwargs):\n",
        "        super(V4Layer, self).__init__(**kwargs)\n",
        "\n",
        "        self.skip_v4_convolution = skip_v4_convolution\n",
        "\n",
        "        self.csf = self.add_weight(shape=((n_v1_scales, n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"csf\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.v1_hra_k = self.add_weight(shape=((n_v1_scales, n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([2.4,2.4,2.4,2.4,2.4])[:, None], [1, n_v1_orientations])), # 1 to .02\n",
        "                                 name=\"v1_hra_k\",\n",
        "                                 trainable=False)\n",
        "        self.v1_hra_b = self.add_weight(shape=((n_v1_scales, n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([.06,.06,.06,.06,.06])[:, None], [1, n_v1_orientations])), # 1 to .02\n",
        "                                 name=\"v1_hra_b\",\n",
        "                                 trainable=False)\n",
        "\n",
        "        self.v4_scales_exponent = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(1.5), name=\"v4_scales_exponent\", trainable=True)\n",
        "        self.v4_scales_min = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(.54), name=\"v4_scales_min\", trainable=True)\n",
        "        self.v4_scales_factor = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(0.5), name=\"v4_scales_factor\", trainable=True)\n",
        "\n",
        "        self.v4_widths_exponent = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(1.5), name=\"v4_widths_exponent\", trainable=True)\n",
        "        self.v4_widths_min = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(.6), name=\"v4_widths_min\", trainable=True)\n",
        "        self.v4_widths_factor = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(0.2), name=\"v4_widths_factor\", trainable=True)\n",
        "\n",
        "        self.v4_scales = self.add_weight(shape=(n_v4_scales),\n",
        "                                      initializer=tf.keras.initializers.Constant(np.array([.4,1.1,2.1,4.0,7.5]).astype(np.float32)/box_width),\n",
        "                                      #initializer=tf.keras.initializers.Constant(np.array([1.4,1.6,1.75,1.83,1.9]).astype(np.float32)),\n",
        "                                      name=\"v4_scales\", trainable=False)\n",
        "        self.v4_widths = self.add_weight(shape=(n_v4_scales),\n",
        "                                            initializer=tf.keras.initializers.Constant(np.array([.5,0.7,1.,1.7,3.8]).astype(np.float32)/box_width),\n",
        "                                            #initializer=tf.keras.initializers.Constant(np.array([1.4,1.25,1.15,1.03,.98]).astype(np.float32)),\n",
        "                                            name=\"v4_widths\", trainable=False)\n",
        "        self.v4_angle_mask_widths = self.add_weight(shape=(n_v1_orientations, n_v4_scales),\n",
        "                                                 initializer=tf.keras.initializers.Constant(4.),\n",
        "                                                 name=\"v4_angle_mask_widths\", trainable=False)\n",
        "        self.v4_filter_strengths = self.add_weight(shape=(n_v1_orientations, n_v4_scales),\n",
        "                                               initializer=tf.keras.initializers.Constant(1.),\n",
        "                                               name=\"v4_filter_strengths\", trainable=False)\n",
        "\n",
        "        self.v4_hra_k = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([1.4, 1.4, 1.4, 1.4, 1.4])[None, :], [2*n_v1_orientations, 1])),\n",
        "                                 name=\"v4_hra_k\",\n",
        "                                 trainable=False)\n",
        "        self.v4_hra_b = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([1,1,1,1,1])[None, :], [2*n_v1_orientations, 1])),\n",
        "                                 name=\"v4_hra_b\",\n",
        "                                 trainable=False)\n",
        "\n",
        "\n",
        "        # Each ring should only be able to draw from \n",
        "        self.v1_v4_scale_weights = self.add_weight(shape=(1, n_v4_scales),\n",
        "                                 #initializer=tf.keras.initializers.Constant((eps + np.triu(np.ones((n_v1_scales, n_v4_scales))).astype(np.float32) * .5**toeplitz(np.zeros(n_v1_scales), np.arange(n_v4_scales)))),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"v1_v4_scale_weights\",\n",
        "                                 trainable=True)\n",
        "        self.v1_v4_orientation_weights = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.)),\n",
        "                                 name=\"v1_v4_orientation_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.v4_b_scale_weights = self.add_weight(shape=(1, n_v4_scales),\n",
        "                                 #initializer=tf.keras.initializers.Constant((eps + np.triu(np.ones((n_v1_scales, n_v4_scales))).astype(np.float32) * .5**toeplitz(np.zeros(n_v1_scales), np.arange(n_v4_scales)))),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"v4_b_scale_weights\",\n",
        "                                 trainable=True)\n",
        "        self.v4_b_orientation_weights = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.)),\n",
        "                                 name=\"v4_b_orientation_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        \n",
        "        self.g_hra_k = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp([4.4, 5.4, 4.4, 2.4, 1.4])),\n",
        "                                 name=\"g_hra_k\",\n",
        "                                 trainable=True)\n",
        "        self.g_hra_b = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp([1.5, 2., 2.5, 1.5, 1.0]).astype(np.float32)),\n",
        "                                 name=\"g_hra_b\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.feedback_modulation_strength = self.add_weight(shape=(1, 2*n_v1_orientations, 1, 1),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(2.)),\n",
        "                                 name=\"feedback_modulation_strength\",\n",
        "                                 trainable=False)\n",
        "\n",
        "        self.b_dn_b = self.add_weight(shape=(1, 2*n_v1_orientations),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.5)),\n",
        "                                 name=\"b_dn_b\",\n",
        "                                 trainable=False)\n",
        "        self.b_dn_k = self.add_weight(shape=(1, 2*n_v1_orientations),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(3.2)),\n",
        "                                 name=\"b_dn_k\",\n",
        "                                 trainable=False)\n",
        "        self.b_dn_k_pool = self.add_weight(shape=(1, 2*n_v1_orientations),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(2.)),\n",
        "                                 name=\"b_dn_k_pool\",\n",
        "                                 trainable=False)\n",
        "\n",
        "        # We would want the normalization pool to mostly include, for each size/orientation, the opposite orientation.\n",
        "        # We would also want to include smaller sizes. But perhaps that's not so important?\n",
        "\n",
        "        basic_dn_matrix = np.zeros((1, 2*n_v1_orientations, 1, 2*n_v1_orientations)).astype(np.float32)\n",
        "\n",
        "        # The first ones are the ones that count towards the second\n",
        "        for s1 in range(1):\n",
        "            for o1 in range(2*n_v1_orientations):\n",
        "                for s2 in range(1):\n",
        "                    for o2 in range(2*n_v1_orientations):\n",
        "                        s_distance = np.exp(-(s1 - s2)**2)\n",
        "                        basic_dn_matrix[s1, o1, s2, o2] = s_distance\n",
        "\n",
        "        self.b_dn_weights = self.add_weight(shape=((1, 2*n_v1_orientations, 1, 2*n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(basic_dn_matrix.astype(np.float32)),\n",
        "                                 name=\"b_dn_weights\",\n",
        "                                 trainable=False)\n",
        "\n",
        "\n",
        "        self.g_dn_b = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.5)),\n",
        "                                 name=\"g_dn_b\",\n",
        "                                 trainable=True)\n",
        "        self.g_dn_k = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(3.2)),\n",
        "                                 name=\"g_dn_k\",\n",
        "                                 trainable=True)\n",
        "        self.g_dn_k_pool = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(2.)),\n",
        "                                 name=\"g_dn_k_pool\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        # We would want the normalization pool to mostly include, for each size/orientation, the opposite orientation.\n",
        "        # We would also want to include smaller sizes. But perhaps that's not so important?\n",
        "\n",
        "        basic_g_dn_matrix = np.zeros((n_v4_scales, n_v4_scales)).astype(np.float32)\n",
        "\n",
        "        # The first ones are the ones that count towards the second\n",
        "        for s1 in range(n_v4_scales):\n",
        "            for s2 in range(n_v4_scales): # the smaller ones should always suppress the bigger ones\n",
        "                s_distance = 1. if s1 <= s2 else 0.\n",
        "                basic_g_dn_matrix[s1, s2] = s_distance\n",
        "\n",
        "        self.g_dn_weights = self.add_weight(shape=((n_v4_scales, n_v4_scales)),\n",
        "                                 initializer=tf.keras.initializers.Constant(basic_g_dn_matrix.astype(np.float32)),\n",
        "                                 name=\"g_dn_weights\",\n",
        "                                 trainable=False)\n",
        "\n",
        "\n",
        "\n",
        "    def get_v4_scales(self):\n",
        "        return (tf.nn.relu(eps + tf.range(0, n_v4_scales * self.v4_scales_factor, self.v4_scales_factor) + self.v4_scales_min) ** tf.nn.relu(eps + self.v4_scales_exponent)) / box_width\n",
        "\n",
        "    def get_v4_widths(self):\n",
        "        return (tf.nn.relu(eps + tf.range(0, n_v4_scales * self.v4_widths_factor, self.v4_widths_factor) + self.v4_widths_min) ** tf.nn.relu(eps + self.v4_widths_exponent)) / box_width\n",
        "\n",
        "    def print_weights(self):\n",
        "        print(\"HRA parameters:\")\n",
        "        print(\"---------\")\n",
        "        print(\"V1 (scales/orientations) exponents [k] and half-points [b]\")\n",
        "        plt.imshow(sp(self.v1_hra_k))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        plt.imshow(sp(self.v1_hra_b))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        print(\"V4 (scales/orientations) exponents [k] and half-points [b]\")\n",
        "        plt.imshow(sp(self.v4_hra_k))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        plt.imshow(sp(self.v4_hra_b))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        print(\"G (scales) exponents [k] and half-points [b]\")\n",
        "        plt.plot(sp(self.g_hra_k))\n",
        "        plt.plot(sp(self.g_hra_b))\n",
        "        plt.show()\n",
        "\n",
        "        print(\"M\")\n",
        "        v4_filters = (make_v4_filters(self.get_v4_scales(), self.get_v4_widths(), self.v4_angle_mask_widths))[None, None, None, ...]\n",
        "        for i in range(n_v4_scales):\n",
        "            plt.imshow(tf.reduce_sum(v4_filters[0, 0, 0, :, i, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                            int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))], [0]))\n",
        "            plt.colorbar()\n",
        "            plt.show()\n",
        "\n",
        "        print(\"SCALES, WIDTHS, STRENGHTS\", self.get_v4_scales().numpy(), \"ORIGINALSTRENGHTS\", self.v4_scales.numpy(), \"\\n WIDTHS\", self.get_v4_widths().numpy(), \"ORIGINALWIDTHS\", self.v4_widths.numpy(), \"\\n\", self.v4_filter_strengths.numpy())\n",
        "\n",
        "        print(\"Forward linking matrix:\")\n",
        "        print(\"Scale weights:\")\n",
        "        plt.imshow(sp(self.v1_v4_scale_weights))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        print(\"Orientation weights:\")\n",
        "        plt.imshow(sp(self.v1_v4_orientation_weights))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Backward linking matrix:\")\n",
        "        print(\"Scale weights:\")\n",
        "        plt.imshow(sp(self.v4_b_scale_weights))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        print(\"Orientation weights:\")\n",
        "        plt.imshow(sp(self.v4_b_orientation_weights))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Feedback modulation strength:\")\n",
        "        plt.imshow(sp(self.feedback_modulation_strength)[:, :, 0, 0])\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"DN exponents: upper k:\", tf.reduce_mean(self.b_dn_k).numpy(), \"pool k:\", tf.reduce_mean(self.b_dn_k_pool).numpy())\n",
        "        print(\"DN Weights (size 2):\")\n",
        "        plt.imshow(self.b_dn_weights[0, :, 0, :])\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "    def hra_v1(self, i):\n",
        "        k = sp(self.v1_hra_k[None, None, :, :, None, None])\n",
        "        b = sp(self.v1_hra_b[None, None, :, :, None, None])\n",
        "        return ((i + eps) ** k) / (eps + b**k + (i + eps) ** k)\n",
        "\n",
        "    def hra_v4(self, i):\n",
        "        return i\n",
        "        k = sp(self.v4_hra_k[None, None, :, :, None, None])\n",
        "        b = sp(self.v4_hra_b[None, None, :, :, None, None])\n",
        "        return ((i + eps) ** k) # / (eps + b**k + (i + eps) ** k)\n",
        "\n",
        "    def hra_g(self, i):\n",
        "        return i\n",
        "        k = sp(self.g_hra_k[None, None, :, None, None])\n",
        "        b = sp(self.g_hra_b[None, None, :, None, None])\n",
        "        return ((i + eps) ** k) #/ (eps + b**k + (i + eps) ** k)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        v1c = tf.reduce_sum(self.hra_v1(tf.abs(inputs)) * tf.nn.relu(self.csf[None, None, :, :, None, None]) / tf.reduce_sum(tf.nn.relu(self.csf)), [2], keepdims=True) # should end up with just a single scale.\n",
        "    \n",
        "        b_balanced = tf.pad(tf.concat([v1c]*2, axis=3), [[0, 0], [0, 0], [0, 0], [0, 0],\n",
        "                                [int(np.ceil(box_height / 2)), int(box_height / 2)],\n",
        "                                [int(np.ceil(box_width / 2)), int(box_width / 2)]], mode='CONSTANT')\n",
        "        \n",
        "        b_balanced_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(b_balanced, 0.), [4, 5]))\n",
        "        \n",
        "        v4_filters = (make_v4_filters(self.get_v4_scales(), self.get_v4_widths(), self.v4_angle_mask_widths) * tf.concat([self.v4_filter_strengths] * 2, axis=0)[..., None, None])[None, None, None, ...]\n",
        "        \n",
        "        v4_filters_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(v4_filters, 0.), [5, 6]))\n",
        "        \n",
        "        v4_activations_0_by_s_o = tf.nn.relu(tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(v4_filters_fft * b_balanced_fft[:, :, :, :, None, :, :]), [5, 6])))\n",
        "        \n",
        "        v4_activations_0 = self.hra_v4(tf.einsum(\"bdsochw,sc->bdochw\", v4_activations_0_by_s_o, eps + tf.nn.relu(self.v1_v4_scale_weights))) # hra_v4\n",
        "        \n",
        "        G_0 = self.hra_g(tf.einsum(\"bdochw,oc->bdchw\", v4_activations_0, tf.nn.relu(self.v1_v4_orientation_weights) / (eps + tf.reduce_mean(tf.nn.relu(self.v1_v4_orientation_weights), axis=[0], keepdims=True) ))) \n",
        "        \n",
        "        # We split the G_0 response by orientation, just like they came in.\n",
        "        v4_feedback = tf.einsum(\"bdchw,oc->bdochw\", G_0, tf.nn.relu(self.v1_v4_orientation_weights) / (eps + tf.reduce_mean(tf.nn.relu(self.v1_v4_orientation_weights), axis=[0], keepdims=True)))\n",
        "    \n",
        "        # For each V4 (ochw), convolute with its counterpart. This produces the opposite.\n",
        "        v4_feedback_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(v4_feedback, 0.), [4, 5]))\n",
        "        v4_filters_fft_inverse = tf.roll(v4_filters_fft[:, :, 0, :, :, :, :], [n_v1_orientations], [2])\n",
        "        v4_feedback_deconvolved = tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(v4_feedback_fft * v4_filters_fft_inverse), [4, 5]))\n",
        "        \n",
        "        # For each counterpart, figure out how much it should contribute to the feedback at each scale.\n",
        "        b_feedback = tf.einsum(\"bdochw,sc->bdsohw\", v4_feedback_deconvolved, tf.nn.relu(self.v4_b_scale_weights))\n",
        "    \n",
        "        b_modulated = b_balanced * (1. + self.feedback_modulation_strength * b_feedback)\n",
        "        \n",
        "        b_normalization_pools = tf.einsum(\"bdsohw,sopq->bdpqhw\", (b_modulated + eps) ** sp(self.b_dn_k_pool[None, None, :, :, None, None]), self.b_dn_weights)\n",
        "        \n",
        "        b_normalized = (b_modulated + eps) ** sp(self.b_dn_k[None, None, :, :, None, None]) / (sp(self.b_dn_b[None, None, :, :, None, None]) ** sp(self.b_dn_k_pool[None, None, :, :, None, None]) + b_normalization_pools)\n",
        "        \n",
        "        b_normalized_fft = tf.signal.fft2d(tf.complex(tf.signal.ifftshift(b_normalized, [4, 5]), 0.))\n",
        "        \n",
        "        v4_activations_1_by_s_o = tf.nn.relu(tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(v4_filters_fft * b_normalized_fft[:, :, :, :, None, :, :]), [5, 6])))\n",
        "        \n",
        "        v4_activations_1 = self.hra_v4(tf.einsum(\"bdsochw,sc->bdochw\", v4_activations_1_by_s_o, tf.nn.relu(self.v1_v4_scale_weights)))\n",
        "        \n",
        "        G_1 = self.hra_g(tf.einsum(\"bdochw,oc->bdchw\", v4_activations_1, self.v1_v4_orientation_weights))\n",
        "\n",
        "        G_1_normalization_pools = tf.einsum(\"bdchw,cq->bdqhw\", G_1 ** sp(self.g_dn_k_pool)[None, None, :, None, None], self.g_dn_weights)\n",
        "        G_1_normalized = (G_1 + eps) ** sp(self.g_dn_k[None, None, :, None, None]) / (sp(self.g_dn_b[None, None, :, None, None]) ** sp(self.g_dn_k_pool[None, None, :, None, None]) + G_1_normalization_pools)\n",
        "\n",
        "        return G_1_normalized[:, :, None, None, :, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                            int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))] \n",
        "\n",
        "# 8. Cost layer\n",
        "class CostLayer(tf.keras.layers.Layer): # These are like the V1 complex edges\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CostLayer, self).__init__(**kwargs)\n",
        "        # <b, s, o, h, w, d>\n",
        "        self.wp = self.add_weight(shape=(n_v4_scales), # Losses\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp([1.5, .9, 1.23, 0.27, 0.01])),\n",
        "                                 name=\"wp\",\n",
        "                                 trainable=True)\n",
        "        self.wn = self.add_weight(shape=(n_v4_scales), # Gains\n",
        "                                 initializer=tf.keras.initializers.Constant([0.13, 0.24, 0.48, 0.22, 0.03]),\n",
        "                                 name=\"wn\",\n",
        "                                 trainable=True)\n",
        "        self.penalty_exps = self.add_weight(shape=((1, 1, 1, 1, n_v4_scales, 1, 1)),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.0)),\n",
        "                                 name=\"penalty_exps\",\n",
        "                                 trainable=True)\n",
        "        self.reward_exps = self.add_weight(shape=((1, 1, 1, 1, n_v4_scales, 1, 1)),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.0)),\n",
        "                                 name=\"reward_exps\",\n",
        "                                 trainable=True)\n",
        "\n",
        "    def norm(self, i):\n",
        "        \"\"\"Normalize the weights.\n",
        "        This regularization is necessary to keep the optimizer from simply making the weights tiny.\"\"\"\n",
        "\n",
        "        v = tf.cumsum(sp(1e3*i)/1e3, axis=0, reverse=True)\n",
        "        wpv = tf.reduce_sum(tf.cumsum(sp(1e3*self.wn)/1e3, axis=0, reverse=True) + tf.cumsum(sp(1e3*self.wp)/1e3, axis=0, reverse=True))\n",
        "        v = (i) # sp(i)\n",
        "        #v = tf.exp(i)\n",
        "        #wpv = tf.reduce_sum(tf.exp(self.wn) + tf.exp(self.wp))\n",
        "\n",
        "        return v[None, None, None, None, :, None, None] #/ wpv\n",
        "\n",
        "    def print_weights(self):\n",
        "        print(\"loss penalties (blue for loss, orange for gains\")\n",
        "        plt.plot(tf.nn.relu(self.norm(self.wp)[0, 0, 0, 0, :, 0, 0]))\n",
        "        plt.plot(self.norm(self.wn)[0, 0, 0, 0, :, 0, 0])\n",
        "        plt.show()\n",
        "        print(\"penalty (blue) and reward (orange) exps, by size:\")\n",
        "        plt.plot(sp(self.penalty_exps)[0, 0, 0, 0, :, 0, 0])\n",
        "        plt.plot(sp(self.reward_exps)[0, 0, 0, 0, :, 0, 0])\n",
        "        plt.show()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        penalties = tf.nn.relu(inputs) * tf.nn.relu(self.norm(self.wp))\n",
        "\n",
        "        rewards = tf.nn.relu(-inputs) * self.norm(self.wn)  # Such that a very strong large grouping is equivalent to a medium-strong smaller grouping\n",
        "\n",
        "        #total_penalties = tf.reduce_sum((eps + tf.reduce_sum(penalties, [5, 6], keepdims=True)) ** sp(self.penalty_exps), [2, 3, 4, 5, 6])\n",
        "\n",
        "        #mean_rewards = (eps + tf.reduce_sum(rewards, [2,3,4,5,6])) / (eps + tf.reduce_sum(tf.nn.relu(-inputs), [2,3,4,5,6]))\n",
        "\n",
        "        #total_rewards_deviation = (eps + tf.abs(mean_rewards - self.desired_total_grouping))**sp(self.desired_total_grouping_deviation_exponent)\n",
        "\n",
        "        return (penalties, rewards) #, total_rewards_deviation, total_penalties, mean_rewards)\n",
        "\n",
        "# 9. Set up the actual math\n",
        "\n",
        "def get_pair_violation(left_v1_response, right_v1_response):\n",
        "    \"\"\"Runs the V1 responses through the V4 layer, weights the pair differences via the CostLayer,\n",
        "    and then returns the worst violation of the \"cost-must-be-lowest-for-optimal-distance\" principle\n",
        "    which is then passed to the optimizer.\"\"\"\n",
        "\n",
        "    # Feed V1 responses through the V4 layer\n",
        "    v4 = V4Layer(False)\n",
        "    left_v4_response = tf.identity(v4(tf.abs(left_v1_response)), \"left_v4_response\")\n",
        "    right_v4_response = tf.identity(v4(tf.abs(right_v1_response)), \"right_v4_response\")\n",
        "    pair_v4_response = tf.identity(v4(tf.abs(left_v1_response + right_v1_response)), \"pair_v4_response\")\n",
        "\n",
        "    # Compute gains and losses in V4 (of pair, relative to standalone letters).\n",
        "    #pair_diff = tf.identity(tf.math.log((left_v4_response + right_v4_response + eps) / (pair_v4_response + eps)), \"pair_diff\")\n",
        "    pair_diff = tf.identity(left_v4_response + right_v4_response - pair_v4_response, \"pair_diff\")\n",
        "\n",
        "    # Compute penalty/reward values for each pair_diff\n",
        "    cost = CostLayer()\n",
        "    (pair_pixel_penalties, pair_pixel_rewards) = cost(pair_diff)\n",
        "    \n",
        "    pair_pixel_cost = tf.identity(pair_pixel_penalties - pair_pixel_rewards, \"pair_pixel_cost\")\n",
        "\n",
        "    # Sum over all channels and pixels to yield one total cost per <pair, sample_distance>\n",
        "    total_pair_cost = tf.reduce_sum(pair_pixel_cost, [2,3,4,5,6], name=\"pair_total_cost\") \n",
        "    #\n",
        "    # Find worst violation of the well\n",
        "    up_first_ness = (total_pair_cost[:, 1] - total_pair_cost[:, 0])\n",
        "    down_second_ness = (total_pair_cost[:, 1] - total_pair_cost[:, 2])\n",
        "    worst_violation = tf.reduce_max(tf.stack([up_first_ness, down_second_ness]), name=\"worst_violation\")\n",
        "\n",
        "    # Both pair_pixel_penalties and pair_pixel_rewards should only get bigger with more proximity\n",
        "    #penalty_nonmonotonicity = tf.reduce_sum(tf.nn.relu(pair_total_penalties[:, 1:] - pair_total_penalties[:, 0:-1]))\n",
        "    #reward_nonmonotonicity = tf.reduce_sum(tf.nn.relu(pair_total_rewards[:, 1:] - pair_total_rewards[:, 0:-1]))\n",
        "\n",
        "    return worst_violation # + penalty_nonmonotonicity + reward_nonmonotonicity\n",
        "\n",
        "# 10. Set up Keras model and run\n",
        "\n",
        "def get_keras_model():\n",
        "    # The translated raw images aren't used in the model, they're just for visualization purposes ...\n",
        "    left_image = tf.keras.Input(shape=(n_sample_distances, box_height, box_width), name='left_image')\n",
        "    right_image = tf.keras.Input(shape=(n_sample_distances, box_height, box_width), name='right_image')\n",
        "\n",
        "    # ... but the translated V1 responses are:\n",
        "    left_v1_response = tf.keras.Input(shape=(n_sample_distances, n_v1_scales, n_v1_orientations, box_height, box_width), name='left_v1_response', dtype=tf.complex64)\n",
        "    right_v1_response = tf.keras.Input(shape=(n_sample_distances, n_v1_scales, n_v1_orientations, box_height, box_width), name='right_v1_response', dtype=tf.complex64)\n",
        "\n",
        "    # This calls the V4 layer, the penalty/reward layer, and finds the max cost\n",
        "    total_violation = tf.identity(get_pair_violation(left_v1_response, right_v1_response), \"total_violation\")\n",
        "\n",
        "    return tf.keras.Model(inputs=[left_v1_response, right_v1_response, left_image, right_image], outputs=(total_violation))\n",
        "\n",
        "class MonitorProgressCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, dataset, interval):\n",
        "        self.dataset = dataset\n",
        "        self.interval = interval\n",
        "        self.current_data = None\n",
        "\n",
        "    def get_val(self, name):\n",
        "        l = [l for l in self.model.layers if l.name.find(name) >= 0][0]\n",
        "        output = tf.keras.backend.function(self.model.inputs, [l.output])([self.current_data[\"left_v1_response\"],\n",
        "                                                                           self.current_data[\"right_v1_response\"],\n",
        "                                                                           self.current_data[\"left_image\"],\n",
        "                                                                           self.current_data[\"right_image\"]])[0]\n",
        "        return output\n",
        "\n",
        "    def get_weights(self, name):\n",
        "        l = [l for l in self.model.layers if l.name.find(name) >= 0][0]\n",
        "        return l.get_weights()\n",
        "\n",
        "    def print_weights(self, name):\n",
        "        l = [l for l in self.model.layers if l.name.find(name) >= 0][0]\n",
        "        l.print_weights()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Only show this stuff every [interval] batches\n",
        "        if epoch % self.interval != 0:\n",
        "            return\n",
        "\n",
        "        print([l.name for l in self.model.layers])\n",
        "        print(self.model.inputs)\n",
        "        self.current_data, _ = next(self.dataset) #list(self.dataset.take(1).as_numpy_iterator())[0]\n",
        "        pair_images = self.current_data[\"left_image\"] + self.current_data[\"right_image\"]\n",
        "\n",
        "        plt.imshow(pair_images[0, 0, :, :])\n",
        "        plt.imshow(tf.reduce_sum(tf.abs(self.current_data[\"left_v1_response\"][0, 0, 0, :, :, :]), [0]), alpha=.6)\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        plt.imshow(pair_images[0, 1, :, :])\n",
        "        plt.imshow(tf.reduce_sum(tf.abs(self.current_data[\"left_v1_response\"][0, 1, 2, :, :, :]), [0]), alpha=.6)\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        plt.imshow(pair_images[0, 2, :, :])\n",
        "        plt.imshow(tf.reduce_sum(tf.abs(self.current_data[\"left_v1_response\"][0, 2, n_v1_scales - 2, :, :, :]), [0]), alpha=.6)\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\nPair DIFFS:\")\n",
        "        pair_cost = self.get_val(\"pair_pixel_cost\")\n",
        "        print(\"Pair total cost\", self.get_val(\"pair_total_cost\")[0, 0])\n",
        "        plt.imshow(pair_images[0, 0, :, :], alpha=1)\n",
        "        plt.imshow(tf.reduce_sum(pair_cost, [2, 3, 4], keepdims=True)[0, 0, 0, 0, 0, :, :], alpha=0.7)\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        print(\"Pair total cost\", self.get_val(\"pair_total_cost\")[0, 1])\n",
        "        pair_cost = self.get_val(\"pair_pixel_cost\")\n",
        "        plt.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "        plt.imshow(tf.reduce_sum(pair_cost, [2, 3, 4], keepdims=True)[0, 1, 0, 0, 0, :, :], alpha=0.7)\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        print(\"Pair total cost\", self.get_val(\"pair_total_cost\")[0, 2])\n",
        "        pair_cost = self.get_val(\"pair_pixel_cost\")\n",
        "        plt.imshow(pair_images[0, 2, :, :], alpha=1)\n",
        "        plt.imshow(tf.reduce_sum(pair_cost, [2, 3, 4], keepdims=True)[0, 2, 0, 0, 0, :, :], alpha=0.7)\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "        pair_diff = self.get_val(\"pair_diff\")\n",
        "        maxv = tf.reduce_max(pair_diff)\n",
        "        minv = tf.reduce_min(pair_diff)\n",
        "        ex = max(abs(maxv), abs(minv))\n",
        "        print(\"RAW LOSSES for size\")\n",
        "        fs = 16\n",
        "        figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "        fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "        for j in range(n_v4_scales):\n",
        "            ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "            ax[j].imshow(pair_diff[0, 1, 0, 0, j, :, :], alpha=0.7, vmin=-ex, vmax=ex)\n",
        "        plt.show()\n",
        "\n",
        "        figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "        fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "        print(\"RAW V4 LOSSES for size, without min/max limit\")\n",
        "        for j in range(n_v4_scales):\n",
        "            print(\"Scale\", j, \"max loss:\", tf.reduce_max(tf.nn.relu(pair_diff[0, 1, 0, 0, j, :, :])), \"total losses:\", tf.reduce_sum(tf.nn.relu(pair_diff[0, 1, 0, 0, j, :, :])))\n",
        "            ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "            ax[j].imshow(tf.nn.relu(pair_diff[0, 1, 0, 0, j, :, :]), alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "        figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "        fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "        print(\"RAW V4 GAINS for size, without min/max limit\")\n",
        "        for j in range(n_v4_scales):\n",
        "            print(\"Scale\", j, \"max gain:\", tf.reduce_max(tf.nn.relu(-pair_diff[0, 1, 0, 0, j, :, :])), \"total gain:\", tf.reduce_sum(tf.nn.relu(-pair_diff[0, 1, 0, 0, j, :, :])))\n",
        "            ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "            ax[j].imshow(tf.nn.relu(-pair_diff[0, 1, 0, 0, j, :, :]), alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "        figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "        fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "        print(\"LEFT GLYPH v4 response for size, without min/max limit, 0-3\")\n",
        "        for j in range(n_v4_scales):\n",
        "            print(\"Channel\", j, \"max\", tf.reduce_max(self.get_val(\"left_v4_response\")[0, 1, 0, 0, j, :, :]), \"sum\", tf.reduce_sum(self.get_val(\"left_v4_response\")[0, 1, 0, 0, j, :, :]))\n",
        "            ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "            #ax[j].imshow(self.get_val(\"left_v4_response\")[0, 1, 0, 0, j, :, :], alpha=0.7)\n",
        "            ax[j].imshow(tf.reduce_sum(self.get_val(\"left_v4_response\")[0, 1, 0, 0:3, j, :, :], [0]), alpha=0.7)\n",
        "            #ax[j].imshow(tf.reduce_sum(self.get_val(\"left_v4_response\")[0, 1, j, 0:3, 0, :, :], [0]), alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "        figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "        fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "        print(\"LEFT GLYPH v4 response for size, without min/max limit\")\n",
        "        for j in range(n_v4_scales):\n",
        "            print(\"Channel\", j, \"max\", tf.reduce_max(self.get_val(\"left_v4_response\")[0, 1, 0, 0, j, :, :]), \"sum\", tf.reduce_sum(self.get_val(\"left_v4_response\")[0, 1, 0, 0, j, :, :]))\n",
        "            ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "            ax[j].imshow(tf.reduce_sum(self.get_val(\"left_v4_response\")[0, 1, :, 3:, j, :, :], [0,1]), alpha=0.7)\n",
        "            #ax[j].imshow(tf.reduce_sum(self.get_val(\"left_v4_response\")[0, 1, j, :, 0, :, :], [0]), alpha=0.7)\n",
        "            #ax[j].imshow(tf.reduce_sum(self.get_val(\"left_v4_response\")[0, 1, j, 3:, 0, :, :], [0]), alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "        maxv = tf.reduce_max(pair_cost)\n",
        "        minv = tf.reduce_min(pair_cost)\n",
        "        ex = max(abs(maxv), abs(minv))\n",
        "        print(\"COST of DIFF for size\")\n",
        "        for j in range(n_v4_scales):\n",
        "            ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "            ax[j].imshow(pair_cost[0, 1, 0, 0, j, :, :], alpha=0.7, vmin=-ex, vmax=ex)\n",
        "        plt.show()\n",
        "\n",
        "        self.print_weights(\"v4_layer\")\n",
        "\n",
        "        print(\"costs\")\n",
        "        print(\"worst violation\", self.get_val(\"worst_violation\"))\n",
        "        plt.plot(np.transpose(self.get_val(\"pair_total_cost\")))\n",
        "        plt.show()\n",
        "\n",
        "        print(\"raw_losses\")\n",
        "        plt.plot(tf.reshape(tf.einsum(\"bdsoc->dbsoc\", tf.reduce_sum(pair_diff, [5,6])), [n_sample_distances, batch_size*n_v4_scales]))\n",
        "        plt.show()\n",
        "\n",
        "        self.print_weights(\"cost_layer\")\n",
        "\n",
        "model = get_keras_model()\n",
        "model.compile(loss=(lambda _, c: c), optimizer=tf.keras.optimizers.Adam(.001))\n",
        "\n",
        "testing = 0\n",
        "\n",
        "prepared_dataset = translated_dataset.shuffle(batch_size).batch(batch_size).prefetch(batch_size)\n",
        "\n",
        "if True:\n",
        "    history = model.fit(prepared_dataset,\n",
        "                        callbacks=[MonitorProgressCallback(prepared_dataset.as_numpy_iterator(), 1 if testing else 5)],\n",
        "                        epochs=(1 if testing else 1000),\n",
        "                        steps_per_epoch=(1 if testing else 20), use_multiprocessing=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kv_RPn_cSbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scales = np.array([1.4,1.6,1.75,1.83,1.9])\n",
        "inner_widths = np.array([1.4,1.25,1.15,1.03,0.98]) # Making these bigger shrinks the circle.\n",
        "#scales = np.log(m) - inner_widths**2\n",
        "freq_masks = (1/(r**2 + eps)) * np.exp(-(np.log(r + eps) - scales[None, :, None, None])**2 / (2 * inner_widths[None, :, None, None])**2)\n",
        "for i in range(n_v4_scales):\n",
        "    print(\"i\", i, \"total = \", np.sum(freq_masks[0, i, :, :]))\n",
        "    plt.imshow(freq_masks[0, i, :, :])\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "print(\"AND THE TOTAL\")\n",
        "plt.imshow(np.sum(freq_masks[0, :, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                            int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))], (0)))\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}