{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YinYangFit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7C37IyQfwGEM942+vN85N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skosch/YinYangFit/blob/master/YinYangFit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnMfGpUTnOrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n",
        "\n",
        "if tf.test.is_gpu_available():\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "      raise SystemError('GPU device not found')\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "elif False:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    \n",
        "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "    tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA7klPDBnZ-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "pi = np.pi\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.cm as cm\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import random; random.seed()\n",
        "import math\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm as tqdm\n",
        "import sys\n",
        "from functools import reduce\n",
        "import random\n",
        "from itertools import cycle, islice, product\n",
        "import operator\n",
        "from scipy.linalg import toeplitz\n",
        "from scipy.optimize import minimize_scalar\n",
        "\n",
        "!pip install --quiet tensorfont\n",
        "!pip install --quiet fonttools\n",
        "!pip install --quiet --upgrade fontParts\n",
        "!pip install booleanOperations\n",
        "!pip install --quiet --upgrade ufo-extractor\n",
        "!pip install --quiet --upgrade defcon\n",
        "!pip install --quiet --upgrade ufo2ft\n",
        "import fontParts\n",
        "import extractor\n",
        "import defcon\n",
        "from ufo2ft import compileOTF\n",
        "\n",
        "from tensorfont import Font\n",
        "\n",
        "print(\"✓ Dependencies imported.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrGlCMQnnfcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget -q -O OpenSans-Regular.ttf https://github.com/googlefonts/opensans/blob/master/ttfs/OpenSans-Regular.ttf?raw=true\n",
        "#!wget -q -O Roboto.ttf https://github.com/google/fonts/blob/master/apache/roboto/Roboto-Regular.ttf?raw=true\n",
        "#!wget -q -O Roboto.otf https://github.com/AllThingsSmitty/fonts/blob/master/Roboto/Roboto-Regular/Roboto-Regular.otf?raw=true\n",
        "#!wget -q -O DroidSerif.ttf https://github.com/datactivist/sudweb/blob/master/fonts/droid-serif-v6-latin-regular.ttf?raw=true\n",
        "!wget -q -O CrimsonItalic.otf https://github.com/skosch/Crimson/blob/master/Desktop%20Fonts/OTF/Crimson-Italic.otf?raw=true\n",
        "#!wget -q -O CrimsonBold.otf https://github.com/skosch/Crimson/blob/master/Desktop%20Fonts/OTF/Crimson-Bold.otf?raw=true \n",
        "#!wget -q -O CrimsonRoman.otf https://github.com/alif-type/amiri/blob/master/Amiri-Regular.ttf?raw=true\n",
        "\n",
        "!wget -q -O CrimsonRoman.otf https://github.com/skosch/Crimson/blob/master/Desktop%20Fonts/OTF/Crimson-Roman.otf?raw=true\n",
        "print(\"✓ Font file(s) downloaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxGlXUzWngSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glyph_char_list = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "#glyph_char_list = \"bdghijlmnopqu\" # straight letters only\n",
        "#glyph_char_list = \"abgjqrst\"\n",
        "#glyph_char_list = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "#glyph_char_list = \"OO\"\n",
        "#glyph_char_list = \"abc\"\n",
        "\n",
        "# ==== Create Font ====\n",
        "factor = 1.0 #1.539  # This scales the size of everything\n",
        "filename = \"CrimsonRoman.otf\"\n",
        "f = Font(filename, 34 * factor) # Roboto.ttf CrimsonRoman.otf # 34 for lowercase\n",
        "box_height = int(f.full_height_px)\n",
        "box_width = int(161 * factor) # 121\n",
        "box_width += (box_width + 1) % 2\n",
        "print(\"Box size:\", box_height, \"×\", box_width)\n",
        "\n",
        "batch_size = 2\n",
        "sample_distance_deltas = [-2, 0, 2]\n",
        "sample_distance_factors = [.5, 1., 2.0]\n",
        "n_sample_distances = len(sample_distance_deltas)\n",
        "\n",
        "n_v1_scales = 5\n",
        "n_b_scales = 1\n",
        "n_v1_orientations = 4\n",
        "n_v4_scales = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROjMw0u2nk7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sigmas(skip_scales=0):\n",
        "    sigmas = []\n",
        "    for s in range(n_v1_scales):\n",
        "        min_sigma = 0.7\n",
        "        max_sigma = box_width / 15\n",
        "        sigmas.append((max_sigma - min_sigma) * (s + skip_scales)**2 / (n_v1_scales - 1)**2 + min_sigma)\n",
        "        #sigmas.append((max_sigma - min_sigma) * s / n_v1_scales + min_sigma)\n",
        "    return np.array(sigmas)\n",
        "\n",
        "print(\"Spatial frequency scales:\", get_sigmas())\n",
        "\n",
        "def get_v1_filter_bank(skip_scales, display_filters=False):\n",
        "    def rotated_mgrid(oi):\n",
        "        \"\"\"Generate a meshgrid and rotate it by RotRad radians.\"\"\"\n",
        "        rotation = np.array([[ np.cos(pi*oi/n_v1_orientations), np.sin(pi*oi/n_v1_orientations)],\n",
        "                             [-np.sin(pi*oi/n_v1_orientations), np.cos(pi*oi/n_v1_orientations)]])\n",
        "        hh = box_height # / 2\n",
        "        bw = box_width # / 2\n",
        "        y, x = np.mgrid[-hh:hh, -bw:bw].astype(np.float32)\n",
        "        y += 0.5 # 0 if box_height % 2 == 0 else 0.5\n",
        "        x += 0.5 # 0 if box_width % 2 == 0 else 0.5\n",
        "        return np.einsum('ji, mni -> jmn', rotation, np.dstack([x, y]))\n",
        "\n",
        "    def get_filter(s, theta):\n",
        "        x, y = rotated_mgrid(theta)\n",
        "\n",
        "        # To minimize ringing etc., we create the filter as is, then run it through the DFT.\n",
        "\n",
        "        # First derivative (odd filter/up-down)\n",
        "        d1_space = np.exp(-(x**2+y**2)/(2*s**2))*x/(2*pi*s**4)\n",
        "        d1_relu_sum = np.sum(d1_space * (d1_space > 0))\n",
        "        d1 = np.fft.fft2(np.fft.ifftshift(d1_space + 1j * np.zeros_like(d1_space)))\n",
        "\n",
        "        # Second derivative (even filter/mexican hat):\n",
        "        s2 = s * .85 # To make them about the same width\n",
        "        d2_space = np.exp(-(x**2+y**2)/(2*s2**2))/(2*pi*s2**4) - np.exp(-(x**2+y**2)/(2*s2**2))*x**2/(2*pi*s2**6)\n",
        "        d2_relu_sum = np.sum(d2_space * (d2_space > 0))\n",
        "        d2 = (d1_relu_sum / d2_relu_sum) * np.fft.fft2(np.fft.ifftshift(d2_space + 1j * np.zeros_like(d2_space)))\n",
        "\n",
        "        return (d1 + 1j*d2) / (np.max(tf.abs(d1+1j*d2))) # Max output should be about 0.2, which leaves lots of flexibility for the HRA later\n",
        "\n",
        "    filter_bank = np.zeros((n_v1_scales, n_v1_orientations, 2*box_height, 2*box_width)).astype(np.complex64)\n",
        "\n",
        "    if display_filters:\n",
        "        sizediv = 20\n",
        "        fig, ax = plt.subplots(nrows=n_v1_scales*2, ncols=n_v1_orientations, gridspec_kw = {'wspace':0, 'hspace':0}, figsize=(box_width * n_v1_orientations / sizediv, box_height * n_v1_scales * 2 / sizediv))\n",
        "\n",
        "    sigmas = get_sigmas()\n",
        "    for s in range(n_v1_scales):\n",
        "        sigma = sigmas[s]\n",
        "        for o in range(n_v1_orientations):\n",
        "            f = get_filter(sigma, o)\n",
        "            if display_filters:\n",
        "                mx = np.max(np.abs(np.imag(np.fft.ifft2(f))))\n",
        "                ax[s*2, o].imshow(np.real(np.fft.fftshift(np.fft.ifft2(f))), cmap=\"RdBu\", vmin=-mx, vmax=mx)\n",
        "                ax[s*2, o].set_aspect(\"auto\")\n",
        "                ax[s*2, o].set_yticklabels([])\n",
        "                ax[s*2+1, o].imshow(np.imag(np.fft.fftshift(np.fft.ifft2(f))), cmap=\"RdBu\", vmin=-mx, vmax=mx)\n",
        "                ax[s*2+1, o].set_aspect(\"auto\")\n",
        "                ax[s*2+1, o].set_yticklabels([])\n",
        "            filter_bank[s, o, :, :] = f\n",
        "\n",
        "    if display_filters:\n",
        "        plt.show()\n",
        "\n",
        "    return filter_bank.astype(np.complex64)\n",
        "\n",
        "filter_bank = get_v1_filter_bank(0, display_filters=True)\n",
        "\n",
        "\n",
        "def apply_filter_bank(input_image, filter_bank):\n",
        "    \"\"\"\n",
        "    Input image should have dimensions <h, w> or <s, o, h, w> or <b, s, o, h, w, d>.\n",
        "    Filter bank should have dimensions <s, o, h, w>\n",
        "    \"\"\"\n",
        "    bdsohw_input_image = input_image[None, None, None, None, :, :]\n",
        "\n",
        "    # pad image to filter size, which is 2*box_height, 2*box_width (to prevent too much wrapping)\n",
        "    padded_input = tf.pad(bdsohw_input_image, [[0, 0], [0, 0], [0, 0], [0, 0],\n",
        "                            [int(np.ceil(box_height / 2)), int(box_height / 2)],\n",
        "                            [int(np.ceil(box_width / 2)), int(box_width / 2)]], mode='CONSTANT')\n",
        "\n",
        "    input_in_freqdomain = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(padded_input, tf.zeros_like(padded_input))))\n",
        "\n",
        "    padded_result = tf.signal.ifft2d(input_in_freqdomain * filter_bank[None, None, :, :, :, :])\n",
        "\n",
        "    presult = tf.signal.fftshift(padded_result[0, 0, :, :, :, :], [2, 3])\n",
        "\n",
        "    return presult[:, :, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                        int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo6SiTQ9zoL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pf = 3\n",
        "\n",
        "eps = np.finfo(np.float32).tiny\n",
        "u, v = np.mgrid[-box_height*pf/2:box_height*pf/2,-box_width*pf/2:box_width*pf/2].astype(np.float32)\n",
        "r = np.sqrt(u**2 + v**2)[None, None, :, :] / (box_height*pf/2)\n",
        "r[r == 0] = 0.5\n",
        "angle = np.arctan2(u, v)[None, None, :, :] # <b, d, s, o, c, h, w>\n",
        "angles = np.arange(n_v1_orientations)[None, :, None, None].astype(np.float32)/n_v1_orientations\n",
        "angle_mask_widths = 4. * np.ones((n_v1_scales, n_v1_orientations)).astype(np.float32)\n",
        "\n",
        "def make_blur_filters(e): # Returns masks of shape <o, c, h, w>\n",
        "    radial_mask = (1/(r + eps)) ** e\n",
        "    distance_mask = (1/(r + eps)) ** (e+1)\n",
        "\n",
        "    # Uses von-Mises distribution (via Bessel function)\n",
        "    bp_angle_masks = tf.exp(-angle_mask_widths[:, :, None, None] * tf.cos(angle - pi - pi * angles)) / (2*pi*tf.math.bessel_i0(angle_mask_widths[:, :, None, None]))\n",
        "    bn_angle_masks = tf.exp(-angle_mask_widths[:, :, None, None] * tf.cos(angle - pi * angles)) / (2*pi*tf.math.bessel_i0(angle_mask_widths[:, :, None, None]))\n",
        "\n",
        "    x1 = tf.concat([radial_mask * bp_angle_masks, radial_mask * bn_angle_masks], axis=1)\n",
        "    x2 = tf.concat([distance_mask * bp_angle_masks, distance_mask * bn_angle_masks], axis=1)\n",
        "\n",
        "    return (x1, x2)\n",
        "\n",
        "blur_e = 2.\n",
        "(x1_filter, x2_filter) = make_blur_filters(blur_e)\n",
        "x1_filter_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(x1_filter, 0.), [2,3]))\n",
        "x2_filter_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(x2_filter, 0.), [2,3]))\n",
        "print(x1_filter_fft.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hbbp_6ap8LP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Render glyphs\n",
        "\n",
        "def get_glyph_image(glyph_char):\n",
        "    \"\"\"Returns a np.array of shape [box_height, box_width] containing the glyph at the center.\"\"\"\n",
        "    return f.glyph(glyph_char).as_matrix(normalize=True).with_padding_to_constant_box_width(box_width).astype(np.float32)\n",
        "\n",
        "def get_glyph_ink_width(glyph_char):\n",
        "    \"\"\"Returns the width of the rendered glyph in pixels.\"\"\"\n",
        "    return f.glyph(glyph_char).ink_width\n",
        "\n",
        "def get_v1_response(glyph_image):\n",
        "    \"\"\"Returns a np.array of shape [n_v1_scales, n_v1_orientations, box_height, box_width] and type complex64,\n",
        "    containing the local responses to the V1 filter bank (after inverse Fourier transform, i.e. in the spatial domain).\"\"\"\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "        filtered = apply_filter_bank(glyph_image, filter_bank)\n",
        "    return filtered\n",
        "\n",
        "def get_v4_strength(glyph_v1_response):\n",
        "    \"\"\"Returns a np.array of shape [n_v1_scales, 2*n_v1_orientations, box_height, box_width].\"\"\"\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "        # Pad the image, fft convolve it, \n",
        "        padded_image = tf.pad(tf.abs(glyph_v1_response), [[0, 0], [0, 0], [int((pf-1)*box_height/2), int((pf-1)*box_height/2)],\n",
        "                                                                  [int((pf-1)*box_width/2), int((pf-1)*box_width/2)]])\n",
        "        padded_image_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(tf.concat(2*[padded_image], axis=1), 0.), [2, 3]))\n",
        "        x1_full = tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(padded_image_fft * x1_filter_fft), [2, 3]))\n",
        "        x2_full = tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(padded_image_fft * x2_filter_fft), [2, 3]))\n",
        "\n",
        "        x1 = x1_full[:, :, int(np.ceil(box_height * (pf-1) / 2)):int(box_height + np.ceil(box_height * (pf-1)/ 2)),\n",
        "                        int(np.ceil(box_width  * (pf-1)/ 2)):int(box_width + np.ceil(box_width * (pf-1)/ 2))]\n",
        "        x2 = x2_full[:, :, int(np.ceil(box_height * (pf-1) / 2)):int(box_height + np.ceil(box_height * (pf-1)/ 2)),\n",
        "                        int(np.ceil(box_width  * (pf-1)/ 2)):int(box_width + np.ceil(box_width * (pf-1)/ 2))]\n",
        "\n",
        "        distances = x1 / x2\n",
        "        fullnesses = x1 * distances ** (blur_e - 1)\n",
        "        strengths = fullnesses / distances\n",
        "        return strengths\n",
        "\n",
        "\n",
        "glyph_images = {c: get_glyph_image(c) for c in tqdm(glyph_char_list)}\n",
        "print(\"  ✓\", len(glyph_char_list), \"glyphs rendered.\", flush=True)\n",
        "glyph_ink_widths = {c: get_glyph_ink_width(c) for c in tqdm(glyph_char_list)}\n",
        "print(\"  ✓\", len(glyph_char_list), \"glyphs measured.\", flush=True)\n",
        "glyph_v1_responses = {c: get_v1_response(glyph_images[c]) for c in tqdm(glyph_char_list)}\n",
        "print(\"  ✓\", len(glyph_char_list), \"glyphs filtered.\", flush=True)\n",
        "glyph_v4_strengths = {c: get_v4_strength(glyph_v1_responses[c]) for c in tqdm(glyph_char_list)}\n",
        "print(\"  ✓\", len(glyph_char_list), \"glyphs strengthed.\", flush=True)\n",
        "print(\"glyph\", glyph_v4_strengths[\"a\"].shape)\n",
        "print(\"glyph\", glyph_v1_responses[\"a\"].shape)\n",
        "\n",
        "# 1a. Show an example of filtered glyphs\n",
        "for si in range(n_v1_scales):\n",
        "    print(\"Scale:\", si)\n",
        "    #plt.imshow(glyph_images[\"b\"], cmap=\"gray\")\n",
        "    plt.imshow(np.sum(np.abs(glyph_v1_responses[\"a\"][si, :, :, :]), (0))**2, cmap=\"Reds\", alpha=1.0)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "# 1b. Show an example of filtered glyphs\n",
        "for si in range(n_v1_scales):\n",
        "    print(\"SCALE:\", si)\n",
        "    #plt.imshow(glyph_images[\"b\"], cmap=\"gray\")\n",
        "    plt.imshow(tf.reduce_sum(glyph_v4_strengths[\"a\"][si, :, :, :], [0]), cmap=\"Reds\", alpha=1.0)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "plt.imshow(glyph_images[\"a\"], cmap=\"gray\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZtCijES0gKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. Assemble pairs\n",
        "\n",
        "def get_pair_translations(char1, char2, distance_deltas, distance_factors=None):\n",
        "    \"\"\"Returns two 1D arrays of distances (in pixels) by which the left and right glyph need to be translated (i.e. shifted horizontally)\n",
        "    in order to place the two glyphs at the desired distances.\n",
        "    \n",
        "    Example: distance_deltas = [-2, 0, 2] or distance_factors=[0.7, 1.0, 1.5]\n",
        "    \"\"\"\n",
        "\n",
        "    optimal_distance = int(f.pair_distance(char1, char2) + f.minimum_ink_distance(char1, char2))\n",
        "\n",
        "    if distance_factors is None:\n",
        "        if distance_deltas is None:\n",
        "            raise ValueError(\"Must provide either distance_deltas or distance_factors\")\n",
        "        \n",
        "        sample_distances = optimal_distance + np.array(distance_deltas)\n",
        "    else:\n",
        "        if distance_deltas is not None:\n",
        "            raise ValueError(\"Must provide either distance_deltas or distance_factors, not both\")\n",
        "\n",
        "        sample_distances = optimal_distance * np.array(distance_factors)\n",
        "\n",
        "    total_width_at_minimum_ink_distance = glyph_ink_widths[char1] + glyph_ink_widths[char2] - f.minimum_ink_distance(char1, char2)\n",
        "    total_ink_width = glyph_ink_widths[char1] + glyph_ink_widths[char2]\n",
        "    ink_width_left = np.floor(total_ink_width / 4)\n",
        "    ink_width_right = np.ceil(total_ink_width / 4)\n",
        "    sample_distances_left = np.ceil(sample_distances / 2)\n",
        "    sample_distances_right = np.floor(sample_distances / 2)\n",
        "\n",
        "    left_translations = (-(np.ceil(total_width_at_minimum_ink_distance/2) + sample_distances_left) - (-ink_width_left)).astype(np.int32)\n",
        "    right_translations = ((np.floor(total_width_at_minimum_ink_distance/2) + sample_distances_right) - ink_width_right).astype(np.int32)\n",
        "    \n",
        "    return (left_translations, right_translations)\n",
        "    \n",
        "left_images = []\n",
        "right_images = []\n",
        "left_v1_responses = []\n",
        "right_v1_responses = []\n",
        "left_v4_strengths = []\n",
        "right_v4_strengths = []\n",
        "left_translations = []\n",
        "right_translations = []\n",
        "\n",
        "for c1 in tqdm(glyph_char_list):\n",
        "    for c2 in reversed(glyph_char_list):\n",
        "        left_images.append(glyph_images[c1])\n",
        "        right_images.append(glyph_images[c2])\n",
        "        left_v1_responses.append(glyph_v1_responses[c1])\n",
        "        right_v1_responses.append(glyph_v1_responses[c2])\n",
        "        left_v4_strengths.append(glyph_v4_strengths[c1])\n",
        "        right_v4_strengths.append(glyph_v4_strengths[c2])\n",
        "\n",
        "        lt, rt = get_pair_translations(c1, c2, None, sample_distance_factors) #sample_distance_deltas\n",
        "        left_translations.append(lt)\n",
        "        right_translations.append(rt)\n",
        "\n",
        "print(\"  ✓\", len(glyph_char_list)**2, \"pairs assembled.\")\n",
        "\n",
        "# 3. Set up generator to yield pairs, and wrap generator in a tf.Dataset\n",
        "\n",
        "def return_pair():\n",
        "    i = 0\n",
        "    while i < len(left_images):\n",
        "        yield {\n",
        "            \"left_image\": left_images[i],\n",
        "            \"right_image\": right_images[i],\n",
        "            \"left_v1_response\": left_v1_responses[i],\n",
        "            \"right_v1_response\": right_v1_responses[i],\n",
        "            \"left_v4_strength\": left_v4_strengths[i],\n",
        "            \"right_v4_strength\": right_v4_strengths[i],\n",
        "            \"left_translations\": left_translations[i],\n",
        "            \"right_translations\": right_translations[i],\n",
        "        }\n",
        "        i = (i + 1) % len(left_images)\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "     return_pair,\n",
        "     {\n",
        "      \"left_image\": tf.float32,\n",
        "      \"right_image\": tf.float32,\n",
        "      \"left_v1_response\": tf.complex64,\n",
        "      \"right_v1_response\": tf.complex64,\n",
        "      \"left_v4_strength\": tf.float32,\n",
        "      \"right_v4_strength\": tf.float32,\n",
        "      \"left_translations\": tf.int32,\n",
        "      \"right_translations\": tf.int32,\n",
        "     },\n",
        "     {\n",
        "      \"left_image\": tf.TensorShape([box_height, box_width]),\n",
        "      \"right_image\": tf.TensorShape([box_height, box_width]),\n",
        "      \"left_v1_response\": tf.TensorShape([n_v1_scales, n_v1_orientations, box_height, box_width]),\n",
        "      \"right_v1_response\": tf.TensorShape([n_v1_scales, n_v1_orientations, box_height, box_width]),\n",
        "      \"left_v4_strength\": tf.TensorShape([n_v1_scales, 2*n_v1_orientations, box_height, box_width]),\n",
        "      \"right_v4_strength\": tf.TensorShape([n_v1_scales, 2*n_v1_orientations, box_height, box_width]),\n",
        "      \"left_translations\": tf.TensorShape([n_sample_distances,]),\n",
        "      \"right_translations\": tf.TensorShape([n_sample_distances,])\n",
        "     },\n",
        ")\n",
        "\n",
        "print(\"\\n  ✓ Dataset ready.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-LYhZo_riZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. Apply horizontal translations in the dataset\n",
        "\n",
        "def translate_4d_image(input_image, translations):\n",
        "    \"\"\"Shifts images to left/right and back-fills with zeros.\n",
        "    @param image: <sizes, orientations, height, width>\n",
        "    @param translations: <len(translations)>\n",
        "    @output        <len(translations), sizes, orientations, height, width>\n",
        "    \"\"\"\n",
        "\n",
        "    images = tf.tile(input_image[:, :, :, :, None], [1, 1, 1, 1, translations.shape[0]]) # create len(shifts) channel copies\n",
        "    fill_constant = 0\n",
        "    left = tf.maximum(0, tf.reduce_max(translations)) # positive numbers are shifts to the right, for which we need to add zeros on the left\n",
        "    right = -tf.minimum(0, tf.reduce_min(translations)) # negative numbers are shifts to the left, for which we need to add zeros on the right\n",
        "    left_mask = tf.ones(shape=(tf.shape(images)[0], tf.shape(images)[1], tf.shape(images)[2], left, tf.shape(images)[4]), dtype=images.dtype) * fill_constant\n",
        "    right_mask = tf.ones(shape=(tf.shape(images)[0], tf.shape(images)[1], tf.shape(images)[2], right, tf.shape(images)[4]), dtype=images.dtype) * fill_constant\n",
        "    padded_images = tf.concat([left_mask, images, right_mask], axis=3) # pad on axis 3 (i.e. width-wise)\n",
        "\n",
        "    # Now that the images are all padded, we need to crop them to implement the shifts.\n",
        "    def crop_image_widthwise(image_and_shift):\n",
        "        image = image_and_shift[0] # sohw\n",
        "        shift = image_and_shift[1] # \n",
        "        return image[:, :, :, left-shift:left-shift+input_image.shape[3]] # positive shift: left-shift\n",
        "\n",
        "    result = tf.map_fn(\n",
        "        crop_image_widthwise,\n",
        "        (tf.einsum(\"sohwd->dsohw\", padded_images), translations),\n",
        "        dtype=images.dtype)\n",
        "\n",
        "    # Manually ensure that the width-dimension hasn't changed\n",
        "    s = list(result.shape)\n",
        "    s[-1] = box_width\n",
        "    result.set_shape(s)\n",
        "\n",
        "    return result\n",
        "\n",
        "def apply_translations(d):\n",
        "    d[\"left_image\"] = translate_4d_image(d[\"left_image\"][None, None, :, :], d[\"left_translations\"])[:, 0, 0, :, :]\n",
        "    d[\"right_image\"] = translate_4d_image(d[\"right_image\"][None, None, :, :], d[\"right_translations\"])[:, 0, 0, :, :]\n",
        "    d[\"left_v1_response\"] = translate_4d_image(d[\"left_v1_response\"], d[\"left_translations\"])\n",
        "    d[\"right_v1_response\"] = translate_4d_image(d[\"right_v1_response\"], d[\"right_translations\"])\n",
        "    d[\"left_v4_strength\"] = translate_4d_image(d[\"left_v4_strength\"], d[\"left_translations\"])\n",
        "    d[\"right_v4_strength\"] = translate_4d_image(d[\"right_v4_strength\"], d[\"right_translations\"])\n",
        "    del d[\"left_translations\"]\n",
        "    del d[\"right_translations\"]\n",
        "    return (d, 0.)  # The zero here doesn't do anything and is just to make Keras happy, because model.fit expects a dataset of 2-tuples where the second entry is the target value.\n",
        "\n",
        "translated_dataset = dataset.map(apply_translations)\n",
        "\n",
        "print(\"dataset shapes:\", translated_dataset.element_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qo5aVMk3sRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5. Utility functions\n",
        "eps = np.finfo(np.float32).tiny\n",
        "\n",
        "def invspa(t):\n",
        "    return np.log(np.exp(t) - 1).astype(np.float32)\n",
        "\n",
        "def invsp(t):\n",
        "    if t == 0:\n",
        "        return -1e10\n",
        "    else:\n",
        "        return np.log(np.exp(t) - 1).astype(np.float32)\n",
        "\n",
        "def sp(t):\n",
        "    return tf.nn.softplus(t)\n",
        "\n",
        "# 6. Generating G-cell fragments\n",
        "\n",
        "u, v = np.mgrid[-box_height:box_height,-box_width:box_width].astype(np.float32)\n",
        "u = u / (box_width)\n",
        "v = v / (box_width)\n",
        "r = np.sqrt(u**2 + v**2)[None, None, :, :]\n",
        "r[r == 0] = 0.5\n",
        "angle = np.arctan2(u, v)[None, None, :, :] # <b, d, s, o, c, h, w>\n",
        "angles = np.arange(n_v1_orientations)[:, None, None, None].astype(np.float32)/n_v1_orientations\n",
        "angle_mask_widths = 4. * np.ones((n_v1_orientations, n_v4_scales)).astype(np.float32)\n",
        "\n",
        "def make_v4_filters(k, spa, sn, hp, hn, cp, cn): # Returns masks of shape <o, c, h, w>\n",
        "    x_n = n_v4_scales + 2\n",
        "    \n",
        "    xs = tf.linspace(cp, 1, x_n) ** k * cn # k can be one or above (or below)\n",
        "    \n",
        "    a = xs[:-2][None, :, None, None]\n",
        "    c = xs[1:-1][None, :, None, None]\n",
        "    b = xs[2:][None, :, None, None]\n",
        "    \n",
        "    triangles = tf.where(tf.reduce_all([r > a, r <= c], axis=0), 2*(r-a)/((b-a)*(c-a)),\n",
        "                        tf.where(tf.reduce_all([r > c, r < b], axis=0), 2*(b-r)/((b-a)*(b-c)), eps))\n",
        "\n",
        "    radial_mask = (tf.nn.relu(triangles) + eps) / (eps + 2*(b-a))\n",
        "\n",
        "    #flat_indices = tf.reshape((r * box_width).astype(np.int), [4 * box_height * box_width])\n",
        "    #radial_mask = tf.reshape(tf.gather(sp(k), flat_indices), [1, 1, 2 * box_height, 2*box_width])\n",
        "\n",
        "    # Uses von-Mises distribution (via Bessel function)\n",
        "    bp_angle_masks = tf.exp(-angle_mask_widths[:, :, None, None] * tf.cos(angle - pi - pi * angles)) / (2*pi*tf.math.bessel_i0(angle_mask_widths[:, :, None, None]))\n",
        "    bn_angle_masks = tf.exp(-angle_mask_widths[:, :, None, None] * tf.cos(angle - pi * angles)) / (2*pi*tf.math.bessel_i0(angle_mask_widths[:, :, None, None]))\n",
        "\n",
        "    bp_masks = radial_mask * bp_angle_masks\n",
        "    bn_masks = radial_mask * bn_angle_masks\n",
        "\n",
        "    # Each bp/bn_mask fragment (the positive part) should add up to exactly one.\n",
        "    bp_masks_normed = 4*bp_masks / (eps + tf.reduce_sum((bp_masks)**2, [0, 2, 3], keepdims=True))\n",
        "    bn_masks_normed = 4*bn_masks / (eps + tf.reduce_sum((bn_masks)**2, [0, 2, 3], keepdims=True))\n",
        "\n",
        "    return tf.concat([bp_masks_normed, bn_masks_normed], axis=0)\n",
        "\n",
        "\n",
        "def make_blur_filters(exp1, exp2): # Returns masks of shape <o, c, h, w>\n",
        "    # TODO: add anisotropy\n",
        "    radial_mask = (1/(r + eps)) ** exp1\n",
        "    distance_mask = (1/(r + eps)) ** exp2\n",
        "\n",
        "    # Uses von-Mises distribution (via Bessel function)\n",
        "    bp_angle_masks = tf.exp(-angle_mask_widths[:, :, None, None] * tf.cos(angle - pi - pi * angles)) / (2*pi*tf.math.bessel_i0(angle_mask_widths[:, :, None, None]))\n",
        "    bn_angle_masks = tf.exp(-angle_mask_widths[:, :, None, None] * tf.cos(angle - pi * angles)) / (2*pi*tf.math.bessel_i0(angle_mask_widths[:, :, None, None]))\n",
        "\n",
        "    strength = tf.concat([radial_mask * bp_angle_masks, radial_mask * bn_angle_masks], axis=0)\n",
        "    distance = tf.concat([distance_mask * bp_angle_masks, distance_mask * bn_angle_masks], axis=0)\n",
        "\n",
        "    return (strength, distance)\n",
        "\n",
        "def make_losses_filters(g_spreads):\n",
        "    rs = r[None, ...] # <b, d, c, h, w>\n",
        "    gs = g_spreads[None, None, :, None, None]\n",
        "    \n",
        "    return tf.exp(-rs**2 / (2*gs**2)) / (gs * tf.math.sqrt(2.*3.14159276))\n",
        "\n",
        "\n",
        "# 7. V4 layer\n",
        "class V4Layer(tf.keras.layers.Layer):\n",
        "    def __init__(self, skip_v4_convolution=False, **kwargs):\n",
        "        super(V4Layer, self).__init__(**kwargs)\n",
        "\n",
        "        self.skip_v4_convolution = skip_v4_convolution\n",
        "\n",
        "        self.csf = self.add_weight(shape=((n_v1_scales, n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(np.array([3, 15, 25, 3, 1])[:, None], [1, n_v1_orientations]).astype(np.float32) / 200.),\n",
        "                                 name=\"csf\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.v1_hra_k = self.add_weight(shape=((n_v1_scales, n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([2.,2.,2.,2.,2.])[:, None], [1, n_v1_orientations])), # 1 to .02\n",
        "                                 name=\"v1_hra_k\",\n",
        "                                 trainable=True)\n",
        "        self.v1_hra_b = self.add_weight(shape=((n_v1_scales, n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([.5,.5,.5,.5,.5])[:, None], [1, n_v1_orientations])), # 1 to .02\n",
        "                                 name=\"v1_hra_b\",\n",
        "                                 trainable=True)\n",
        "\n",
        "\n",
        "        self.exp1 = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(3.0),\n",
        "                                 name=\"exp1\",\n",
        "                                 trainable=False)\n",
        "        self.exp2 = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(4.0),\n",
        "                                 name=\"exp2\",\n",
        "                                 trainable=False)\n",
        "\n",
        "        #self.v4_scales_exponent = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(1.5), name=\"v4_scales_exponent\", trainable=False)\n",
        "        #self.v4_scales_min = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(.54), name=\"v4_scales_min\", trainable=False)\n",
        "        #self.v4_scales_factor = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(0.75), name=\"v4_scales_factor\", trainable=False)\n",
        "#\n",
        "        #self.v4_widths_exponent = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(1.5), name=\"v4_widths_exponent\", trainable=False)\n",
        "        #self.v4_widths_min = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(.6), name=\"v4_widths_min\", trainable=False)\n",
        "        #self.v4_widths_factor = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(0.2), name=\"v4_widths_factor\", trainable=False)\n",
        "#\n",
        "        #self.v4_depression_scale_fraction = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(np.array([0.3, .3, .3, .3, .3]).astype(np.float32)), name=\"v4_depression_scale_fraction\", trainable=True)\n",
        "        #self.v4_inner_negative_depth = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(np.array([1.,1.,1.,1.,1.]).astype(np.float32)), name=\"v4_inner_negative_depth\", trainable=True)\n",
        "\n",
        "        # How far away from the center we are\n",
        "        #self.v4_cp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.0125, 0.016, 0.021, 0.03, 0.056, 0.08, .12, .2]).astype(np.float32))), name=\"v4_cp\", trainable=True)\n",
        "        #self.v4_cn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.0125, 0.016, 0.021, 0.03, 0.056, 0.08, .12, .2]).astype(np.float32) * 0.16)), name=\"v4_cn\", trainable=True)\n",
        "        self.v4_cp = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(0.2), name=\"v4_cp\", trainable=False)\n",
        "        self.v4_cn = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(0.25), name=\"v4_cn\", trainable=False)\n",
        "        # How wide the rims are\n",
        "        self.v4_sp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.00015, 0.00026, 0.00057, 0.00109, .00216, .0036, .0060, .0097]).astype(np.float32))), name=\"v4_sp\", trainable=True)\n",
        "        self.v4_sn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.00015, 0.00026, 0.00057, 0.00109, .00216, .0036, .0060, .0097]).astype(np.float32) * .25)), name=\"v4_sn\", trainable=True)\n",
        "        # How deep the rims are\n",
        "        self.v4_hp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([.8, .8, .8, .8, .8, .8, .8, .8]).astype(np.float32))), name=\"v4_hp\", trainable=True)\n",
        "        self.v4_hn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([.4, .4, .4, .4, .4, .4, .4, .4]).astype(np.float32)*4.)), name=\"v4_hn\", trainable=True)\n",
        "\n",
        "        #self.v4_cp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.03]).astype(np.float32))), name=\"v4_cp\", trainable=True)\n",
        "        #self.v4_cp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(np.array([-3]).astype(np.float32)), name=\"v4_cp\", trainable=True)\n",
        "        #self.v4_cn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.03]).astype(np.float32))), name=\"v4_cn\", trainable=True)\n",
        "        ## How wide the rims are\n",
        "        ##self.v4_sp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.00109]).astype(np.float32))), name=\"v4_sp\", trainable=True)\n",
        "        #self.v4_sp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(np.array([.2]).astype(np.float32)), name=\"v4_sp\", trainable=True)\n",
        "        #self.v4_sn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([0.00109]).astype(np.float32))), name=\"v4_sn\", trainable=True)\n",
        "        ## How deep the rims are\n",
        "        #self.v4_hp = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([.8]).astype(np.float32))), name=\"v4_hp\", trainable=True)\n",
        "        #self.v4_hn = self.add_weight(shape=(n_v4_scales), initializer=tf.keras.initializers.Constant(invspa(np.array([.4]).astype(np.float32)*4.)), name=\"v4_hn\", trainable=True)\n",
        "\n",
        "        self.kk = self.add_weight(shape=(), initializer=tf.keras.initializers.Constant(2.80), name=\"v4_kk\", trainable=False)\n",
        "\n",
        "        #self.v4_scales = self.add_weight(shape=(n_v4_scales),\n",
        "        #                              initializer=tf.keras.initializers.Constant(np.array([.4,1.1,2.1,4.0,7.5]).astype(np.float32)/box_width),\n",
        "        #                              #initializer=tf.keras.initializers.Constant(np.array([1.4,1.6,1.75,1.83,1.9]).astype(np.float32)),\n",
        "        #                              name=\"v4_scales\", trainable=False)\n",
        "        #self.v4_widths = self.add_weight(shape=(n_v4_scales),\n",
        "        #                                    initializer=tf.keras.initializers.Constant(np.array([.5,0.7,1.,1.7,3.8]).astype(np.float32)/box_width),\n",
        "        #                                    #initializer=tf.keras.initializers.Constant(np.array([1.4,1.25,1.15,1.03,.98]).astype(np.float32)),\n",
        "        #                                    name=\"v4_widths\", trainable=False)\n",
        "        self.v4_angle_mask_widths = self.add_weight(shape=(n_v1_orientations, n_v4_scales),\n",
        "                                                 initializer=tf.keras.initializers.Constant(4.),\n",
        "                                                 name=\"v4_angle_mask_widths\", trainable=False)\n",
        "        self.v4_filter_strengths = self.add_weight(shape=(n_v1_orientations, n_v4_scales),\n",
        "                                               initializer=tf.keras.initializers.Constant(1.),\n",
        "                                               name=\"v4_filter_strengths\", trainable=False)\n",
        "\n",
        "        self.v4_hra_k = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4, 1.4])[None, :], [2*n_v1_orientations, 1])),\n",
        "                                 #initializer=tf.keras.initializers.Constant(np.tile(invsp([1.4])[None, :], [2*n_v1_orientations, 1])),\n",
        "                                 name=\"v4_hra_k\",\n",
        "                                 trainable=True)\n",
        "        self.v4_hra_b = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(invsp([1.5,3,2,1,1, 1,1,1])[None, :], [2*n_v1_orientations, 1])),\n",
        "                                 #initializer=tf.keras.initializers.Constant(np.tile(invsp([1])[None, :], [2*n_v1_orientations, 1])),\n",
        "                                 name=\"v4_hra_b\",\n",
        "                                 trainable=True)\n",
        "\n",
        "\n",
        "        # Each ring should only be able to draw from \n",
        "        self.v1_v4_scale_weights = self.add_weight(shape=(n_v1_scales, n_v4_scales),\n",
        "                                 #initializer=tf.keras.initializers.Constant((eps + np.triu(np.ones((n_v1_scales, n_v4_scales))).astype(np.float32) * .5**toeplitz(np.zeros(n_v1_scales), np.arange(n_v4_scales)))),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.tile(np.array([.04, .1, .13, .04, .01])[:, None], [1, n_v4_scales]).astype(np.float32)),\n",
        "                                 #initializer=tf.keras.initializers.Constant(np.array([1])[None, :].astype(np.float32)),\n",
        "                                 name=\"v1_v4_scale_weights\",\n",
        "                                 trainable=True)\n",
        "        self.v1_v4_orientation_weights = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"v1_v4_orientation_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "\n",
        "        self.v1_blur_orientation_weights = self.add_weight(shape=(2*n_v1_orientations, n_v1_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"v1_blur_orientation_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.v4_b_scale_weights = self.add_weight(shape=(1, n_v4_scales),\n",
        "                                 #initializer=tf.keras.initializers.Constant((eps + np.triu(np.ones((n_v1_scales, n_v4_scales))).astype(np.float32) * .5**toeplitz(np.zeros(n_v1_scales), np.arange(n_v4_scales)))),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.)),\n",
        "                                 name=\"v4_b_scale_weights\",\n",
        "                                 trainable=True)\n",
        "        self.v4_b_orientation_weights = self.add_weight(shape=(2*n_v1_orientations, n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"v4_b_orientation_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        # Using this for filtering\n",
        "        self.g_hra_k = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.array([0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4]).astype(np.float32) / 20.),\n",
        "                                 name=\"g_hra_k\",\n",
        "                                 trainable=True)\n",
        "        self.g_hra_b = self.add_weight(shape=(n_v4_scales),\n",
        "                                 #initializer=tf.keras.initializers.Constant(0.1),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp([.4]).astype(np.float32)),\n",
        "                                 name=\"g_hra_b\",\n",
        "                                 trainable=True)\n",
        "\n",
        "\n",
        "        #g_scale_scores = self.g_scale_score_factor ** (sp(self.g_hra_k) * np.arange(n_v4_scales).astype(np.float32))\n",
        "\n",
        "        self.g_scale_score_factor = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(0.4),\n",
        "                                 name=\"g_scale_score_factor\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.feedback_modulation_strength = self.add_weight(shape=(1, 2*n_v1_orientations, 1, 1),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.)),\n",
        "                                 name=\"feedback_modulation_strength\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.b_dn_b = self.add_weight(shape=(1, 2*n_v1_orientations),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(0.25)),\n",
        "                                 name=\"b_dn_b\",\n",
        "                                 trainable=True)\n",
        "        self.b_dn_k = self.add_weight(shape=(1, 2*n_v1_orientations),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(2.2)),\n",
        "                                 name=\"b_dn_k\",\n",
        "                                 trainable=True)\n",
        "        self.b_dn_k_pool = self.add_weight(shape=(1, 2*n_v1_orientations),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(3.9)),\n",
        "                                 name=\"b_dn_k_pool\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        # We would want the normalization pool to mostly include, for each size/orientation, the opposite orientation.\n",
        "        # We would also want to include smaller sizes. But perhaps that's not so important?\n",
        "\n",
        "        basic_dn_matrix = np.zeros((1, 2*n_v1_orientations, 1, 2*n_v1_orientations)).astype(np.float32)\n",
        "\n",
        "        # The first ones are the ones that count towards the second\n",
        "        for s1 in range(1):\n",
        "            for o1 in range(2*n_v1_orientations):\n",
        "                for s2 in range(1):\n",
        "                    for o2 in range(2*n_v1_orientations):\n",
        "                        s_distance = np.exp(-(s1 - s2)**2)\n",
        "                        basic_dn_matrix[s1, o1, s2, o2] = s_distance\n",
        "\n",
        "        self.b_dn_weights = self.add_weight(shape=((1, 2*n_v1_orientations, 1, 2*n_v1_orientations)),\n",
        "                                 initializer=tf.keras.initializers.Constant(invspa(basic_dn_matrix.astype(np.float32))),\n",
        "                                 name=\"b_dn_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.g_dn_b = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.5)),\n",
        "                                 name=\"g_dn_b\",\n",
        "                                 trainable=True)\n",
        "        self.g_dn_k = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(2.2)),\n",
        "                                 name=\"g_dn_k\",\n",
        "                                 trainable=True)\n",
        "        self.g_dn_k_pool = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(invsp(1.5)),\n",
        "                                 name=\"g_dn_k_pool\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        # We would want the normalization pool to mostly include, for each size/orientation, the opposite orientation.\n",
        "        # We would also want to include smaller sizes. But perhaps that's not so important?\n",
        "\n",
        "        basic_g_dn_matrix = np.zeros((n_v4_scales, n_v4_scales)).astype(np.float32)\n",
        "\n",
        "        # The first ones are the ones that count towards the second\n",
        "        for s1 in range(n_v4_scales):\n",
        "            for s2 in range(n_v4_scales): # the smaller ones should always suppress the bigger ones\n",
        "                s_distance = 1. if s1 <= s2 else 0.0001\n",
        "                basic_g_dn_matrix[s1, s2] = s_distance\n",
        "\n",
        "        self.g_dn_weights = self.add_weight(shape=((n_v4_scales, n_v4_scales)),\n",
        "                                 initializer=tf.keras.initializers.Constant(invspa(basic_g_dn_matrix.astype(np.float32))),\n",
        "                                 name=\"g_dn_weights\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.g = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(0.5),\n",
        "                                 name=\"g\",\n",
        "                                 trainable=True)\n",
        "        self.k = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.array([0.01, 0.1, 0.2, 0.3, .25, 0.125, 0.0325, 0.005]).astype(np.float32)),\n",
        "                                 name=\"k\",\n",
        "                                 trainable=True)\n",
        "    def print_weights(self):\n",
        "        #print(\"CSF\")\n",
        "        #plt.imshow(self.csf.numpy())\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "        #print(\"HRA parameters:\")\n",
        "        #print(\"---------\")\n",
        "        #print(\"V1 (scales/orientations) exponents [k] and half-points [b]\")\n",
        "        #plt.imshow(sp(self.v1_hra_k))\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "        #plt.imshow(sp(self.v1_hra_b))\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "#\n",
        "        #print(\"G (scales/orientations) exponents [k] and half-points [b]\")\n",
        "        #print(sp(self.g_hra_k))\n",
        "        #print(sp(self.g_hra_b))\n",
        "        #plt.plot(sp(self.g_hra_k))\n",
        "        #plt.show()\n",
        "        #print(\"beta\")\n",
        "        #plt.plot(sp(self.g_hra_b))\n",
        "        #plt.show()\n",
        "\n",
        "        #print(\"M\")\n",
        "        #v4_filters = make_v4_filters(self.kk, self.v4_sp, self.v4_sn, self.v4_hp, self.v4_hn, self.v4_cp, self.v4_cn)[None, None, None, ...]\n",
        "        #print(self.v4_sp.numpy(), self.v4_hp.numpy(), self.v4_cp.numpy())\n",
        "        #for i in range(n_v4_scales):\n",
        "        #    plt.imshow(tf.reduce_sum(v4_filters[0, 0, 0, :, i, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "        #                    int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))], [0]))\n",
        "        #    plt.colorbar()\n",
        "        #    plt.show()\n",
        "#\n",
        "        #print(\"Forward linking matrix:\")\n",
        "        #print(\"Scale weights:\")\n",
        "        #plt.imshow(self.v1_v4_scale_weights[:, :])\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "        #print(\"Orientation weights:\")\n",
        "        #plt.imshow(self.v1_v4_orientation_weights[: ,:])\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "        print(\"Blur orientation weights:\")\n",
        "        plt.imshow(self.v1_blur_orientation_weights[: ,:])\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "        #print(\"BDN exponents: upper k:\", sp(self.b_dn_k).numpy(), \"pool k:\", sp(self.b_dn_k_pool).numpy())\n",
        "        #print(\"BDN exponents, b:\", sp(self.b_dn_b).numpy())\n",
        "        #print(\"BDN Weights (size 2):\")\n",
        "        #plt.imshow(sp(self.b_dn_weights)[0, :, 0, :])\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "#\n",
        "        #print(\"GDN exponents: upper k:\", sp(self.g_dn_k).numpy(), \"pool k:\", sp(self.g_dn_k_pool).numpy())\n",
        "        #print(\"GDN exponents, b:\", sp(self.g_dn_b).numpy())\n",
        "        #print(\"GDN Weights (size 2):\")\n",
        "        #plt.imshow(sp(self.g_dn_weights)[:, :])\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "##\n",
        "        ##g_scale_scores = self.g_scale_score_factor ** (sp(self.g_hra_k) * np.arange(n_v4_scales).astype(np.float32))\n",
        "        ##print(\"G scale scores\", g_scale_scores.numpy())\n",
        "#\n",
        "        #print(\"G exponent:\", .5 + tf.nn.relu(self.g.numpy()))\n",
        "        ##plt.plot(0.5 + tf.nn.relu(self.g.numpy()))\n",
        "        ##plt.show()\n",
        "        #print(\"K feedback strength exponents:\")\n",
        "        #plt.plot(self.k.numpy())\n",
        "        #plt.show()\n",
        "\n",
        "    def hra_v1(self, i):\n",
        "        return i\n",
        "        k = sp(self.v1_hra_k[None, None, :, :, None, None])\n",
        "        b = sp(self.v1_hra_b[None, None, :, :, None, None])\n",
        "        return ((i + eps) ** k) / (eps + b**k + (i + eps) ** k)\n",
        "        # We need to ensure that whatever comes out of v1 is scaled.\n",
        "        # The point of V1 scaling is that complex cells respond nonlinearly in real life; such that\n",
        "        # e.g. stems are active in the center, and not as much on the outside.\n",
        "        # But we need to ensure that total energy is kept the same, and simply redistributed.\n",
        "        # Question is whether there is a way to normalize this.\n",
        "\n",
        "    def hra_v4(self, i):\n",
        "        return i\n",
        "        k = sp(self.v4_hra_k[None, None, :, :, None, None])\n",
        "        b = sp(self.v4_hra_b[None, None, :, :, None, None])\n",
        "        return ((i + eps) ** k) # / (eps + b**k + (i + eps) ** k)\n",
        "\n",
        "    def hra_g(self, i):\n",
        "        k = sp(self.g_hra_k) #sp(self.g_hra_k[None, None, :, None, None])\n",
        "        b = sp(self.g_hra_b[None, None, :, None, None])\n",
        "        return ((i + eps) ** k) #/ (eps + b**k + (i + eps) ** k)\n",
        "\n",
        "    def score_g(self, i):\n",
        "        # We get [b, d, c, h, w], and for each c we want to have a quadratic equation\n",
        "\n",
        "\n",
        "        return (self.g_hra_b[None, None, :, None, None] * i ** self.g_hra_k[None, None, :, None, None])\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        v1c = self.hra_v1(tf.abs(inputs)) #* tf.nn.relu(self.csf[None, None, :, :, None, None]) / (eps + tf.reduce_sum(tf.nn.relu(self.csf))), [2], keepdims=True) # should end up with just a single scale.\n",
        "        pf = 3\n",
        "\n",
        "        b_balanced = tf.pad(tf.concat([v1c]*2, axis=3), [[0, 0], [0, 0], [0, 0], [0, 0],\n",
        "                                [int(np.ceil(box_height * (pf-1) / 2)), int(box_height * (pf-1)/ 2)],\n",
        "                                [int(np.ceil(box_width * (pf-1)/ 2)), int(box_width * (pf-1)/ 2)]], mode='CONSTANT')\n",
        "        \n",
        "        b_balanced_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(b_balanced, 0.), [4, 5]))\n",
        "\n",
        "        v4_filters = make_v4_filters(self.kk, self.v4_sp, self.v4_sn, self.v4_hp, self.v4_hn, self.v4_cp, self.v4_cn)[None, None, None, ...]\n",
        "        \n",
        "        v4_filters_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(v4_filters, 0.), [5, 6]))\n",
        "        \n",
        "        v4_activations_0_by_s_o = tf.nn.relu(tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(v4_filters_fft * b_balanced_fft[:, :, :, :, None, :, :]), [5, 6])))\n",
        "        \n",
        "        v4_activations_0 = self.hra_v4(tf.einsum(\"bdsochw,sc->bdochw\", v4_activations_0_by_s_o, eps + tf.nn.relu(self.v1_v4_scale_weights) / (eps + tf.reduce_sum(tf.nn.relu(self.v1_v4_scale_weights))) )) # hra_v4\n",
        "        \n",
        "        G_0 = tf.einsum(\"bdochw,oc->bdchw\", v4_activations_0, tf.nn.relu(self.v1_v4_orientation_weights) / (eps + tf.reduce_mean(eps + tf.nn.relu(self.v1_v4_orientation_weights), axis=[0], keepdims=True) ))\n",
        "\n",
        "        x1_filters, x2_filters = make_blur_filters(self.exp1, self.exp1 + 1)\n",
        "        x1_filters_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(x1_filters[None, None, None, ...], 0.), [5, 6]))\n",
        "        x2_filters_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(x2_filters[None, None, None, ...], 0.), [5, 6]))\n",
        "        v1_x1 = tf.nn.relu(tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(x1_filters_fft * b_balanced_fft[:, :, :, :, None, :, :]), [5, 6])))\n",
        "        v1_x2 = tf.nn.relu(tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(x2_filters_fft * b_balanced_fft[:, :, :, :, None, :, :]), [5, 6])))\n",
        "\n",
        "        v1_distances = v1_x1 / v1_x2\n",
        "        v1_fullnesses = v1_x1 * v1_distances ** (self.exp1 - 1)\n",
        "        v1_strengths = tf.einsum(\"bdcoshw,oc->bdhw\", v1_fullnesses / v1_distances, (tf.nn.relu(self.v1_blur_orientation_weights) / (eps + tf.reduce_mean(eps + tf.nn.relu(self.v1_blur_orientation_weights), axis=[0], keepdims=True))))[:, :, None, :, :]\n",
        "\n",
        "        v1_strengths = tf.einsum(\"bdsochw->bdchw\", v1_x1 / v1_x2)\n",
        "\n",
        "        # Now we want these G-cells to compete against one another.\n",
        "        # In a previous version, the G-cells competed indirectly, via B-cells. But we are now competing directly.\n",
        "\n",
        "        #G_0_dn = G_0 ** 3 * tf.nn.relu(self.k)[None, None, :, None, None] / (sp(self.g_hra_b)[None, None, :, None, None] ** 2 + tf.einsum(\"bdchw,cq->bdqhw\", G_0_filtered**2, sp(self.g_dn_weights)) + eps)\n",
        "\n",
        "        #gn = (.5 + tf.nn.relu(self.g[None, None, :, None, None]))\n",
        "        #gn = (.5 + tf.nn.relu(self.g))\n",
        "        #G_strength = (tf.nn.relu(self.k[None, None, :, None, None]) * (eps + G_0) + eps) #/ (eps + (tf.nn.relu(self.attention_attraction_beta[None, None, :, None, None]) + eps) ** gn + (eps + relevant_p) ** gn)\n",
        "        #G_strength = tf.nn.relu(G_0) * tf.nn.relu(self.k)[None, None, :, None, None] + eps\n",
        "        # We already have the option to make some stronger than others, and that's via orientation and scale weights! So we don't need to do anything at all.\n",
        "\n",
        "        return (G_0[:, :, :, int(np.ceil(box_height * (pf-1) / 2)):int(box_height * (pf-1) + np.ceil(box_height / 2)),\n",
        "                              int(np.ceil(box_width * (pf-1) / 2)):int(box_width * (pf-1) + np.ceil(box_width / 2))], eps + G_0, v1_strengths, v1_strengths)  #* g_scal_scores[None, None, None, None, :, None, None]\n",
        "\n",
        "\n",
        "class RelevanceLayer(tf.keras.layers.Layer): # These are like the V1 complex edges\n",
        "    def __init__(self, **kwargs):\n",
        "        super(RelevanceLayer, self).__init__(**kwargs)\n",
        "        self.relevance_strictness = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(0.01),\n",
        "                                 name=\"relevance_strictness\",\n",
        "                                 trainable=True)  \n",
        "    def print_weights(self):\n",
        "        print(\"Relevance strictness:\", self.relevance_strictness.numpy())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        (l, r) = inputs\n",
        "        return 1. - (tf.abs(l - r)/(1e-12 + l + r)) ** (1. + tf.nn.relu(self.relevance_strictness))\n",
        "\n",
        "\n",
        "class GroupingStrengthLayer(tf.keras.layers.Layer): # These are like the V1 complex edges\n",
        "    def __init__(self, **kwargs):\n",
        "        super(GroupingStrengthLayer, self).__init__(**kwargs)\n",
        "        # Todo: we can try adding height here\n",
        "        self.channel_attention_attraction_rate = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.array([0.1, 0.2, 0.3, 0.4, 0.3, 0.2, 0.1, 0.01]).astype(np.float32)),\n",
        "                                 name=\"channel_attention_attraction_rate\",\n",
        "                                 trainable=True)  \n",
        "        self.attention_g = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(0.1),\n",
        "                                 name=\"attention_g\",\n",
        "                                 trainable=True)  \n",
        "        #self.w_global = self.add_weight(shape=(n_v4_scales, n_v4_scales),\n",
        "        #                         initializer=tf.keras.initializers.Constant(0.1),\n",
        "        #                         name=\"w_global\",\n",
        "        #                         trainable=True)\n",
        "        #self.w_local = self.add_weight(shape=(n_v4_scales, n_v4_scales),\n",
        "        #                         initializer=tf.keras.initializers.Constant(0.1),\n",
        "        #                         name=\"w_local\",\n",
        "        #                         trainable=True)\n",
        "        self.attention_attraction_beta = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(0.1),\n",
        "                                 name=\"attention_attraction_beta\",\n",
        "                                 trainable=True)\n",
        "        self.b = self.add_weight(shape=(n_v4_scales),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.array([0.1, 0.2, 0.3, 0.4, 0.3, 0.2, 0.1, 0.05]).astype(np.float32)),\n",
        "                                 name=\"b\",\n",
        "                                 trainable=True)\n",
        "        self.n = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(6.),\n",
        "                                 name=\"n\",\n",
        "                                 trainable=True)\n",
        "        self.yfactors = self.add_weight(shape=(n_v4_scales,box_height),\n",
        "                                       initializer=tf.keras.initializers.Constant(1.0),\n",
        "                                       name=\"yfactor\",\n",
        "                                       trainable=True)\n",
        "\n",
        "    def print_weights(self):\n",
        "        #print(\"Channel attention attraction rate:\")\n",
        "        #plt.plot(self.channel_attention_attraction_rate.numpy())\n",
        "        #plt.show()\n",
        "        print(\"N:\", self.n.numpy())\n",
        "        #print(\"bet:\")\n",
        "        #plt.plot(self.attention_attraction_beta.numpy())\n",
        "        #plt.show()\n",
        "        #print(\"W local\")\n",
        "        #plt.imshow(self.w_local.numpy())\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "        #print(\"W global\")\n",
        "        #plt.imshow(self.w_global.numpy())\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "        #print(\"B feedback strength factors:\")\n",
        "        #plt.plot(self.b.numpy())\n",
        "        #plt.show()\n",
        "        #print(\"yfactor:\")\n",
        "        #plt.imshow(self.yfactors.numpy())\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        (l, r, p, relevance) = inputs\n",
        "        \n",
        "        # We want only the relevant inputs, and for each input, we want to find out the grouping strength.\n",
        "        # We essentially want for each scale of input, an exponent and a multiplier to predict the grouping strength.\n",
        "        # We may need a sigmoid function of some sort to do this well.\n",
        "        # Then, when the strength has been calculated everywhere, then we go and essentially find the max strength via a polynomial softmax approximation.\n",
        "\n",
        "        #relevant_strengths = p * relevance\n",
        "        relevant_strengths = l * tf.nn.relu(p - l) + r * tf.nn.relu(p - r)\n",
        "\n",
        "        # Now, calculate the strength for each\n",
        "\n",
        "        #strongest_strength = tf.reduce_sum((eps + strengths) ** tf.nn.relu(eps + self.n + 1.), [2], keepdims=True) / (eps + tf.reduce_sum((eps + strengths) ** tf.nn.relu(eps + self.n), [2,3,4], keepdims=True))\n",
        "        ns = relevant_strengths * (10 ** self.n)\n",
        "        softmax_weights = tf.exp(ns) / (eps + tf.reduce_sum(tf.exp(ns), [2,3,4], keepdims=True))\n",
        "        strongest_strength = relevant_strengths * softmax_weights\n",
        "\n",
        "        return strongest_strength[:, :, :, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                              int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))]\n",
        "\n",
        "        # We would like to see the result, such that only the strongest one wins.\n",
        "\n",
        "        #yfn = (tf.nn.relu(self.yfactors[None, None, :, :, None]) + eps) / (eps + tf.reduce_mean(tf.nn.relu(self.yfactors)))\n",
        "        #attention_attraction_rates = eps + tf.nn.relu(p * self.channel_attention_attraction_rate[None, None, :, None, None]  / (eps + tf.reduce_min(tf.nn.relu(self.channel_attention_attraction_rate))))\n",
        "\n",
        "        # We want to normalize, so that horizontally, any large-scale attention attractors are scaled down by small-scale competitors.\n",
        "\n",
        "\n",
        "        # What if we want to normalize the attention stuff first, so that the larger ones don't win? And then we add the relevance after?\n",
        "\n",
        "\n",
        "        #attention_attraction_pool_local = tf.einsum(\"bdchw,qc->bdqhw\", attention_attraction_rates ** gn, eps + tf.nn.relu(self.w_local)) + eps\n",
        "        #attention_attraction_pool_global = tf.einsum(\"bdchw,qc->bdq\", attention_attraction_rates ** gn, eps + tf.nn.relu(self.w_global))[:, :, :, None, None] + eps\n",
        "        #probability_of_grouping_feedback = (eps + relevance * yfn * attention_attraction_rates) ** gn / (eps + (tf.nn.relu(self.attention_attraction_beta[None, None, :, None, None]) + eps) ** gn + attention_attraction_pool_local + attention_attraction_pool_global)\n",
        "        \n",
        "        #feedback_strength = ((tf.nn.relu(p) + eps) ** (.5 + tf.nn.relu(self.k[None, None, :, None, None])) * tf.nn.relu(self.b[None, None, :, None, None])) #/ (eps + tf.reduce_min(self.b))\n",
        "\n",
        "        #return probability_of_grouping_feedback * feedback_strength\n",
        "\n",
        "\n",
        "# 8. Cost layer\n",
        "class SkeletonCostLayer(tf.keras.layers.Layer): # These are like the V1 complex edges\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SkeletonCostLayer, self).__init__(**kwargs)\n",
        "        # <b, s, o, h, w, d>\n",
        "        #self.wp = self.add_weight(shape=(n_v4_scales), # Penalties for Losses\n",
        "        self.wp = self.add_weight(shape=(n_v1_scales), # Penalties for Losses\n",
        "                                 #initializer=tf.keras.initializers.Constant(np.array([2., 1.7, 1.53, 0.4, 0.11, 0.01, 0.01, 0.01]).astype(np.float32)),\n",
        "                                 initializer=tf.keras.initializers.Constant(np.array([2., 1.7, 1.53, 0.4, 0.11]).astype(np.float32)),\n",
        "                                 #initializer=tf.keras.initializers.Constant(0.1),\n",
        "                                 name=\"wp\",\n",
        "                                 trainable=True)\n",
        "        #self.blurwidths = self.add_weight(shape=(n_v4_scales),\n",
        "        self.blurwidths = self.add_weight(shape=(n_v1_scales),\n",
        "                                 #initializer=tf.keras.initializers.Constant(tf.constant([0.0025, 0.003, 0.004, 0.0067, 0.0094, 0.017, 0.0291, 0.0471])),\n",
        "                                 #initializer=tf.keras.initializers.Constant(tf.constant([0.0025, 0.003, 0.004, 0.0067, 0.0094, 0.017, 0.0291, 0.0471])),\n",
        "                                 initializer=tf.keras.initializers.Constant(0.01),\n",
        "                                 name=\"blurwidths\",\n",
        "                                 trainable=False)  \n",
        "        self.we = self.add_weight(shape=(n_v4_scales), # Penalties for Losses\n",
        "                                 #initializer=tf.keras.initializers.Constant(np.array([2., 1.7, 1.53, 0.4, 0.11, 0.01, 0.01, 0.01]).astype(np.float32)),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.0),\n",
        "                                 name=\"we\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.blurwidthfactor = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"blurwidthfactor\",\n",
        "                                 trainable=False)  \n",
        "        self.n = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(1.),\n",
        "                                 name=\"n\",\n",
        "                                 trainable=True)  \n",
        "\n",
        "    def print_weights(self):\n",
        "        print(\"Skeleton loss cost:\")\n",
        "        plt.plot(tf.nn.relu(self.wp).numpy())\n",
        "        plt.show()\n",
        "        print(\"Skeleton loss exps:\")\n",
        "        plt.plot(tf.nn.relu(self.we).numpy())\n",
        "        plt.show()\n",
        "        print(\"Blurwidths:\")\n",
        "        plt.plot(tf.nn.relu(self.blurwidths).numpy() * tf.nn.relu(self.blurwidthfactor))\n",
        "        plt.show()\n",
        "        print(\"Skeleton loss softmax n:\", self.n.numpy())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        #(l, r, p) = inputs\n",
        "\n",
        "        # Find the skeleton losses\n",
        "        #losses = tf.nn.relu(l - p) + tf.nn.relu(r - p)\n",
        "\n",
        "        losses = inputs\n",
        "\n",
        "        losses_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(losses, eps), [3, 4]))\n",
        "        losses_filters = make_losses_filters(eps + tf.nn.relu(self.blurwidths) * tf.nn.relu(self.blurwidthfactor))\n",
        "        losses_filters_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(losses_filters, eps), [3, 4]))\n",
        "        losses_filtered = (eps + tf.nn.relu(tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(losses_fft * losses_filters_fft), [3, 4])))) #[:, :, :, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                              #int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))])) # ** (eps + tf.nn.relu(self.we)[None, None, :, None, None])\n",
        "\n",
        "        #penalties = (tf.nn.relu(self.wk + eps) ** tf.range(n_v4_scales, dtype=tf.float32))[None, None, :, None, None]\n",
        "        penalties = tf.nn.relu(self.wp)[None, None, :, None, None]\n",
        "\n",
        "        # Penalize the skeleton losses\n",
        "        penalized_losses = losses_filtered * penalties \n",
        "\n",
        "        # Find the worst penalty\n",
        "        pln = penalized_losses * 10 ** self.n\n",
        "        expd = tf.exp(pln - tf.reduce_max(pln, [2,3,4], keepdims=True))\n",
        "        softmax_weights = expd / (eps + tf.reduce_sum(expd, axis=[2,3,4], keepdims=True))\n",
        "        worst_skeleton_loss_penalty = softmax_weights * penalized_losses\n",
        "\n",
        "        return penalized_losses #worst_skeleton_loss_penalty\n",
        "\n",
        "\n",
        "# 8. Cost layer\n",
        "class LossLayer(tf.keras.layers.Layer): # These are like the V1 complex edges\n",
        "    def __init__(self, **kwargs):\n",
        "        super(LossLayer, self).__init__(**kwargs)\n",
        "        # <b, s, o, h, w, d>\n",
        "        self.target_strength = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(5.),\n",
        "                                 name=\"target_strength\",\n",
        "                                 trainable=True)  \n",
        "        self.target_grouping = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(0.0002),\n",
        "                                 name=\"target_grouping\",\n",
        "                                 trainable=True)  \n",
        "        self.skeleton_loss_weight = self.add_weight(shape=(),\n",
        "                                 initializer=tf.keras.initializers.Constant(-3.),\n",
        "                                 name=\"skeleton_loss_weight\",\n",
        "                                 trainable=True)\n",
        "    def print_weights(self):\n",
        "        print(\"Target strength:\", self.target_strength.numpy())\n",
        "        print(\"Target grouping:\", self.target_grouping.numpy())\n",
        "        print(\"Skeleton loss weight:\", (10 * self.skeleton_loss_weight).numpy())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        (grouping_strength, skeleton_loss_cost) = inputs\n",
        "\n",
        "        xs = tf.constant(sample_distance_factors)[None, :]\n",
        "        #ys = (grouping_strength - self.target_strength) ** 2 + skeleton_loss_cost * (eps + sp(self.skeleton_loss_weight)) # <b, d>\n",
        "        # We want to minimize the\n",
        "        #ys = -grouping_strength + skeleton_loss_cost * (eps + 10 ** (self.skeleton_loss_weight))\n",
        "        ys = (skeleton_loss_cost - self.target_strength) ** 2 #+ (grouping_strength - self.target_grouping) ** 2 + \n",
        "\n",
        "        # Find worst violation of the well\n",
        "        up_first_ness = (ys[:, 1] - ys[:, 0]) #[1,2,3,4,5,6]\n",
        "        down_second_ness = (ys[:, 1] - ys[:, 2]) # has shape <batch_size>, [2,3,4,5,6,7,]\n",
        "        worst_violation_sum = tf.reduce_mean((tf.reduce_max(tf.stack([up_first_ness, down_second_ness], axis=0), axis=[0]) + eps), name=\"worst_violation\")\n",
        "        return worst_violation_sum \n",
        "\n",
        "        # The problem we're having is that the ys are flat.\n",
        "        # But with flat ys ... that means that the strongest strength is exactly constant between two sample distances.\n",
        "        # Even without any kind of training changes, sometimes we seem to get just perfectly flat ys.\n",
        "        # This is very strange. Why isn't the \n",
        "        #slopes = (ys[:, 1:]-ys[:, :-1])/(xs[:, 1:]-xs[:, :-1]) - 1e-8\n",
        "        #intercepts = ys[:, 1:] - xs[:, 1:] * slopes\n",
        "        #predicted_intersections = self.target_strength/slopes - ys[:, 1:]/slopes + xs[:, 1:]    # should be somewhere between -100 and 100\n",
        "        ## what happens if the predicted intersection is at infinity?\n",
        "        #use_second = tf.nn.sigmoid(100. * (predicted_intersections[:, 1] - xs[:, 1]))  # Predicted intersections may be very large, in which case \n",
        "        #use_first = 1. - use_second\n",
        "        #predicted_intersection = use_first * predicted_intersections[:, 0] + use_second * predicted_intersections[:, 1]\n",
        "        #deviations_from_target = (predicted_intersection - xs[0, 1]) ** 2\n",
        "        #return (deviations_from_target, predicted_intersection)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 9. Set up the actual math\n",
        "\n",
        "def get_pair_violation_from_strength(left_v4_strength, right_v4_strength):\n",
        "    # TODO: Give them each an exponent, weigh them by orientation and by scale, and sum them up.\n",
        "    print(\"ORIGINAL STRENGTH\", left_v4_strength)\n",
        "    left_strength = tf.reduce_sum(left_v4_strength, [2, 3], keepdims=True) # <b,d,h,w>\n",
        "    right_strength = tf.reduce_sum(right_v4_strength, [2, 3], keepdims=True) # <b,d,h,w>\n",
        "\n",
        "    total_strength_loss = tf.identity(left_strength * right_strength / (left_strength + right_strength), \"strengthloss\")\n",
        "\n",
        "    #sll = SkeletonCostLayer()\n",
        "    #skeleton_loss_cost_image = tf.identity(sll(total_strength_loss), \"skeleton_loss_cost_image\") # <b, d>\n",
        "    #skeleton_loss_cost = tf.identity(tf.reduce_sum(skeleton_loss_cost_image, [2,3]), \"skeleton_losscosts\")\n",
        "    skeleton_loss_cost_image = tf.reduce_sum(total_strength_loss, [2,3], name=\"skeleton_loss_cost_image\")\n",
        "\n",
        "    skeleton_loss_cost = tf.reduce_max(skeleton_loss_cost_image, [2,3])\n",
        "\n",
        "    ys = (skeleton_loss_cost - 90000) ** 2 #+ (grouping_strength - self.target_grouping) ** 2 + \n",
        "\n",
        "    # Find worst violation of the well\n",
        "    up_first_ness = (ys[:, 1] - ys[:, 0]) #[1,2,3,4,5,6]\n",
        "    down_second_ness = (ys[:, 1] - ys[:, 2]) # has shape <batch_size>, [2,3,4,5,6,7,]\n",
        "    worst_violation_sum = tf.reduce_mean((tf.reduce_max(tf.stack([up_first_ness, down_second_ness], axis=0), axis=[0]) + eps), name=\"worst_violation\")\n",
        "    return worst_violation_sum \n",
        "\n",
        "    #return tf.reduce_sum(skeleton_loss_cost)\n",
        "    # Find worst violation of the well\n",
        "\n",
        "def get_pair_violation(left_v1_response, right_v1_response):\n",
        "    \"\"\"Runs the V1 responses through the V4 layer, weights the pair differences via the CostLayer,\n",
        "    and then returns the worst violation of the \"cost-must-be-lowest-for-optimal-distance\" principle\n",
        "    which is then passed to the optimizer.\"\"\"\n",
        "\n",
        "    # Feed V1 responses through the V4 layer\n",
        "    v4 = V4Layer(False)\n",
        "    (left_v4_filtered, left_v4_response, left_fullness, left_strength) = v4(tf.abs(left_v1_response))\n",
        "    (right_v4_filtered, right_v4_response, right_fullness, right_strength) = v4(tf.abs(right_v1_response))\n",
        "    (pair_v4_filtered, pair_v4_response, pair_fullness, pair_strength) = v4(tf.abs(left_v1_response + right_v1_response))\n",
        "\n",
        "    left_v4_filtered = tf.identity(left_v4_filtered, \"left_v4_filtered\")\n",
        "\n",
        "    left_fullness = tf.identity(left_fullness, \"left_fullness\")\n",
        "    left_strength = tf.identity(left_strength, \"left_strength\")\n",
        "    right_fullness = tf.identity(right_fullness, \"right_fullness\")\n",
        "    right_strength = tf.identity(right_strength, \"right_strength\")\n",
        "\n",
        "    left_v4_response = tf.identity(left_v4_response, \"left_v4_response\") + 0. * tf.reduce_sum(left_strength)\n",
        "    right_v4_response = tf.identity(right_v4_response, \"right_v4_response\") + 0. * tf.reduce_sum(right_strength)\n",
        "    pair_v4_response = tf.identity(pair_v4_response, \"pair_v4_response\")\n",
        "\n",
        "    # What can we do with these things?\n",
        "\n",
        "    total_strength = tf.identity(tf.identity(left_strength, \"total_strength\"), \"skeleton_loss_cost_image\") #  * (left_distance + right_distance)\n",
        "    # This approximates the strength of the G-cells that define the gap.\n",
        "\n",
        "    # We need a function that converts the local fullness value, combined with the distance, to a strength.\n",
        "\n",
        "    rl = RelevanceLayer()\n",
        "    relevance = tf.identity(rl((left_v4_response, right_v4_response)), \"relevance\")\n",
        "\n",
        "    gsl = GroupingStrengthLayer()\n",
        "    grouping_strength_image = tf.identity(gsl((left_v4_response, right_v4_response, pair_v4_response, relevance)), \"grouping_local_strengths\")\n",
        "    grouping_strength = tf.identity(tf.reduce_sum(grouping_strength_image, [2,3,4]), \"grouping_strengths\") # <b, d>\n",
        "\n",
        "    # We need a penalty for the maximal skeleton loss\n",
        "    sll = SkeletonCostLayer()\n",
        "    #skeleton_loss_cost_image = tf.identity(sll((left_v4_response, right_v4_response, pair_v4_response)), \"skeleton_loss_cost_image\") # <b, d>\n",
        "    #skeleton_loss_cost_image = tf.identity(sll(total_strength), \"skeleton_loss_cost_image\") # <b, d>\n",
        "    #skeleton_loss_cost = tf.identity(tf.reduce_sum(skeleton_loss_cost_image, [2,3,4]), \"skeleton_losscosts\")\n",
        "\n",
        "    skeleton_loss_cost = tf.reduce_sum(total_strength, [2,3,4])\n",
        "\n",
        "    ll = LossLayer()\n",
        "    total_pair_cost = tf.identity(ll((grouping_strength, skeleton_loss_cost)), \"pair_total_cost\")  # The difference from the target. <b, d>\n",
        "\n",
        "\n",
        "    return total_pair_cost + 0. * tf.reduce_sum(total_strength)\n",
        "    # Find worst violation of the well\n",
        "    #up_first_ness = (total_pair_cost[:, 1] - total_pair_cost[:, 0]) #[1,2,3,4,5,6]\n",
        "    #down_second_ness = (total_pair_cost[:, 1] - total_pair_cost[:, 2]) # has shape <batch_size>, [2,3,4,5,6,7,]\n",
        "    #worst_violation_sum = tf.reduce_mean((tf.reduce_max(tf.stack([up_first_ness, down_second_ness], axis=0), axis=[0]) + eps), name=\"worst_violation\")\n",
        "    #return worst_violation_sum \n",
        "\n",
        "    # Worst violation sum: results in extremely flat cost lines, but often far away from the target line.\n",
        "    # We want to minimize the zero, but we also don't want to flatten things.\n",
        "    # We want to total pair cost \n",
        "    #return tf.math.sqrt(eps + tf.reduce_sum(total_pair_cost[:, 1] / (eps + tf.reduce_sum(total_pair_cost, axis=[1], keepdims=True)))) \n",
        "\n",
        "    # Instead of the worst violation, we directly predict the deviation from the correct x\n",
        "    #return tf.math.sqrt(eps + tf.reduce_mean(total_pair_cost))\n",
        "\n",
        "# 10. Set up Keras model and run\n",
        "\n",
        "def get_keras_model():\n",
        "    # The translated raw images aren't used in the model, they're just for visualization purposes ...\n",
        "    left_image = tf.keras.Input(shape=(n_sample_distances, box_height, box_width), name='left_image')\n",
        "    right_image = tf.keras.Input(shape=(n_sample_distances, box_height, box_width), name='right_image')\n",
        "\n",
        "    # ... but the translated V1 responses are:\n",
        "    left_v1_response = tf.keras.Input(shape=(n_sample_distances, n_v1_scales, n_v1_orientations, box_height, box_width), name='left_v1_response', dtype=tf.complex64)\n",
        "    right_v1_response = tf.keras.Input(shape=(n_sample_distances, n_v1_scales, n_v1_orientations, box_height, box_width), name='right_v1_response', dtype=tf.complex64)\n",
        "    left_v4_strength = tf.keras.Input(shape=(n_sample_distances, n_v1_scales, 2*n_v1_orientations, box_height, box_width), name='left_v4_strength')\n",
        "    right_v4_strength = tf.keras.Input(shape=(n_sample_distances, n_v1_scales, 2*n_v1_orientations, box_height, box_width), name='right_v4_strength')\n",
        "\n",
        "    lvs = tf.identity(left_v4_strength, \"lvs\")\n",
        "    print(\"IN:\", left_v4_strength.shape, lvs.shape)\n",
        "\n",
        "    # This calls the V4 layer, the penalty/reward layer, and finds the max cost\n",
        "    #total_violation = tf.identity(get_pair_violation(left_v1_response, right_v1_response), \"total_violation\")\n",
        "    total_violation = tf.identity(get_pair_violation_from_strength(left_v4_strength, right_v4_strength), \"total_violation\") + 0. * tf.reduce_sum(lvs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[left_image, right_image, left_v4_strength, right_v4_strength, left_v1_response, right_v1_response], outputs=(total_violation))\n",
        "\n",
        "class MonitorProgressCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, dataset, interval):\n",
        "        self.dataset = dataset\n",
        "        self.interval = interval\n",
        "        self.current_data = None\n",
        "\n",
        "    def get_val(self, name):\n",
        "        l = [l for l in self.model.layers if l.name.find(name) >= 0][0]\n",
        "        output = tf.keras.backend.function(self.model.inputs, [l.output])([self.current_data[\"left_v1_response\"],\n",
        "                                                                           self.current_data[\"right_v1_response\"],\n",
        "                                                                           self.current_data[\"left_v4_strength\"],\n",
        "                                                                           self.current_data[\"right_v4_strength\"],\n",
        "                                                                           self.current_data[\"left_image\"],\n",
        "                                                                           self.current_data[\"right_image\"]])[0]\n",
        "        return output\n",
        "\n",
        "    def get_weights(self, name):\n",
        "        l = [l for l in self.model.layers if l.name.find(name) >= 0][0]\n",
        "        return l.get_weights()\n",
        "\n",
        "    def print_weights(self, name):\n",
        "        l = [l for l in self.model.layers if l.name.find(name) >= 0][0]\n",
        "        l.print_weights()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Only show this stuff every [interval] batches\n",
        "        if epoch % self.interval != 0:\n",
        "            return\n",
        "\n",
        "        #print([l.name for l in self.model.layers])\n",
        "        #print(self.model.inputs)\n",
        "\n",
        "        self.current_data, _ = next(self.dataset) #list(self.dataset.take(1).as_numpy_iterator())[0]\n",
        "        pair_images = self.current_data[\"left_image\"] + self.current_data[\"right_image\"]\n",
        "\n",
        "        #print(\"\\nPair DIFFS:\")\n",
        "        #pair_cost = self.get_val(\"pair_pixel_cost\")\n",
        "        #print(\"Pair total cost\", self.get_val(\"pair_total_cost\")[0, 0])\n",
        "        #plt.imshow(pair_images[0, 0, :, :], alpha=1)\n",
        "        #plt.imshow(tf.reduce_sum(pair_cost, [2, 3, 4], keepdims=True)[0, 0, 0, 0, 0, :, :], alpha=0.7)\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "        #print(\"Pair total cost\", self.get_val(\"pair_total_cost\")[0, 1])\n",
        "        #pair_cost = self.get_val(\"pair_pixel_cost\")\n",
        "        #plt.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "        #plt.imshow(tf.reduce_sum(pair_cost, [2, 3, 4], keepdims=True)[0, 1, 0, 0, 0, :, :], alpha=0.7)\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "        #print(\"Pair total cost\", self.get_val(\"pair_total_cost\")[0, 2])\n",
        "        #pair_cost = self.get_val(\"pair_pixel_cost\")\n",
        "        #plt.imshow(pair_images[0, 2, :, :], alpha=1)\n",
        "        #plt.imshow(tf.reduce_sum(pair_cost, [2, 3, 4], keepdims=True)[0, 2, 0, 0, 0, :, :], alpha=0.7)\n",
        "        #plt.colorbar()\n",
        "        #plt.show()\n",
        "\n",
        "        # print(\"Grouping strengths:\")\n",
        "        # local_grouping_strengths = self.get_val(\"grouping_local_strengths\")\n",
        "        # for nb in range(n_sample_distances):\n",
        "        #     plt.imshow(pair_images[0, nb, :, :], cmap=\"gray\")\n",
        "        #     plt.imshow(tf.reduce_sum(local_grouping_strengths[0, nb, :, :, :], [0]), alpha=.8)\n",
        "        #     plt.colorbar()\n",
        "        #     plt.show()\n",
        "\n",
        "        print(\"Skeleton losses:\")\n",
        "        local_skeleton_loss_cost = self.get_val(\"skeleton_loss_cost_image\")\n",
        "\n",
        "        for nb in range(n_sample_distances):\n",
        "            plt.imshow(pair_images[0, nb, :, :], cmap=\"gray\")\n",
        "            #plt.imshow(tf.reduce_sum(local_skeleton_loss_cost[0, nb, :, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "            #                  int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))], [0]), alpha=.8)\n",
        "            plt.imshow(local_skeleton_loss_cost[0, nb, :, :], alpha=.8)\n",
        "            plt.colorbar()\n",
        "            plt.show()\n",
        "\n",
        "        return\n",
        "\n",
        "        pair_diff = self.get_val(\"relevance\")\n",
        "        maxv = tf.reduce_max(pair_diff)\n",
        "        minv = tf.reduce_min(pair_diff)\n",
        "        ex = max(abs(maxv), abs(minv))\n",
        "        fs = 16\n",
        "\n",
        "        left_v4_response = self.get_val(\"left_v4_response\")\n",
        "        right_v4_response = self.get_val(\"right_v4_response\")\n",
        "        pair_v4_response = self.get_val(\"pair_v4_response\")\n",
        "        if True: # False if displaying B cells\n",
        "            print(\"RAW LOSSES for size\")\n",
        "            figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            if n_v4_scales > 1:\n",
        "                for j in range(n_v4_scales):\n",
        "                    ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                    ax[j].imshow(pair_diff[0, 1, j, :, :], alpha=0.7, vmin=-ex, vmax=ex)\n",
        "            else:\n",
        "                ax.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax.imshow(pair_diff[0, 1, 0, :, :], alpha=0.7, vmin=-ex, vmax=ex)\n",
        "            plt.show()\n",
        "    \n",
        "        if False:\n",
        "            figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            print(\"RAW V4 GAINS for size, without min/max limit\")\n",
        "            if n_v4_scales > 1:\n",
        "                for j in range(n_v4_scales):\n",
        "                    print(\"Scale\", j, \"max loss:\", tf.reduce_max(tf.nn.relu(pair_diff[0, 1, j, :, :])), \"total losses:\", tf.reduce_sum(tf.nn.relu(pair_diff[0, 1, j, :, :])))\n",
        "                    ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                    ax[j].imshow(tf.nn.relu(pair_diff[0, 1, j, :, :]), alpha=0.7)\n",
        "            else:\n",
        "                ax.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax.imshow(tf.nn.relu(pair_diff[0, 1, 0, :, :]), alpha=0.7)\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "        # THIN SAMPLE RESULTS\n",
        "        if True:\n",
        "            figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            print(\"RAW V4 PAIR TIMES RELEVANCE for size, without min/max limit\")\n",
        "            if n_v4_scales > 1:\n",
        "                for j in range(n_v4_scales):\n",
        "                    print(\"Scale\", j, \"max gain:\", tf.reduce_max(tf.nn.relu((pair_diff*pair_v4_response)[0, 0, j, :, :])), \"total gain:\", tf.reduce_sum(tf.nn.relu((pair_diff * pair_v4_response)[0, 0, j, :, :])))\n",
        "                    ax[j].imshow(pair_images[0, 0, :, :], alpha=1)\n",
        "                    ax[j].imshow(pair_diff[0, 0, j, :, :] * pair_v4_response[0, 0, j, :, :], alpha=0.7)\n",
        "            else:\n",
        "                ax.imshow(pair_images[0, 0, :, :], alpha=1)\n",
        "                ax.imshow(tf.nn.relu(-pair_diff[0, 0, 0, :, :]), alpha=0.7)\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "        if True:\n",
        "            figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            print(\"RAW V4 PAIR TIMES RELEVANCE for size, without min/max limit\")\n",
        "            if n_v4_scales > 1:\n",
        "                for j in range(n_v4_scales):\n",
        "                    print(\"Scale\", j, \"max gain:\", tf.reduce_max(tf.nn.relu((pair_diff*pair_v4_response)[0, 1, j, :, :])), \"total gain:\", tf.reduce_sum(tf.nn.relu((pair_diff * pair_v4_response)[0, 1, j, :, :])))\n",
        "                    ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                    ax[j].imshow(pair_diff[0, 1, j, :, :] * pair_v4_response[0, 1, j, :, :], alpha=0.7)\n",
        "            else:\n",
        "                ax.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax.imshow(tf.nn.relu(-pair_diff[0, 1, 0, :, :]), alpha=0.7)\n",
        "            plt.show()\n",
        "\n",
        "        # WIDE SAMPLE RESULTS\n",
        "        if True:\n",
        "            figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            print(\"RAW V4 PAIR TIMES RELEVANCE for size, without min/max limit\")\n",
        "            if n_v4_scales > 1:\n",
        "                for j in range(n_v4_scales):\n",
        "                    print(\"Scale\", j, \"max gain:\", tf.reduce_max(tf.nn.relu((pair_diff * pair_v4_response)[0, 2, j, :, :])), \"total gain:\", tf.reduce_sum(tf.nn.relu((pair_diff * pair_v4_response)[0, 2, j, :, :])))\n",
        "                    ax[j].imshow(pair_images[0, 2, :, :], alpha=1)\n",
        "                    ax[j].imshow(pair_diff[0, 2, j, :, :] * pair_v4_response[0, 2, j, :, :], alpha=0.7)\n",
        "            else:\n",
        "                ax.imshow(pair_images[0, 2, :, :], alpha=1)\n",
        "                ax.imshow(tf.nn.relu(-pair_diff[0, 2, 0, :, :]), alpha=0.7)\n",
        "            plt.show()\n",
        "\n",
        "        if False:\n",
        "            print(\"FILTERED\")\n",
        "            left_v4_filtered = self.get_val(\"left_v4_filtered\")\n",
        "            if True:\n",
        "                figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "                fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "                print(\"RAW V4 PAIR TIMES RELEVANCE for size, without min/max limit\")\n",
        "                if n_v4_scales > 1:\n",
        "                    for j in range(n_v4_scales):\n",
        "                        print(\"Scale\", j, \"max gain:\", tf.reduce_max(tf.nn.relu((pair_diff * left_v4_filtered)[0, 1, j, :, :])), \"total gain:\", tf.reduce_sum(tf.nn.relu((pair_diff * left_v4_filtered)[0, 1, j, :, :])))\n",
        "                        ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                        ax[j].imshow(left_v4_filtered[0, 1, j, :, :], alpha=0.7)\n",
        "                else:\n",
        "                    ax.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                    ax.imshow(tf.nn.relu(-pair_diff[0, 1, 0, :, :]), alpha=0.7)\n",
        "                plt.show()\n",
        "    \n",
        "\n",
        "        figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "        fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "        print(\"PAIR v4 response for size, without min/max limit, 0-3\")\n",
        "        if n_v4_scales > 1:\n",
        "            for j in range(n_v4_scales):\n",
        "                print(\"Channel\", j, \"max\", tf.reduce_max(pair_v4_response[0, 1, j, :, :]), \"sum\", tf.reduce_sum(left_v4_response[0, 1,  j, :, :]))\n",
        "                #print(\"Channel\", j, \"max\", tf.reduce_max(self.get_val(\"left_v4_response\")[0, 1, 0, j, 0, :, :]), \"sum\", tf.reduce_sum(self.get_val(\"left_v4_response\")[0, 1, 0, j, 0, :, :]))\n",
        "                ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax[j].imshow(pair_v4_response[0, 1, j, :, :], alpha=0.8)\n",
        "                #ax[j].imshow(self.get_val(\"left_v4_response\")[0, 1, 0, j, 0, :, :], alpha=0.7)\n",
        "        else:\n",
        "            ax.imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "            ax.imshow(pair_v4_response[0, 1, 0, 0, 0, :, :], alpha=0.8)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        if False:\n",
        "            figsize = (fs * 1 * box_width / 100, fs * n_v4_scales * box_height / 100)\n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            print(\"PAIR v4 response for size, without min/max limit, 0-3\")\n",
        "            for j in range(n_v4_scales):\n",
        "                print(\"Channel\", j, \"max\", tf.reduce_max(pair_v4_response[0, 1, 0, 0, j, :, :]), \"sum\", tf.reduce_sum(pair_v4_response[0, 1, 0, 0, j, :, :]))\n",
        "                #print(\"Channel\", j, \"max\", tf.reduce_max(self.get_val(\"pair_v4_response\")[0, 1, 0, j, 0, :, :]), \"sum\", tf.reduce_sum(self.get_val(\"pair_v4_response\")[0, 1, 0, j, 0, :, :]))\n",
        "                ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax[j].imshow(pair_v4_response[0, 1, 0, 0, j, :, :], alpha=0.8)\n",
        "                #ax[j].imshow(self.get_val(\"pair_v4_response\")[0, 1, 0, j, 0, :, :])\n",
        "            plt.show()\n",
        "    \n",
        "            fig, ax = plt.subplots(1, n_v4_scales, gridspec_kw={'wspace':0, 'hspace':0}, figsize=figsize)\n",
        "            maxv = tf.reduce_max(pair_cost)\n",
        "            minv = tf.reduce_min(pair_cost)\n",
        "            ex = max(abs(maxv), abs(minv))\n",
        "            print(\"COST of DIFF for size\")\n",
        "            for j in range(n_v4_scales):\n",
        "                ax[j].imshow(pair_images[0, 1, :, :], alpha=1)\n",
        "                ax[j].imshow(pair_cost[0, 1, 0, 0, j, :, :], alpha=0.7, vmin=-ex, vmax=ex)\n",
        "            plt.show()\n",
        "\n",
        "        self.print_weights(\"v4_layer\")\n",
        "\n",
        "        self.print_weights(\"grouping_strength_layer\")\n",
        "        #self.print_weights(\"skeleton_cost_layer\")\n",
        "        self.print_weights(\"loss_layer\")\n",
        "\n",
        "        skeleton_loss_weight = 10 ** (self.get_weights(\"loss_layer\")[2])\n",
        "        grouping_strength = np.transpose(self.get_val(\"grouping_strengths\"))\n",
        "\n",
        "        target_strength = self.get_weights(\"loss_layer\")[0]\n",
        "        target_grouping = self.get_weights(\"loss_layer\")[1]\n",
        "\n",
        "        skeleton_loss_weights = np.transpose(skeleton_loss_weight * self.get_val(\"skeleton_losscosts\"))\n",
        "        print(\"Skeleton loss weight, extracted:\", skeleton_loss_weight)\n",
        "        #plt.plot(np.transpose((self.get_val(\"grouping_strengths\") - 0.00023251) ** 2), \":\") # Deviation penalties\n",
        "        #plt.plot(np.transpose(skeleton_loss_weight * self.get_val(\"skeleton_losscosts\")), \"--\")  # Skeleton loss penalties\n",
        "        #plt.plot(np.transpose((self.get_val(\"grouping_strengths\") - 0.00023251) ** 2) + skeleton_loss_weight * np.transpose(self.get_val(\"skeleton_losscosts\"))) # Total penalties\n",
        "        #plt.plot(skeleton_loss_weights, \"--\")\n",
        "        #plt.plot(-grouping_strength, \":\")\n",
        "        #plt.plot(skeleton_loss_weights - grouping_strength)        \n",
        "        plt.plot(np.transpose(self.get_val(\"skeleton_losscosts\") - target_strength)**2) # + (grouping_strength - target_grouping) ** 2)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        #ys = (tf.reduce_max(self.skeleton_loss_cost, [2,3,4]) - self.target_strength) ** 2\n",
        "    \n",
        "\n",
        "\n",
        "model = get_keras_model()\n",
        "testing = 0\n",
        "model.compile(loss=(lambda _, c: c), optimizer=tf.keras.optimizers.Adam(0.0 if testing else .005))\n",
        "\n",
        "\n",
        "prepared_dataset = translated_dataset.shuffle(10*batch_size).batch(batch_size).prefetch(batch_size)\n",
        "\n",
        "if True:\n",
        "    history = model.fit(prepared_dataset,\n",
        "                        callbacks=[MonitorProgressCallback(prepared_dataset.as_numpy_iterator(), 1 if testing else 12)],\n",
        "                        epochs=(1 if testing else 1000),\n",
        "                        steps_per_epoch=(1 if testing else 3), use_multiprocessing=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCzdTCu_yk_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARAMETERS\n",
        "\n",
        "kk = 2.8\n",
        "cp = 0.2\n",
        "cn = 0.25\n",
        "v1_v4_scale_weights = tf.tile(tf.constant([.04, .1, .13, .04, .01])[:, None], [1, n_v4_scales]) # includes the CSF\n",
        "v1_v4_scale_weights = tf.ones((n_v1_scales, n_v4_scales)) # An alternative for the CSF.\n",
        "v1_v4_orientation_weights = tf.ones((2*n_v1_orientations, n_v4_scales))\n",
        "\n",
        "k = tf.constant([2.4] * n_v4_scales)\n",
        "b = (0.7 ** (2.4 * tf.range(n_v4_scales, dtype=tf.float32)))\n",
        "\n",
        "v4_filters = make_v4_filters(2.8, 0, 0, 0, 0, cp, cn)[None, ...]\n",
        "v4_filters_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(v4_filters, 0.), [3, 4])) \n",
        "\n",
        "# Skeleton loss penalty\n",
        "blurwidths = tf.constant([0.0025, 0.002, 0.0026, 0.0067, 0.003, 0.0001, 0.0001, 0.0001])\n",
        "loss_penalties = tf.constant([0.5, 1.6, 1.5, 0.37, 0.1, 0.01, 0.01, 0.01])\n",
        "skeleton_loss_target = 10\n",
        "\n",
        "#channel_attention_attraction_rate = tf.constant([.15, .18, .25, .48, .25, .14, .05, 0.002])[:, None, None]\n",
        "#g = tf.constant([1.07, 1.122, 1.156, 1.158, 1.162, 1.152, 1.159, 1.143])[:, None, None]\n",
        "#beta = tf.constant([0., 0.04, 0.06, 0.05, 0.135, 0.126, 0.117, 0.1])[:, None, None]\n",
        "#w_local = 0.06 * tf.ones((n_v4_scales, n_v4_scales)) # actually a whole thing\n",
        "#w_global = 0.04 * tf.ones((n_v4_scales, n_v4_scales)) # actually a whole thing\n",
        "#fk = tf.constant([1.001, 1.055, 1.08, 1.041, 1.08, 1.091, 1.09, 1.08])[:, None, None]\n",
        "#fb = tf.constant([0.24, 0.25, .332, .47, .32, .2, .12, .08])[:, None, None]\n",
        "#yfn = tf.ones((n_v4_scales, box_height))[:, :, None]\n",
        "\n",
        "def g_response(v1c):\n",
        "    # Multiply by CSF\n",
        "    v1b = tf.pad(tf.concat([v1c]*2, axis=1), [[0, 0], [0, 0],\n",
        "                                [int(np.ceil(box_height / 2)), int(box_height / 2)],\n",
        "                                [int(np.ceil(box_width / 2)), int(box_width / 2)]], mode='CONSTANT')\n",
        "\n",
        "    b_balanced_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(v1b, 0.), [2, 3]))\n",
        "    v4_activations_by_s_o = tf.nn.relu(tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(v4_filters_fft * b_balanced_fft[:, :, None, :, :]), [3, 4]))) \n",
        "    v4_activations = tf.einsum(\"sochw,sc->ochw\", v4_activations_by_s_o, v1_v4_scale_weights)\n",
        "    g_activations = tf.einsum(\"ochw,oc->chw\", v4_activations, v1_v4_orientation_weights)\n",
        "\n",
        "    #print(\"GCELLs\")\n",
        "    #plt.imshow(g_activations[0, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "    #                        int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))])\n",
        "    #plt.show()\n",
        "\n",
        "    return g_activations \n",
        "\n",
        "def pair_at_distance(d, l, r):\n",
        "    (lt, rt) = get_pair_translations(l, r, d)\n",
        "    v1_l = translate_4d_image(glyph_v1_responses[l], np.array([lt]))[0, ...]\n",
        "    v1_r = translate_4d_image(glyph_v1_responses[r], np.array([rt]))[0, ...]\n",
        "    g_l = translate_4d_image(glyph_images[l][None, None, :, :], np.array([lt]))[0, 0, 0, :, :]\n",
        "    g_r = translate_4d_image(glyph_images[r][None, None, :, :], np.array([rt]))[0, 0, 0, :, :]\n",
        "    v1_p = v1_l + v1_r\n",
        "\n",
        "    v1c_l, v1c_r, v1c_p = tf.abs(v1_l), tf.abs(v1_r), tf.abs(v1_p)\n",
        "    v4g_l, v4g_r, v4g_p = g_response(v1c_l), g_response(v1c_r), g_response(v1c_p)\n",
        "\n",
        "\n",
        "    # Find the skeleton losses\n",
        "    losses = tf.nn.relu(v4g_l - v4g_p) + tf.nn.relu(v4g_r - v4g_p)\n",
        "\n",
        "    losses_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(losses, eps), [1, 2]))\n",
        "    losses_filters = make_losses_filters(eps + tf.nn.relu(blurwidths))[0, 0, ...]\n",
        "    losses_filters_fft = tf.signal.fft2d(tf.signal.ifftshift(tf.complex(losses_filters, eps), [1, 2]))\n",
        "    losses_filtered = tf.math.real(tf.signal.fftshift(tf.signal.ifft2d(losses_fft * losses_filters_fft), [1, 2]))[:, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                            int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))]\n",
        "\n",
        "    penalized_losses = losses_filtered * loss_penalties[:, None, None] # tf.nn.relu(self.wp)[None, None, :, None, None]\n",
        "\n",
        "    loss_penalty = (tf.reduce_max(penalized_losses) - skeleton_loss_target) ** 2\n",
        "    if (l == \"c\"):\n",
        "        plt.imshow(g_l + g_r, cmap=\"gray\")\n",
        "        plt.imshow(tf.reduce_sum(losses[:, int(np.ceil(box_height / 2)):int(box_height + np.ceil(box_height / 2)),\n",
        "                            int(np.ceil(box_width / 2)):int(box_width + np.ceil(box_width / 2))], [0]), alpha=0.8)\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "#    relevance = 1. - (tf.abs(v4g_l - v4g_r)/(eps + v4g_l + v4g_r)) ** 1.3\n",
        "#\n",
        "#    attention_attraction_rates = v4g_p * channel_attention_attraction_rate * relevance * yfn / (eps + tf.reduce_min(channel_attention_attraction_rate))\n",
        "#\n",
        "#    attention_attraction_pool_local = tf.einsum(\"chw,qc->qhw\", attention_attraction_rates ** g, w_local)\n",
        "#    attention_attraction_pool_global = tf.einsum(\"chw,qc->q\", attention_attraction_rates ** g, w_global)[:, None, None]\n",
        "#    probability_of_grouping_feedback = attention_attraction_rates ** g / (beta ** g + attention_attraction_pool_local + attention_attraction_pool_global)\n",
        "#    \n",
        "#    feedback_strength = v4g_p ** fk * fb\n",
        "#\n",
        "#    mean_grouping_strength = tf.reduce_sum(probability_of_grouping_feedback * feedback_strength)\n",
        "    #print(\"loss_penalty\", loss_penalty)\n",
        "    return loss_penalty\n",
        "\n",
        "def find_best_distance(l, r):\n",
        "    best_distance = minimize_scalar(pair_at_distance, args=(l, r), options={\"maxiter\": 1}).x\n",
        "\n",
        "    print(\"Best distance for\", l, r, \":\", best_distance)\n",
        "\n",
        "\n",
        "find_best_distance(\"n\", \"n\")\n",
        "#find_best_distance(\"l\", \"l\")\n",
        "#find_best_distance(\"p\", \"o\")\n",
        "#find_best_distance(\"d\", \"b\")\n",
        "#find_best_distance(\"d\", \"h\")\n",
        "find_best_distance(\"c\", \"x\")\n",
        "#find_best_distance(\"m\", \"i\")\n",
        "#find_best_distance(\"a\", \"a\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}